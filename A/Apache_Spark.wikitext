{{NoteTA
| G1 = IT
| G2 = FL
| 1= zh-cn:集群; zh-tw:叢集;
}}
{{Infobox Software
| name                   = Apache Spark
| logo                   = [[File:Spark-logo-192x100px.png|frameless]]
| caption                =
| developer              = [[Apache軟體基金會|Apache軟體基金會]], [[加州大學柏克萊分校|加州大學柏克萊分校]]AMPLab, [[Databricks|Databricks]]
| status                 = 活躍
| latest release version = 2.4.3
| latest release date    = {{release date|2019|5|8}}
| latest preview version = 
| latest preview date    = 
| operating system       = [[Linux|Linux]], [[Mac_OS|Mac OS]], [[Microsoft_Windows|Microsoft Windows]]
| size                   = 
| programming language   = [[Scala|Scala]], [[Java|Java]], [[Python|Python]]
| genre                  = [[數據分析|數據分析]], [[機器學習|機器學習]]演算法
| license                = [[Apache许可证|Apache授權條款]] 2.0 
| website                = {{URL|https://spark.apache.org}}
}}

'''Apache Spark'''是一個[[開源|開源]]叢集運算框架，最初是由加州大學柏克萊分校AMPLab所開發。相對於[[Apache_Hadoop|Hadoop]]的[[MapReduce|MapReduce]]會在執行完工作後將中介資料存放到磁碟中，Spark使用了記憶體內運算技術，能在資料尚未寫入硬碟時即在記憶體內分析運算。Spark在記憶體內執行程式的運算速度能做到比Hadoop MapReduce的運算速度快上100倍，即便是執行程式於硬碟時，Spark也能快上10倍速度。<ref>{{cite paper| first1=Reynold| last1=Xin| first2=Josh| last2=Rosen| first3=Matei| last3=Zaharia| first4=Michael| last4=Franklin| first5=Scott| last5=Shenker| first6=Ion| last6=Stoica| title=Shark: SQL and Rich Analytics at Scale| conference=SIGMOD 2013| date=June 2013| url=https://amplab.cs.berkeley.edu/wp-content/uploads/2013/02/shark_sigmod2013.pdf| journal=| access-date=2015-05-30| archive-date=2017-08-09| archive-url=https://web.archive.org/web/20170809050056/https://amplab.cs.berkeley.edu/wp-content/uploads/2013/02/shark_sigmod2013.pdf| dead-url=no}}</ref>Spark允許用戶將資料加載至叢集記憶體，並多次對其進行查詢，非常適合用於[[機器學習|機器學習]]演算法。<ref>{{cite AV media|url=http://www.youtube.com/watch?v=qLvLg-sqxKc|location=Invited Talk at NIPS 2011 Big Learning Workshop: Algorithms, Systems, and Tools for Learning at Scale|people=Matei Zaharia|title=Spark: In-Memory Cluster Computing for Iterative and Interactive Applications|access-date=2015-05-30|archive-date=2015-11-13|archive-url=https://web.archive.org/web/20151113033741/https://www.youtube.com/watch?v=qLvLg-sqxKc|dead-url=no}}</ref>

使用Spark需要搭配叢集管理員和分散式儲存系統。Spark支援獨立模式（本地Spark叢集）、[[Apache_Hadoop|Hadoop YARN]]或[[Apache_Mesos|Apache Mesos]]的叢集管理。<ref>{{cite web |url=https://spark.apache.org/docs/1.2.0/cluster-overview.html#cluster-manager-types |title=Cluster Mode Overview - Spark 1.2.0 Documentation - Cluster Manager Types |author=<!--Staff writer(s); no by-line.--> |date=2014-12-18 |website=apache.org |publisher=Apache Foundation |accessdate=2015-01-18 |archive-date=2015-01-19 |archive-url=https://web.archive.org/web/20150119080215/https://spark.apache.org/docs/1.2.0/cluster-overview.html#cluster-manager-types |dead-url=no }}</ref>  在分散式儲存方面，Spark可以和 [[Alluxio|Alluxio]]、[[Apache_Hadoop|HDFS]]<ref>{{Cite web |url=https://amplab.cs.berkeley.edu/software/ |title=Figure showing Spark in relation to other open-source Software projects including Hadoop |accessdate=2015-05-30 |archive-date=2015-03-24 |archive-url=https://web.archive.org/web/20150324111910/https://amplab.cs.berkeley.edu/software/ |dead-url=no }}</ref>、 [[Apache_Cassandra|Cassandra]]<ref>{{cite mailing list |url=http://mail-archives.apache.org/mod_mbox/cassandra-user/201409.mbox/%3CCABNXB2DE5Apmvn1nNg79+VdPCSZiCsGdt=ZB4s4OF_5JzS60iA@mail.gmail.com%3E |title=Re: cassandra + spark / pyspark |date=2014-09-10 |accessdate=2014-11-21 |mailinglist=Cassandra User |last=Doan |first=DuyHai |archive-date=2015-05-30 |archive-url=https://web.archive.org/web/20150530182941/http://mail-archives.apache.org/mod_mbox/cassandra-user/201409.mbox/%3CCABNXB2DE5Apmvn1nNg79+VdPCSZiCsGdt=ZB4s4OF_5JzS60iA@mail.gmail.com%3E |dead-url=no }}</ref> 、[[OpenStack#Object_Storage_(Swift)|OpenStack Swift]]和[[Amazon_S3|Amazon S3]]等介面搭配。 Spark也支援偽分散式（pseudo-distributed）本地模式，不過通常只用於開發或測試時以本機檔案系統取代分散式儲存系統。在這樣的情況下，Spark僅在一台機器上使用每個CPU核心執行程序。

在2014年有超過465位貢獻者投入Spark開發<ref>{{Cite web |url=https://www.openhub.net/p/apache-spark |title=Open HUB Spark development activity |accessdate=2015-05-30 |archive-date=2014-12-07 |archive-url=https://web.archive.org/web/20141207194200/https://www.openhub.net/p/apache-spark |dead-url=no }}</ref>，讓其成為[[Apache軟體基金會|Apache軟體基金會]]以及[[巨量資料|巨量資料]]眾多開源專案中最為活躍的專案。

==歷史==
Spark在2009年由{{le|Matei Zaharia|Matei Zaharia}}在[[加州大學柏克萊分校|加州大學柏克萊分校]]AMPLab開創，2010年透過[[BSD授權條款|BSD授權條款]]開源釋出。2013年，該專案被捐贈給[[Apache軟體基金會|Apache軟體基金會]]並切換授權條款至Apache2.0。<ref>{{cite web |url=https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces50 |title=The Apache Software Foundation Announces Apache&#8482 Spark&#8482 as a Top-Level Project |author=<!--Staff writer(s); no by-line.--> |date=27 February 2014 |website=apache.org |publisher=Apache Software Foundation |accessdate=4 March 2014 |archive-date=2015-03-17 |archive-url=https://web.archive.org/web/20150317210246/https://blogs.apache.org/foundation/entry/the_apache_software_foundation_announces50 |dead-url=no }}</ref>。2014年2月，Spark成為Apache的頂級專案。2014年11月，Databricks團隊使用Spark 刷新資料排序世界記錄。<ref>{{Cite web |url=http://databricks.com/blog/2014/11/05/spark-officially-sets-a-new-record-in-large-scale-sorting.html |title=Spark officially sets a new record in large-scale sorting |accessdate=2015-05-30 |archive-date=2015-05-15 |archive-url=https://web.archive.org/web/20150515145909/http://databricks.com/blog/2014/11/05/spark-officially-sets-a-new-record-in-large-scale-sorting.html |dead-url=no }}</ref>

==專案構成要素==
Spark專案包含下列幾項:

===Spark核心和彈性分散式資料集（RDDs）===
Spark核心是整個專案的基礎，提供了分散式任務調度，排程和基本的I／O功能。而其基礎的程序抽象則稱為彈性分散式資料集（RDDs），是一個可以并行操作、有容錯機制的資料集合。 RDDs可以透過引用外部存儲系統的資料集建立（例如：共享文件系統、HDFS、HBase或其他 Hadoop 資料格式的資料來源）。或者是通過在現有RDDs的轉換而創建（比如：map、filter、reduce、join等等）。

RDD抽象化是經由一個以[[Scala|Scala]]、[[Java|Java]]、[[Python|Python]]的語言集成API所呈現，簡化了編程複雜性，應用程序操縱RDDs的方法類似於操縱本地端的資料集合。

以 RDD 為中心的函數式編程的一個典型示例是以下 Scala 程序，它計算一組文本文件中出現的所有單詞的頻率並打印最常見的單詞。 每個 map、flatMap（map 的變體）和 reduceByKey 都採用匿名函數對單個數據項（或一對項）執行簡單操作，並應用其參數將 RDD 轉換為新的 RDD。<ref>{{cite book|url=https://qualified.one/books/taming-big-data-with-apache-spark-and-python/|title=Taming Big Data with Apache Spark and Python|author=Frank Kane|ISBN=978-1787287945|publisher=Packt|year=2017|access-date=2021-11-09|archive-date=2021-11-09|archive-url=https://web.archive.org/web/20211109233622/https://qualified.one/books/taming-big-data-with-apache-spark-and-python/}}</ref><ref>{{Citation|title=dotnet/spark|date=2020-09-14|url=https://github.com/dotnet/spark|publisher=.NET Platform|access-date=2020-09-14|archive-date=2022-04-29|archive-url=https://web.archive.org/web/20220429003731/https://github.com/dotnet/spark}}</ref>


<syntaxhighlight lang="scala">
val conf = new SparkConf().setAppName("wiki_test") 
val sc = new SparkContext(conf) 
val data = sc.textFile("/path/to/somedir") 
val tokens = data.flatMap(_.split(" ")) 
val wordFreq = tokens.map((_, 1)).reduceByKey(_ + _) 
wordFreq.sortBy(s => -s._2).map(x => (x._2, x._1)).top(10) 
</syntaxhighlight>

===Spark SQL===
Spark SQL在Spark核心上帶出一種名為SchemaRDD的資料抽象化概念，提供結構化和半結構化資料相關的支援。Spark SQL提供了領域特定語言，可使用Scala、Java或Python來操縱SchemaRDDs。它還支援使用使用命令行界面和ODBC／JDBC伺服器操作SQL語言。在Spark 1.3版本，SchemaRDD被重新命名為DataFrame。

===Spark Streaming===
Spark Streaming充分利用Spark核心的快速排程能力來執行串流分析。它擷取小批量的資料並對之執行RDD轉換。這種設計使串流分析可在同一個引擎內使用同一組為批次分析編寫而撰寫的應用程序代碼。

===MLlib===
MLlib是Spark上分散式機器學習框架。Spark分散式記憶體式的架構比Hadoop磁碟式的[[Apache_Mahout|Apache Mahout]]快上10倍，擴充性甚至比{{le|Vowpal Wabbit|Vowpal Wabbit}}要好。<ref>{{cite web |url=http://www.slideshare.net/chaochen5496/mlllib-sparkmeetup8613finalreduced |title=Spark Meetup: MLbase, Distributed Machine Learning with Spark |last1=Sparks |first1=Evan |last2=Talwalkar |first2=Ameet |date=2013-08-06 |website=slideshare.net |publisher=Spark User Meetup, San Francisco, California |accessdate=10 February 2014 |archive-date=2015-06-26 |archive-url=https://web.archive.org/web/20150626122507/http://www.slideshare.net/chaochen5496/mlllib-sparkmeetup8613finalreduced |dead-url=no }}</ref> MLlib可使用許多常見的機器學習和統計演算法，簡化大規模機器學習時間，其中包括：
*匯總統計、相關性、分層抽樣、假設檢定、隨機數據生成
*分類與回歸：[[支持向量機|支持向量機]]、[[回歸|回歸]]、[[線性回歸|線性回歸]]、[[邏輯回歸|邏輯回歸]]、[[決策樹|決策樹]]、[[樸素貝葉斯分類器|樸素貝葉斯]]
*[[協同過濾|協同過濾]]：ALS
*分群：[[K-平均算法|k-平均演算法]]
*維度约减：[[奇異值分解|奇異值分解]]（SVD），[[主成分分析|主成分分析]]（PCA）
*特徵提取和轉換：TF-IDF、Word2Vec、StandardScaler
*最优化：隨機梯度下降法（SGD）、L-BFGS

===GraphX===
GraphX是Spark上的分散式圖形處理框架。它提供了一組API，可用於表達圖表計算並可以模擬Pregel抽象化。GraphX還對這種抽象化提供了優化運行。

GraphX最初為[[加州大學柏克萊分校|加州大學柏克萊分校]]AMPLab和Databricks的研究專案，後來捐贈給Spark專案。<ref>{{cite paper| first1=Joseph| last1=Gonzalez| first2=Reynold| last2=Xin| first3=Ankur| last3=Dave| first4=Daniel| last4=Crankshaw| first5=Michael| last5=Franklin| first6=Ion| last6=Stoica| title=GraphX: Graph Processing in a Distributed Dataflow Framework| conference=OSDI 2014| date=Oct 2014| url=https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-gonzalez.pdf| journal=| access-date=2015-05-30| archive-date=2014-12-07| archive-url=https://web.archive.org/web/20141207172944/https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-gonzalez.pdf| dead-url=no}}</ref>

==特色==
*Java、Scala、Python和R APIs。
*可擴展至超過8000個結點。<ref>{{cite web |url=https://spark.apache.org/faq.html |title=Apache Spark FAQ |author=<!--Staff writer(s); no by-line.--> |website=apache.org |publisher=Apache Software Foundation |accessdate=5 December 2014 |archive-url=https://web.archive.org/web/20150520060625/http://spark.apache.org/faq.html |archive-date=2015-05-20 |dead-url=yes }}</ref>
*能夠在記憶體內緩存資料集以進行交互式資料分析。
*Scala或Python中的互動式命令列介面可降低橫向擴展資料探索的反應時間。
*Spark Streaming對即時資料串流的處理具有可擴充性、高吞吐量、可容錯性等特點。
*Spark SQL支援結構化和關聯式查詢處理（SQL）。
*MLlib機器學習演算法和Graphx圖形處理演算法的高階函式庫。

==參考資料==
{{Reflist|30em}}

==外部連結==
*{{Official website|https://spark.apache.org}}{{En}}
*[https://spark.apache.org/sql/ Spark SQL] {{Wayback|url=https://spark.apache.org/sql/ |date=20150519040940 }}
*[https://spark.apache.org/streaming/ Spark Streaming] {{Wayback|url=https://spark.apache.org/streaming/ |date=20150519040945 }}
*[https://spark.apache.org/mllib/ MLlib機器學習] {{Wayback|url=https://spark.apache.org/mllib/ |date=20150531031024 }}
*[https://spark.apache.org/graphx/ GraphX 圖形處理] {{Wayback|url=https://spark.apache.org/graphx/ |date=20150603052740 }}

{{Apache}}

[[Category:叢集計算|Category:叢集計算]]
[[Category:Hadoop|Category:Hadoop]]
[[Category:加利福尼亞大學柏克萊分校|Category:加利福尼亞大學柏克萊分校]]
[[Category:Apache軟體基金會|Category:Apache軟體基金會]]
[[Category:Scala平台軟體|Category:Scala平台軟體]]
[[Category:Java平台|Category:Java平台]]
[[Category:使用Apache許可證的軟體|Category:使用Apache許可證的軟體]]