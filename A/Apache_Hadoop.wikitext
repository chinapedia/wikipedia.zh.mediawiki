{{citation style|time=2017-11-22T03:37:20+00:00}}
{{NoteTA|G1=IT|G2=FL}}
{{Infobox software
| name = Apache Hadoop
| logo = Hadoop logo.svg
| logo_alt = Hadoop Logo
| screenshot = 
| caption = 
| developer = [[Apache软件基金会|Apache软件基金会]]
| status = 活躍
| released = {{Start date and age|2006|04|01}}<ref>{{cite web |url=https://archive.apache.org/dist/hadoop/common/ |title=Hadoop Releases |website=apache.org |publisher=Apache Software Foundation |accessdate=2019-04-28 |archive-date=2019-04-28 |archive-url=https://web.archive.org/web/20190428190426/https://archive.apache.org/dist/hadoop/common/ |dead-url=no }}</ref>
| latest release version = 3.3.0
| latest release date = {{Release date|2020|07|14}}
| latest preview version = 3.0.0-alpha4
| latest preview date = {{Release date|2017|07|07}}
| operating system = [[跨平台|跨平台]]
| programming language = [[Java|Java]]
| genre = [[大數據|大數據]]、[[分佈式系統|分佈式系統]]
| license = [[Apache許可證|Apache許可證]] 2.0
| website = {{URL|https://hadoop.apache.org/}}
}}

'''Apache Hadoop'''是一款支持數據密集型[[分布式计算|分佈式]]應用程序并以[[Apache许可证|Apache 2.0許可協議]]發佈的[[開源|開源]][[軟體框架|軟體框架]]。它支持在商用硬件構建的大型集群上運行的應用程序。Hadoop是根據[[谷歌公司|谷歌公司]]發表的[[MapReduce|MapReduce]]和[[Google檔案系統|Google檔案系統]]的論文自行實作而成。所有的Hadoop模块都有一个基本假设，即硬件故障是常见情况，应该由框架自动处理。

Hadoop框架透明地為應用提供可靠性和數據移動。它實現了名為MapReduce的[[編程範式|編程範式]]：應用程序被分割成許多小部分，而每個部分都能在集群中的任意節點上執行或重新執行。此外，Hadoop還提供了分佈式文件系統，用以存儲所有計算節點的數據，這為整個集群帶來了非常高的帶寬。MapReduce和分佈式文件系統的設計，使得整個框架能夠自動處理節點故障。它使應用程序與成千上萬的獨立計算的電腦和PB級的數據连接起来。現在普遍認為整個Apache Hadoop“平台”包括Hadoop內核、MapReduce、Hadoop分佈式文件系統（HDFS）以及一些相關項目，有Apache Hive和Apache HBase等等。

== 主要子项目 ==
[[File:Cubieboard_HADOOP_cluster.JPG|thumb]]用Cubieboard电脑。]]
* Hadoop Common：在0.20及以前的版本中，包含HDFS、[[MapReduce|MapReduce]]和其他项目公共内容，从0.21开始HDFS和MapReduce被分离为独立的子项目，其余内容为Hadoop Common
* HDFS：Hadoop分佈式文件系統（Distributed File System）－HDFS（Hadoop Distributed File System）
* MapReduce：并行计算框架，0.20前使用org.apache.hadoop.mapred旧接口，0.20版本开始引入org.apache.hadoop.mapreduce的新API

== 相關项目 ==
* [[Apache_HBase|Apache HBase]]：分布式[[NoSQL|NoSQL]]列[[数据库|数据库]]，类似[[谷歌|谷歌]]公司[[BigTable|BigTable]]。
* [[Apache_Hive|Apache Hive]]：构建于hadoop之上的[[数据仓库|数据仓库]]，通过一种类[[SQL|SQL]]语言HiveQL为用户提供数据的归纳、查询和分析等功能。Hive最初由[[Facebook|Facebook]]贡献。
* [[Apache_Mahout|Apache Mahout]]：[[机器学习|机器学习]]算法软件包。
* [[Apache_Sqoop|Apache Sqoop]]：[[结构化数据|结构化数据]]（如[[关系数据库|关系数据库]]）与Apache Hadoop之间的数据转换工具。
* [[Apache_ZooKeeper|Apache ZooKeeper]]：分布式锁设施，提供类似[[Google|Google]] [[Chubby|Chubby]]的功能，由[[Facebook|Facebook]]贡献。
* [[Apache_Avro|Apache Avro]]：新的数据[[序列化|序列化]]格式与传输工具，将逐步取代Hadoop原有的IPC机制。

== 知名用戶 ==
=== Hadoop在Yahoo!的應用 ===
2008年2月19日，[[雅虎|雅虎]]使用10,000個[[微處理器|微處理器]]核心的[[Linux|Linux]][[计算机集群|计算机集群]]運行一個Hadoop應用程式。<ref>{{Cite web |url=http://developer.yahoo.com/blogs/hadoop/2008/02/yahoo-worlds-largest-production-hadoop.html |title=Yahoo! Launches World's Largest Hadoop Production Application (Hadoop and Distributed Computing at Yahoo!) |accessdate=2008-09-04 |archive-date=2008-05-14 |archive-url=https://web.archive.org/web/20080514135459/http://developer.yahoo.com/blogs/hadoop/2008/02/yahoo-worlds-largest-production-hadoop.html |dead-url=yes }}</ref>

=== 其他用戶 ===
其他知名用戶包括<ref>{{Cite web |url=http://wiki.apache.org/hadoop/PoweredBy |title=PoweredBy |access-date=2008-09-07 |archive-url=https://web.archive.org/web/20121129102729/http://wiki.apache.org/hadoop/PoweredBy |archive-date=2012-11-29 |dead-url=yes }}</ref>：
<div style="-moz-column-count:3; column-count:3;">
* A9.com
* [[Facebook|Facebook]]
* Fox Interactive Media
* [[华为|华为]]
* [[IBM|IBM]]
* ImageShack
* [[資訊科學研究院|資訊科學研究院]]
* [[Joost|Joost]]
* [[Last.fm|Last.fm]]
* Powerset
* [[紐約時報|紐約時報]]
* Rackspace
* Veoh
* [[中華電信|中華電信]]
* [[中国移动|中国移动]]
</div>

== Hadoop與Sun Grid Engine ==
[[昇陽|昇陽]]電腦的[[Sun_Grid_Engine|Sun Grid Engine]]可以用来调度Hadoop Job。<ref>{{cite web|url=http://blogs.sun.com/ravee/entry/creating_hadoop_pe_under_sge|title=Creating Hadoop pe under SGE|date=2008-01-16|publisher=[[Sun_Microsystems|Sun Microsystems]]|deadurl=yes|archiveurl=https://web.archive.org/web/20080912170855/http://blogs.sun.com/ravee/entry/creating_hadoop_pe_under_sge|archivedate=2008-09-12|accessdate=2008-09-04}}</ref><ref>{{cite web|url=http://wikis.sun.com/download/attachments/170755116/hpcworkshop_hdfs.pdf|title=HDFS-Aware Scheduling With Grid Engine|date=2009-09-10|publisher=[[Sun_Microsystems|Sun Microsystems]]}}{{dead link|date=2017年11月 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>

== Hadoop與Condor ==
[[威斯康辛大學麥迪遜分校|威斯康辛大學麥迪遜分校]]的Condor[[計算機集群|計算機集群]]軟件也可以用作Hadoop Job的排程。<ref>{{cite web|url=http://www.cs.wisc.edu/condor/CondorWeek2010/condor-presentations/thain-condor-hadoop.pdf|title=Condor integrated with Hadoop's Map Reduce|date=2010-04-15|publisher=[[威斯康辛大學麥迪遜分校|威斯康辛大學麥迪遜分校]]|accessdate=2011-03-15|archive-date=2011-04-01|archive-url=https://web.archive.org/web/20110401055838/http://www.cs.wisc.edu/condor/CondorWeek2010/condor-presentations/thain-condor-hadoop.pdf|dead-url=no}}</ref>

== 參見 ==
* [[大数据|大数据]]
* [[雲端運算|雲端運算]]
* [[高性能計算集群|高性能計算集群]]
* [[OpenStack|OpenStack]]－以[[Apache許可證|Apache許可證]]授權的雲端運算軟件。
* [[Apache_Spark|Apache Spark]]

== 参考文献 ==
{{Reflist}}

== 外部連結 ==
* [http://hadoop.apache.org/ Hadoop官方網站]{{Wayback|url=http://hadoop.apache.org/ |date=20170923024639 }}

{{-}}
{{Apache}}
{{Filesystem}}

{{Authority control}}
[[Category:Hadoop|Category:Hadoop]]
[[Category:Java|Category:Java]]
[[Category:Apache软件基金会|Category:Apache软件基金会]]
[[Category:文件系统|Category:文件系统]]
[[Category:分散式檔案系統|Category:分散式檔案系統]]