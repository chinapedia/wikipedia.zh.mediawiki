{{线性代数}}
[[线性代数|线性代数]]中，'''特征分解'''（Eigendecomposition），又称'''[[谱定理|谱分解]]'''（Spectral decomposition）是将[[矩阵|矩阵]]分解为由其[[特征值|特征值]]和[[特征向量|特征向量]]表示的矩阵之积的方法。需要注意只有对[[可对角化矩阵|可对角化矩阵]]才可以施以特征分解。

==特征值与特征向量的基础理论==

{{main|特征值|特征向量}}

''N'' 维非零向量 '''v''' 是 ''N''×''N'' 的矩阵 '''A''' 的[[特征向量|特征向量]]，当且仅当下式成立：
:<math> \mathbf{A} \mathbf{v} = \lambda \mathbf{v}  </math>
其中 ''λ'' 为一标量，称为 '''v''' 对应的[[特征值|特征值]]。也称 '''v''' 为特征值 ''λ'' 对应的特征向量。也即特征向量被施以线性变换 A 只会使向量伸长或缩短而其方向不被改变。

由上式可得
:<math> p\left(\lambda\right) := \det\left(\mathbf{A} - \lambda \mathbf{I}\right)= 0. \!\ </math>
称多项式 ''p''('''λ''') 为矩阵的[[特征多项式|特征多项式]]。上式亦称为矩阵的[[特征方程|特征方程]]。特征多项式是关于未知数 ''λ'' 的 ''N'' 次多项式。由[[代数基本定理|代数基本定理]]，特征方程有 ''N'' 个解。这些解的解集也就是特征值的集合，有时也称为“谱”（Spectrum）。

我们可以对多项式 ''p'' 进行[[因式分解|因式分解]]，而得到
:<math>p\left(\lambda\right)= (\lambda-\lambda_1)^{n_1}(\lambda-\lambda_2)^{n_2}\cdots(\lambda-\lambda_k)^{n_k} = 0 \!\ </math>
其中
:<math>\sum\limits_{i=1}^{k}{n_i} =N.</math>

对每一个特征值 λ<sub>''i''</sub> ，我们都有下式成立：
:<math> \left(\mathbf{A} - \lambda_i \mathbf{I}\right)\mathbf{v}  = 0. \!\ </math>

对每一个特征方程，都会有<math>m_i</math>（ <math>1\le m_i \le n_i</math> ）个[[线性无关|线性无关]]的解。这 ''m''<sub>''i''</sub> 个向量与一个特征值 λ<sub>''i''</sub> 相对应。这里，整数 ''m''<sub>''i''</sub> 称为特征值 λ<sub>''i''</sub> 的'''几何重数'''，而 ''n''<sub>''i''</sub> 称为'''代数重数'''。这里需要注意的是几何重数与代数重数可以相等，但也可以不相等。一种最简单的情况是 ''m''<sub>''i''</sub> = ''n''<sub>''i''</sub> = 1。特征向量的极大线性无关向量组中向量的个数可以由所有特征值的几何重数之和来确定。

==矩阵的特征分解==

令 '''A''' 是一个 ''N''×''N'' 的方阵，且有 ''N'' 个[[线性獨立|线性獨立]]的特征向量 <math>q_i \,\, (i = 1, \dots, N)</math> 。这样， '''A''' 可以被[[矩阵分解|分解]]为
:<math>\mathbf{A}=\mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^{-1}  </math>
其中 '''Q''' 是''N''×''N''方阵，且其第 ''i''列为 '''A''' 的特征向量 <math>q_i</math>。 '''Λ''' 是[[对角矩阵|对角矩阵]]，其对角线上的元素为对应的特征值，也即  <math>\Lambda_{ii}=\lambda_i</math>。这里需要注意只有[[可对角化矩阵|可对角化矩阵]]才可以作特征分解。比如
<math>\begin{bmatrix}
1 & 1 \\
0 & 1 \\
\end{bmatrix}</math>不能被对角化，也就不能特征分解。

一般来说，特征向量 <math>q_i \,\, (i = 1, \dots, N)</math> 一般被单位化（但这不是必须的）。未被单位化的特征向量组 <math>v_i \,\, (i = 1, \dots, N),</math> 也可以作为 '''Q''' 的列向量。这一事实可以这样理解： '''Q''' 中向量的[[模|长度]]都被 '''Q'''<sup>−1</sup> 抵消了。

===通过特征分解求反(逆)矩阵===

{{main|反(逆)矩阵}}

若矩阵 '''A''' 可被特征分解并特征值中不含零，则矩阵 '''A''' 为[[非奇异矩阵|非奇异矩阵]]，且其[[逆矩阵|逆矩阵]]可以由下式给出：

:<math>\mathbf{A}^{-1}=\mathbf{Q}\mathbf{\Lambda}^{-1}\mathbf{Q}^{-1}  </math>

因为 '''Λ''' 为[[对角矩阵|对角矩阵]]，其逆矩阵容易计算出：
:<math>\left[\Lambda^{-1}\right]_{ii}=\frac{1}{\lambda_i}</math>

==对特殊矩阵的特征分解==
===对称矩阵===

任意的 ''N''×''N'' [[实对称矩阵|实对称矩阵]]都有 ''N'' 个线性无关的特征向量。并且这些特征向量都可以正交单位化而得到一组正交且[[模|模]]为 1 的向量。故实对称矩阵 '''A''' 可被分解成
:<math>\mathbf{A}=\mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^{T}  </math>
其中 '''Q''' 为 [[正交矩阵|正交矩阵]]， '''Λ''' 为实[[对角矩阵|对角矩阵]]。

===正规矩阵===

类似地，一个复[[正规矩阵|正规矩阵]]具有一组正交特征向量基，故正规矩阵可以被分解成
:<math>\mathbf{A}=\mathbf{U}\mathbf{\Lambda}\mathbf{U}^{H}  </math>
其中 '''U''' 为一个[[酉矩阵|酉矩阵]]。进一步地，若 '''A''' 是[[埃尔米特矩阵|埃尔米特矩阵]]，那么对角矩阵 '''Λ''' 的对角元全是实数。若 '''A''' 还是酉矩阵，则 '''Λ''' 的所有对角元在[[复平面|复平面]]的[[单位圆|单位圆]]上取得。

==参见==

*[[矩阵分解|矩阵分解]]
*[[特征值|特征值]]
*[[特征向量|特征向量]]
*[[谱定理|谱定理]]

==参考==

* Franklin, Joel N (1968). ''Matrix Theory''. Dover Publications. ISBN 0-486-41179-6
* Golub, G. H. and Van Loan, C. F. (1996). ''Matrix Computations''. 3rd ed.,  Johns Hopkins University Press, Baltimore. ISBN 0-8018-5414-8.
* Horn, Roger A. and Johnson, Charles R (1985). ''Matrix Analysis''.  Cambridge University Press. ISBN 0-521-38632-2.
* Horn, Roger A. and Johnson, Charles R (1991). ''Topics in Matrix Analysis''. Cambridge University Press. ISBN 0-521-46713-6.
* Strang G (1998). ''Introduction to Linear Algebra''. 3rd ed., Wellesley-Cambridge Press. ISBN 0-9614088-5-5.

[[Category:线性代数|Category:线性代数]]
[[Category:矩阵分解|Category:矩阵分解]]