'''視覺信號保真度'''（VIF）是一種評估影像品質的方法，為基於自然場景統計和由{{link-en|人類視覺系統|Human_visual_system_model}}提取影像信號的概念的圖像質量評估參數。它由[[Hamid_R_Sheikh|Hamid R Sheikh]]和[[Alan_Bovik|Alan Bovik]]於2006年在德克薩斯大學奧斯汀分校圖像和視頻工程實驗室（LIVE）開發，結果顯示它與人類對影像質量的判斷非常相近。VIF部署在Netflix VMAF的視頻質量監控系統中，該系統控制Netflix傳輸的所有編碼視頻的影像質量。這占美國所有頻寬消耗的35％，並且在全球視頻流量中也不斷增加。

== 概述 ==
三維視覺環境的圖像和視頻都來自於[[自然場景|自然場景]]（natural scene）。自然場景在所有可能的信號空間形成一個微小的子空間，科學家發明了複雜的模型來描述這些統計數據。但是大多數真實世界都會造成這些統計數據的失真，並使圖像或視頻信號不自然。VIF假設測試和參考圖像之間的共享訊息與視覺品質高度相關，並採用自然場景統計（NSS）模型結合失真（通道）模型來量化這種共享訊息。與基於人類視覺系統（HVS）錯誤敏感度和結構測量的先前方法相比，VIF在消息理論中被使用，且不需要任何HVS或其他觀察幾何參數，就能產生完全參考（FR）質量評估（QA）方法；VIF也不需要任何需要優化的常數，就能與現有的QA方法相競爭。

具體來說，參考圖像被建模後通過HVS通道，接著由大腦處理的隨機「自然」源輸出。參考圖像的資訊被量化為HVS頻道的輸入和輸出之間的[[相互資訊|相互資訊]]（mutual information），這是大腦可以從HVS輸出中提取的最理想資訊。然後讓相同的參考圖像通過失真通道，並對測量進行量化。將這兩個訊息組合，形成視覺質量與相對圖像信息相關聯的視覺信息保真度。

== 模型 ==

=== 來源模型(source model) ===
圖像的的[[小波分析|小波係數]]可用[[高斯混合模型|高斯尺度混和]](Gaussain Scale Mixture, GSM)建模，以下針對特定子帶進行多尺度多方位分解的模型，其他子帶可以進行相似的模型。設給定子帶中的小波係數為<math>\mathcal{C}=\{\bar{\mathit{C_i}}:\mathit{i}\in\mathcal{I}\}</math>，<math>\mathcal{I}</math>表示整個子帶和每個子帶的空間索引集合，子帶被分割成M塊不重疊的區域，每塊對應到一個M維的向量<math>\bar{\mathit{C_i}}</math>。

根據GSM模型

<math>\mathcal{C}=\mathcal{S}\cdot\mathcal{U}=\{\mathit{S_i}\mathit{\bar{U_i}}:\mathit{i}\in\mathcal{I}\}</math>

其中<math>\mathit{S_i}</math>是一個正數，<math>\mathit{\bar{U_i}}</math>是一個平均為0且協方差為<math>\mathrm{C_U}</math>的高斯向量。我們假設這M塊區域彼此獨立，且隨機場<math>\mathcal{S}</math>和<math>\mathcal{U}</math>相互獨立。

=== 失真模型(distortion model) ===
我們利用小波域中的信號衰減和加性噪聲來對失真過程進行建模。以數學式表示，如果<math>\mathcal{D}=\{\bar{D_i}:i\in\mathcal{I}\}</math>表示來自失真圖像的特定子帶的隨機場，<math>\mathcal{G}=\{\bar{g_i}:i\in\mathcal{I}\}</math>是一個確定的常量場且<math>\mathcal{V}=\{\bar{v_i}:i\in\mathcal{I}\}</math>，<math>\bar{V_i}</math>是一個平均為0且協方差為<math>\mathrm{C_V}</math>的高斯向量，其中<math>\mathrm{C_V}=\sigma_v^2\mathrm{I}</math>，那麼

<math>\mathcal{D}=\mathcal{GC}+\mathcal{V}</math>

此外，<math>\mathcal{V}</math>獨立於<math>\mathcal{S}</math> 和<math>\mathcal{U}</math>。

=== 人類視覺系統模型(HVS model) ===
基於視覺信號感知中的不確定性，限制了可以從來源和失真圖像中提取的訊息量，HVS對此進行了額外的建模。這種不確定性的來源可以模擬為HVS模型中的視覺噪聲，小波分解特定子帶中的HVS噪聲更進一步被建模為[[加性高斯白噪声|加性高斯白噪聲]]。假設<math>\mathcal{N}=\{\bar{N_i}:i\in\mathcal{I}\}</math>和<math>\mathcal{N^{'}}=\{\bar{N^{'}_i}:i\in\mathcal{I}\}</math>是隨機場，<math>\bar{N_i}</math>和<math>\bar{N^{'}_i}</math>是平均為0且協方差為<math>\mathrm{C_N}</math>和<math>\mathrm{C^{'}_N}</math>的高斯向量。<math>\mathcal{\varepsilon}=\mathcal{C}+\mathcal{N}</math>和<math>\mathcal{F}=\mathcal{D}+\mathcal{N^{'}}</math>表示HVS輸出端的視覺信號。在數學上，E=C+N且F=D+N’。其中N和N’是隨機的且獨立於<math>\mathcal{S}</math>，<math>\mathcal{U}</math>和<math>\mathcal{V}</math>。

== 定義 ==
將<math>\bar{C}^{N}=(\bar{C_1},\bar{C_1},...,\bar{C_N})</math>定義為特定子帶中所有區塊的向量，同理定義<math>{S}^{N}</math>,<math>\bar{D}^{N}</math>,<math>\bar{E}^{N}</math>和<math>\bar{F}^{N}</math>。<math>s^{N}</math>為給定<math>{C}^{N}</math>和<math>\mathrm{C_U}</math>的<math>S^{N}</math>中機率最大的數。從參考圖像中獲取的資訊量為

<math>I(\bar{C}^{N};\bar{E}^{N}|\bar{S}^{N}=s^{N})=\frac{1}{2}\sum_{i=1}^N\log_2\Bigl(\frac{|s_i^{2}\mathsf{C_U}+\sigma_n^{2}\text{I}|}{|\sigma_n^{2}\text{I}|}\Bigr)</math>

而從測試圖像中獲取的資訊量為

<math>I(\bar{C}^{N};\bar{F}^{N}|\bar{S}^{N}=s^{N})=\frac{1}{2}\sum_{i=1}^N\log_2\Bigl(\frac{|g_i^{2}s_i^{2}\mathsf{C_U}+(\sigma_v^{2}+\sigma_n^{2})\text{I}|}{|(\sigma_v^{2}+\sigma_n^{2})\text{I}|}\Bigr)</math>

VIF定義為

<math>VIF=\frac{\textstyle \sum_{j\in{subbands}}^{}I(\bar{C}^{N,j};\bar{F}^{N,j}|S^{N,j}=s^{N,j}) \displaystyle}{\textstyle \sum_{j\in{subbands}}^{}I(\bar{C}^{N,j};\bar{E}^{N,j}|S^{N,j}=s^{N,j}) \displaystyle}</math>

== 性能 ==
評估LIVE圖像質量評估數據庫中，失真圖像的VIF得分，與相應的人類意見得分之間的[[斯皮尔曼等级相关系数|斯皮爾曼等級排序相關係數]]（SROCC）為0.96<ref name="auto">{{Cite web|url=http://videoclarity.com/wp-content/uploads/2013/05/Statistic-of-Full-Reference-UT.pdf|title=|accessdate=|author=|date=|publisher=}}</ref>。這顯示該指數與人類對圖像質量的感知非常相近，與最佳的FR IQA<ref name="auto"/>算法一致。

==參考文獻==
{{Reflist}}

[[Category:影像品質|Category:影像品質]]