{{Expand language|en|time=2018-05-24T11:53:17+00:00}}
在[[概率论|概率论]]和[[统计学|统计学]]中，'''高斯过程'''（{{lang-en|'''Gaussian process'''}}）是[[随机变量|观测值]]出现在一个连续域（例如时间或空间）的[[随机过程|随机过程]]。在高斯过程中，连续输入空间中每个点都是与一个[[正态分布|正态分布]]的[[随机变量|随机变量]]相关联。此外，这些随机变量的每个有限集合都有一个[[多元正态分布|多元正态分布]]，换句话说他们的任意有限[[线性组合|线性组合]]是一个正态分布。高斯过程的分布是所有那些（無限多个）随机变量的联合分布，正因如此，它是连续域（例如时间或空间）上[[函数|函数]]的分布。

高斯過程被認為是一種[[機器學習|機器學習]]算法，是以{{le|惰性學習|lazy learning|惰性學習}}方式，利用點與點之間同質性的度量作為{{le|核函數|Kernel function|核函數}}，以從輸入的訓練數據預測未知點的值。其預測結果不僅包含該點的值，而同時包含不確定性的資料－它的一維高斯分佈（即該點的[[邊際分佈|邊際分佈]]）。<ref>{{cite web|url=http://platypusinnovation.blogspot.co.uk/2016/05/a-simple-intro-to-gaussian-processes.html|title=Platypus Innovation: A Simple Intro to Gaussian Processes (a great data modelling tool)|publisher=}}</ref><ref>{{Cite journal|title=Multivariate Gaussian and Student-t process regression for multi-output prediction|url=http://link.springer.com/10.1007/s00521-019-04687-8|last=Chen|first=Zexun|last2=Wang|first2=Bo|date=2019-12-31|journal=Neural Computing and Applications|doi=10.1007/s00521-019-04687-8|language=en|issn=0941-0643|last3=Gorban|first3=Alexander N.}}</ref>

對於某些核函數，可以使用矩陣代數（見{{le|克里金插值法|kriging|克里金法}}條目）來計算預測值。若核函數有代數參數，則通常使用軟體以擬合高斯過程的模型。

由於高斯過程是基於高斯分佈（[[正態分佈|正態分佈]]）的概念，故其以[[卡爾·弗里德里希·高斯|卡爾·弗里德里希·高斯]]為名。可以把高斯過程看成多元正態分佈的無限維廣義延伸。

高斯過程常用於[[概率模型|統計建模]]中，而使用高斯過程的模型可以得到高斯過程的屬性。举例来说，如果把一隨機過程用高斯過程建模，我们可以显示求出各種導出量的分布，这些导出量可以是例如隨機過程在一定範圍次數內的平均值，及使用小範圍採樣次數及採樣值進行平均值預測的誤差。

==定義==
一[[概率分布|統計學分佈]]定義為{X<sub>t</sub>, t∈T}是一个'''高斯过程'''，当且仅当对下标集合T的任意有限[[子集|子集]]t<sub>1</sub>,...,t<sub>k</sub>，

<math>X_{t_1, \ldots, t_k} = (X_{t_1}, \ldots, X_{t_k})</math>

是一个[[多元正态分布|多元正态分布]]，这等同于说<math>(X_{t_1}, \ldots, X_{t_k})</math>的任一[[线性组合|线性组合]]是一单变量[[正態分佈|正態分佈]]。更準確地，取樣函數''X''<sub>''t''</sub> 的任一線性[[泛函|泛函]]均會得出[[正態分佈|正態分佈]]。可以寫成''X'' ~ GP(''m'',''K'')，即[[隨機函數|隨機函數]]''X'' 以高斯過程（GP）方式分佈，且其平均數函數為''m'' 及其[[協方差函數|協方差函數]]為''K''。<ref>{{Cite book | last1 = Rasmussen | first1 = C. E. | chapter = Gaussian Processes in Machine Learning | doi = 10.1007/978-3-540-28650-9_4 | title = Advanced Lectures on Machine Learning | series = Lecture Notes in Computer Science | volume = 3176 | pages = 63–71 | year = 2004 | isbn = 978-3-540-23122-6 | pmid =  | pmc = }}</ref>當輸入向量''t''為二維或多維時，高斯過程亦可能被稱為[[高斯自由场|高斯自由场]]（{{le|高斯場|Gaussian random field|高斯場}}）。<ref name="prml">{{cite book |last=Bishop |first=C.M. |title= Pattern Recognition and Machine Learning |year=2006 |publisher=[[Springer_Science+Business_Media|Springer]] |isbn=0-387-31073-8}}</ref>

有些人<ref>{{cite book |last=Simon |first=Barry |title=Functional Integration and Quantum Physics |url=https://archive.org/details/functionalintegr0000simo |year=1979 |publisher=Academic Press}}</ref> 假設[[隨機變量|隨機變量]] ''X''<sub>''t''</sub> 平均為0；其可以在[[不失一般性|不失一般性]]的前提下簡化運算，且高斯過程的均方屬性可完全由[[協方差函數|協方差函數]]''K''得出。<ref name="seegerGPML">{{cite journal |last1= Seeger| first1= Matthias |year= 2004 |title= Gaussian Processes for Machine Learning|journal= International Journal of Neural Systems|volume= 14|issue= 2|pages= 69–104 |doi=10.1142/s0129065704001899}}</ref>

==协方差函数==
高斯過程的關鍵事實是它們可以完全由它們的二階統計量來定義.<ref name="prml"/>因此，如果高斯過程被假定為具有平均值零, defining 協方差函數完全定義了過程的行為。重要的是，這個函數的非負定性使得它的譜分解使用了 [[K-L_轉換|K-L轉換]]. 

可以通過協方差函數定義的基本方面是過程的[[平稳过程|平穩過程]], [[各向同性|各向同性]], [[光滑函数|光滑函數]] 和 [[周期函数|週期函數]]。<ref name="brml">{{cite book |last=Barber |first=David |title=Bayesian Reasoning and Machine Learning |url=http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage |year=2012 |publisher=[[劍橋大學出版社|Cambridge University Press]] |isbn=978-0-521-51814-7}}</ref><ref name="gpml">{{cite book |last=Rasmussen |first=C.E. |author2=Williams, C.K.I |title=Gaussian Processes for Machine Learning |url=http://www.gaussianprocess.org/gpml/ |year=2006 |publisher=[[MIT_Press|MIT Press]] |isbn=0-262-18253-X}}</ref>

[[平稳过程|平穩過程]]指的是過程的任何兩點x和x'的分離行為。如果過程是靜止的，取決於它們的分離x-x'，而如果非平穩則取決於x和x'的實際位置。例如，一個特例 [[Ornstein–Uhlenbeck_過程|Ornstein–Uhlenbeck 過程]], 一個 [[布朗运动|布朗運動]] 過程，是固定的。

如果過程僅依賴於 <math>|x-x'|</math>，x和x'之間的歐幾里德距離（不是方向），那麼這個過程被認為是各向同性的。同時存在靜止和各向同性的過程被認為是 [[同質與異質|同質與異質]];<ref name="PRP">{{cite book |last=Grimmett  |first=Geoffrey |author2=David Stirzaker|title= Probability and Random Processes| year=2001 |publisher=[[牛津大學出版社|Oxford University Press]] |isbn=0198572220}}</ref>在實踐中，這些屬性反映了在給定觀察者位置的過程的行為中的差異（或者更確切地說，缺乏這些差異）。

最終高斯過程翻譯為功能先驗，這些先驗的平滑性可以由協方差函數引起。如果我們預期對於“接近”的輸入點x和x'，其相應的輸出點y和y'也是“接近”，則存在連續性的假設。如果我們希望允許顯著的位移，那麼我們可以選擇一個更粗糙的協方差函數。行為的極端例子是Ornstein-Uhlenbeck協方差函數和前者不可微分和後者無限可微的平方指數。
週期性是指在過程的行為中引發週期性模式。形式上，這是通過將輸入x映射到二維向量<math>u(x) = (\cos(x), \sin(x))</math> 來實現的。

===常見的协方差函數===
[[File:Gaussian_process_draws_from_prior_distribution.png|thumbnail]]
一些常見的协方差函數:<ref name="gpml"/>
* 常值：<math> K_\operatorname{C}(x,x') = C </math>
*線性：<math> K_\operatorname{L}(x,x') =  x^T x'</math>
*高斯噪聲: <math> K_\operatorname{GN}(x,x') = \sigma^2 \delta_{x,x'}</math>
*平方指數: <math> K_\operatorname{SE}(x,x') = \exp \Big(-\frac{\|d\|^2}{2\ell^2} \Big)</math>
*[[Ornstein–Uhlenbeck过程|Ornstein–Uhlenbeck]] : <math> K_\operatorname{OU}(x,x') = \exp \left(-\frac{|d|} \ell \right)</math>
*Matérn: <math> K_\operatorname{Matern}(x,x') = \frac{2^{1-\nu}}{\Gamma(\nu)} \Big(\frac{\sqrt{2\nu}|d|}{\ell} \Big)^\nu K_\nu \Big(\frac{\sqrt{2\nu}|d|}{\ell} \Big)</math>
*定期: <math> K_\operatorname{P}(x,x') = \exp\left(-\frac{ 2\sin^2\left(\frac d 2 \right)}{\ell^2} \right)</math>
*有理二次方: <math> K_\operatorname{RQ}(x,x') =  (1+|d|^2)^{-\alpha}, \quad \alpha \geq 0</math>

== 相关 ==

* [[高斯自由场|高斯自由场]]

==註譯==
{{Reflist}}

{{Stochastic processes}}

{{Authority control}}

{{DEFAULTSORT:高斯过程}}
[[Category:随机过程|Category:随机过程]]