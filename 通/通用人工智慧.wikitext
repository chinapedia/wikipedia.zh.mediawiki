{{copyedit|time=2017-01-11T01:31:36+00:00}}
{{expand|time=2013-05-25T05:04:49+00:00}}
{{人工智能}}
'''強人工智慧'''（{{lang|en|Strong AI}}）或'''通用人工智慧'''（{{lang|en|Artificial General Intelligence}}）是具備與[[人類|人類]]同等[[智慧|智慧]]、或超越人類的[[人工智慧|人工智慧]]，能表現正常人類所具有的所有[[智能|智能]]行為。<ref name="K">{{Harv|Kurzweil|2005|p=260}} or see [http://crnano.typepad.com/crnblog/2005/08/advanced_human_.html Advanced Human Intelligence] {{Wayback|url=http://crnano.typepad.com/crnblog/2005/08/advanced_human_.html |date=20110630032301 }} where he defines strong AI as "machine intelligence with the full range of human intelligence."</ref>

==概述==
強人工智慧是[[人工智慧|人工智慧]]研究的主要目標之一，同時也是[[科幻小說|科幻小說]]和[[未來學|未來學]]家所討論的主要議題。相對的，弱人工智慧（applied AI，narrow AI，weak AI<ref>{{Cite web |url=http://www.open2.net/nextbigthing/ai/ai_in_depth/in_depth.htm |title=The Open University on Strong and Weak AI |access-date=2013-09-22 |archive-url=https://web.archive.org/web/20090925043908/http://www.open2.net/nextbigthing/ai/ai_in_depth/in_depth.htm |archive-date=2009-09-25 |dead-url=yes }}</ref>, artificial narrow intelligence, ANI<ref>AI創世紀, pp.68</ref>）只處理特定的[[解决問題|問題]]。<ref>Encyclopædia Britannica [http://www.britannica.com/eb/article-219086/artificial-intelligence Strong AI, applied AI, and cognitive simulation] {{Wayback|url=http://www.britannica.com/eb/article-219086/artificial-intelligence |date=20071015054758 }} or Jack Copeland [http://www.cs.usfca.edu/www.AlanTuring.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI02.html What is artificial intelligence?] {{Wayback|url=http://www.cs.usfca.edu/www.AlanTuring.net/turing_archive/pages/Reference%20Articles/what_is_AI/What%20is%20AI02.html |date=20070818125256 }} on AlanTuring.net</ref>弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了。由於過去的智能程式多是弱人工智慧，發現這個具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指'''通用人工智能'''（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。<ref>{{Harvnb|Newell|Simon|1976}}. This the term they use for "human-level" intelligence in the physical symbol system hypothesis.</ref>強人工智慧通常把人工智慧和[[意識|意識]]、感性、知識和自覺等人類的特徵互相連結。

因而，這樣的具備意識的強[[人工智慧|人工智慧]]是否存在？目前[[模擬|模擬]]出簡單的一個生物頭[[腦|腦]]已經不是不可能的事，一如[[化學|化學]]技術累積發展下，現在許多研發[[藥品|藥品]]已經使用計算機模型來推演藥物效果，以減少[[受試動物|受試動物]]的痛苦等。從前在使用[[電腦語言|電腦語言]]的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤，而近年來從電腦在[[摩爾定律|摩爾定律]]與[[神經科學|神經科學]]研究的協助下，透過在電腦上對[[生物|生物]][[神經元|神經元]]系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯[[學習|學習]]經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進[[思考|思考]]結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「[[思想|思想]]」上的議題，將還會一直是人們爭辯的對象，特別是在智能[[理性|理性]]與心理[[感性|感性]]部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。在一些能夠自動推理出最佳解的工具已經出現，如[[Google|Google]]旗下的深思公司（DeepMind）在此領域進展最多，成功開發出了能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表者這是一個可以透過自主「進化發展」的通用智慧。<ref >http://www.inside.com.tw/2016/02/21/the-superhero-of-artificial-intelligence-can-this-genius-keep-it-in-check {{Wayback|url=http://www.inside.com.tw/2016/02/21/the-superhero-of-artificial-intelligence-can-this-genius-keep-it-in-check |date=20180903151133 }} 人工智慧有多恐怖？聽聽「天才」Demis Hassabis 怎麼說！</ref>

{{or|強人工智能（定義見上文）不應該和[[约翰·罗杰斯·希尔勒|约翰·罗杰斯·希尔勒]]（John Searle）的'''強人工智能假說'''混淆。強人工智能是指一台計算機可以顯示的智能量，而''強人工智能假說''聲稱一台電腦作為一個人的智能行为，必須也必然有一個[[心靈|心靈]]和[[意識|意識]]。}}

==标准==
{{main|认知科学}}

人们提出过很多[[人工智能|人工智能]]的定义（例如能够通过[[图灵测试|图灵测试]]），但是没有一个定义能够得到所有人的认同<ref>AI founder [[John_McCarthy_(computer_scientist)|John McCarthy]] writes: "we cannot yet characterize in general what kinds of computational procedures we want to call intelligent." {{cite web| url=http://www-formal.stanford.edu/jmc/whatisai/node1.html| title=Basic Questions| last=McCarthy| first=John| authorlink=John McCarthy (computer scientist)| publisher=[[Stanford_University|Stanford University]]| year=2007| accessdate=2016-03-03| archive-date=2019-02-15| archive-url=https://web.archive.org/web/20190215015235/http://www-formal.stanford.edu/jmc/whatisai/node1.html| dead-url=no}} (For a discussion of some definitions of intelligence used by [[artificial_intelligence|artificial intelligence]] researchers, see [[philosophy_of_artificial_intelligence|philosophy of artificial intelligence]].)</ref> 然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：<ref>
This list of intelligent traits is based on the topics covered by major AI textbooks, including:
{{Harvnb|Russell|Norvig|2003}},
{{Harvnb|Luger|Stubblefield|2004}},
{{Harvnb|Poole|Mackworth|Goebel|1998}} and
{{Harvnb|Nilsson|1998}}.
</ref>
*[[自动推理|自动推理]]，使用一些策略来解决问题，在[[不确定性|不确定性]]的环境中作出决策；
*[[知识表示|知识表示]]，包括[[常识知识库|常识知识库]]；
*自动[[规划|规划]]；
*自主学习、创新；
*使用[[自然语言|自然语言]]进行沟通；
*以及，整合以上这些手段来达到同一个的目标；

还有一些重要的能力，包括机器[[知觉|知觉]]（例如[[计算机视觉|计算机视觉]]），以及在智能行为的世界中行动的能力（例如[[机器人|机器人]]移动自身和其他物体的能力）。<ref>Pfeifer, R. and Bongard J. C., How the body shapes the way we think: a new view of intelligence (The MIT Press, 2007). ISBN 0-262-16239-3</ref> 它可能包括探知与回避危险的能力。<ref>White, R. W. (1959). Motivation reconsidered: The concept of competence. Psychological Review, 66, 297-333</ref> 许多研究智能的交叉领域（例如[[认知科学|认知科学]]、[[机器智能|机器智能]]和[[决策|决策]]）试图强调一些额外的特征，例如[[想象力|想象力]]（不依靠预设而建构精神影像与概念的能力）<ref>{{Harvnb|Johnson|1987}}</ref> 以及[[自我决定论|自主性]]。<ref>deCharms, R. (1968). Personal causation. New York: Academic Press.</ref>
基于计算机的系统中的确已经存在许多这样的能力，例如{{le|计算创造性|computational creativity}}、[[自动推理|自动推理]]、[[决策支持系统|决策支持系统]]、[[机器人|机器人]]、[[进化计算|进化计算]]、[[智能代理|智能代理]]，然而并未达到人类的水平。

===检验强人工智能的操作性手段===
一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括[[阿兰·图灵|阿兰·图灵]]、{{le|本·格策尔|Ben Goertzel}}、{{le|尼尔斯·尼尔森|Nils John Nilsson}}，他们提出的测试包括：

1. 图灵测试（''图灵''）
: 同人類交流的試驗。参见 [[图灵测试|图灵测试]]。

2. 咖啡测试 (''沃兹尼亚克'')
: 生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。

3. 机器人学生测试 (''格策尔'')
:透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的[[東大AI|東大AI]]或是IBM參加搶答節目的[[沃森_(人工智能程序)|華生]]。

4.  雇员测试 (''尼尔森'')
: 測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。

这些测试检测了一系列必要的特质，包括推理和学习能力。<ref>{{cite web|last=Muehlhauser|first=Luke|title=What is AGI?|url=http://intelligence.org/2013/08/11/what-is-agi/|publisher=Machine Intelligence Research Institute|accessdate=1 May 2014|archive-date=2019-01-04|archive-url=https://web.archive.org/web/20190104021732/https://intelligence.org/2013/08/11/what-is-agi/|dead-url=no}}</ref>

== 强人工智能需要解决的问题 ==

人们将对于计算机来说最困难的问题，非正式地称为“人工智能完备”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。<ref name="Shapiro92">Shapiro, Stuart C. (1992). [http://www.cse.buffalo.edu/~shapiro/Papers/ai.pdf Artificial Intelligence] {{Wayback|url=http://www.cse.buffalo.edu/~shapiro/Papers/ai.pdf |date=20190513200757 }} In Stuart C. Shapiro (Ed.), ''Encyclopedia of Artificial Intelligence'' (Second Edition, pp. 54–57). New York: John Wiley. (Section 4 is on "AI-Complete Tasks".)</ref>  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。

人们假定人工智能完备的问题包括[[计算机视觉|计算机视觉]]、[[自然语言理解|自然语言理解]]，以及处理真实世界中的意外情况。<ref>Roman V. Yampolskiy. Turing Test as a Defining Feature of AI-Completeness . In Artificial Intelligence, Evolutionary Computation and Metaheuristics (AIECM) --In the footsteps of Alan Turing. Xin-She Yang (Ed.). pp. 3-17. (Chapter 1). Springer, London. 2013. http://cecs.louisville.edu/ry/TuringTestasaDefiningFeature04270003.pdf {{Wayback|url=http://cecs.louisville.edu/ry/TuringTestasaDefiningFeature04270003.pdf |date=20130522094547 }}</ref>目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要{{le|人类计算|human computation}}。这一点在某些方面很有用，例如通过[[验证码|验证码]]来判别人类和机器，以及在[[计算机安全|计算机安全]]方面用于阻止[[暴力破解法|暴力破解法]]。<ref>Luis von Ahn, Manuel Blum, Nicholas Hopper, and John Langford. [http://www.captcha.net/captcha_crypt.pdf CAPTCHA: Using Hard AI Problems for Security] {{Wayback|url=http://www.captcha.net/captcha_crypt.pdf |date=20160304001102 }}. In Proceedings of Eurocrypt, Vol. 2656 (2003), pp. 294-311.</ref><ref>{{cite journal | first = Richard | last = Bergmair | title = Natural Language Steganography and an "AI-complete" Security Primitive | id = {{citeseerx|10.1.1.105.129}} | date = January 7, 2006 }} (unpublished?)</ref>

==人工智能研究的主流==

=== 强人工智能研究的主流历史 ===
{{Main|人工智能史}}
现代人工智能研究开始于1950年代中期。<ref>{{Harvnb|Crevier|1993|pp=48–50}}</ref> 最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱[[司马贺|司马贺]]在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。”<ref>{{Harvnb|Simon|1965|p=96}} quoted in {{Harvnb|Crevier|1993|p=109}}</ref> 启发这一预言的是[[斯坦利·库布里克|斯坦利·库布里克]]和[[亚瑟·查理斯·克拉克|亚瑟·查理斯·克拉克]]创作的角色，[[HAL_9000|HAL 9000]]。当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱[[马文·闵斯基|马文·闵斯基]]，在创作HAL 9000的工作中， <ref>{{Cite web |url=http://mitpress.mit.edu/e-books/Hal/chap2/two1.html |title=Scientist on the Set: An Interview with Marvin Minsky |accessdate=2016-03-04 |archive-date=2012-07-16 |archive-url=https://web.archive.org/web/20120716182537/http://mitpress.mit.edu/e-books/Hal/chap2/two1.html |dead-url=no }}</ref> 他担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决”。<ref>Marvin Minsky to {{Harvtxt|Darrach|1970}}, quoted in {{Harvtxt|Crevier|1993|p=109}}.</ref> 

然而，到了1970年代早期，研究者们意识到他们远远低估了其中的困难。资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。<ref>The [[Lighthill_report|Lighthill report]] specifically criticized AI's "grandiose objectives" and led the dismantling of AI research in England. ({{Harvnb|Lighthill|1973}}; {{Harvnb|Howe|1994}}) In the U.S., [[DARPA|DARPA]] became determined to fund only "mission-oriented direct research, rather than basic undirected research". See {{Harv|NRC|1999}} under "Shift to Applied Research Increases Investment". See also {{Harv|Crevier|1993|pp=115–117}} and {{Harv|Russell|Norvig|2003|pp=21–22}}</ref> 在1980年代初，日本的[[第五代电脑|第五代电脑]]开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”。<ref>{{harvnb|Crevier|1993|pp=211}}, {{harvnb|Russell|Norvig|2003|p=24}} and see also {{Harvnb|Feigenbaum|McCorduck|1983}}</ref> 同时，[[专家系统|专家系统]]的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。<ref>{{Harvnb|Crevier| 1993|pp=161–162,197–203,240}}; {{harvnb|Russell|Norvig|2003|p=25}}; {{harvnb|NRC|1999|loc=under "Shift to Applied Research Increases Investment"}}</ref> 然而，人工智能的市场在1980年代晚期发生剧烈崩塌，而第五代计算机的目标从未实现。<ref>{{Harvnb|Crevier|1993|pp=209–212}}</ref> 再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言。<ref>As AI founder [[John_McCarthy_(computer_scientist)|John McCarthy]] writes "it would be a great relief to the rest of the workers in AI if the inventors of new general formalisms would express their hopes in a more guarded form than has sometimes been the case." {{cite web | url=http://www-formal.stanford.edu/jmc/reviews/lighthill/lighthill.html | title=Reply to Lighthill | last=McCarthy | first=John | authorlink=John McCarthy (computer scientist) | publisher=Stanford University | year=2000 | accessdate=2016-03-04 | archive-date=2008-09-30 | archive-url=https://web.archive.org/web/20080930164952/http://www-formal.stanford.edu/jmc/reviews/lighthill/lighthill.html | dead-url=no }}</ref>  并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。<ref>"At its low point, some computer scientists and software engineers avoided the term artificial intelligence for fear of being viewed as wild-eyed dreamers."{{cite news |first=John |last=Markoff |title=Behind Artificial Intelligence, a Squadron of Bright Real People |url=http://www.nytimes.com/2005/10/14/technology/14artificial.html?ei=5070&en=11ab55edb7cead5e&ex=1185940800&adxnnl=1&adxnnlx=1185805173-o7WsfW7qaP0x5/NUs1cQCQ |work= |publisher=The New York Times |date=2005-10-14 |accessdate=2007-07-30 }}</ref>

===今日的人工智能研究主流===
{{Main|人工智能}}

在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如[[人工神经网络|人工神经网络]]、[[机器视觉|机器视觉]]以及[[数据挖掘|数据挖掘]]。<ref>{{Harvnb|Russell|Norvig|2003|pp=25–26}}</ref> 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。

大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将{{le|智能体架构|agent architecture}}、{{le|认知架构|cognitive architecture}}或者{{le|包容式架构|subsumption architecture}}整合起来。[[汉斯·莫拉维克|汉斯·莫拉维克]]在1988年写道： <blockquote>"我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的[[常识知识库|常识知识库]]。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。"<ref>{{Harvnb|Moravec|1988|p=20}}</ref></blockquote> 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： <blockquote>"人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"<ref>Harnad, S. (1990) The Symbol Grounding Problem. Physica D 42: 335-346.</ref></blockquote>

===现代通用人工智能研究===

“通用人工智能”这一术语于 1997 年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在 2002 年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于 1984 年），以及[[艾伦·纽厄尔|艾伦·纽厄尔]]的 Soar 项目也被认为属于 AGI 的范畴。王培和本·格策尔将 2006 年的 AGI 研究活动描述为“创作出版物和早期的结果”。第一次 AGI 暑期学校于 2009 年，在中国厦门，厦门大学的人工大脑实验室和 OpenCog 所举办。在 2010 和 2011 年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。MIT 在 2018 年开设了 AGI 的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数 AI 研究者仅在 AGI 投入少量精力。不过，仍然有一小批计算机科学家活跃在 AGI 研究以及 AGI 会议中，他们的研究形形色色并富有开拓性。格策尔在他书中的介绍中说到，实现真正灵活的 AGI 所需要的时间从 10 年到一个世纪不等，但是，看起来 AGI 社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。

==理论==
{{Main|中文房間}}
“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家希尔勒认为不可能。

关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？希尔勒认为这是不可能的。他举了著名的[[中文房间|中文房间]]的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，希尔勒认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。

也有哲学家持不同的观点。[[丹尼爾·丹尼特|丹尼爾·丹尼特]]（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。

==風險==


==參見==
* [[人工智能史|人工智能史]]
* [[人工智能哲學|人工智能哲學]]
* [[人工智慧|人工智慧]]
* [[機器學習|機器學習]]
* [[人工意識|人工意識]]
* [[技术奇异点|技术奇异点]]
* [[無條件基本收入|無條件基本收入]]
* [[意识上传|意识上传]]（Mind uploading）

==參考資料==
{{reflist|2}}

[[Category:機器學習|Category:機器學習]]
[[Category:计算神经科学|Category:计算神经科学]]
[[fr:Intelligence_artificielle#Intelligence_artificielle_forte|fr:Intelligence artificielle#Intelligence artificielle forte]]