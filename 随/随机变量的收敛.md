[[概率论|概率论]]中有若干关于'''随机变量收敛'''（Convergence of random variables）的定义。研究一[[序列|列]][[随机变量|随机变量]]是否会收敛到某个[[极限_(数学)|极限]]随机变量是[[概率论|概率论]]中的重要内容，在[[统计学|统计概率]]和[[随机过程|随机过程]]中都有应用。在更广泛的数学领域中，随机变量的收敛被称为'''随机收敛'''，表示一系列本质上随机不可预测的事件所发生的模式可以在样本数量足够大的时候得到合理可靠的预测。各种不同的收敛定义实际上是表示预测时不同的刻画方式。

==简介==
正如一个数列可能收敛到某个极限量，一列函数可能收敛到某个极限函数一样，随机收敛指的是一系列随机变量<math>\left( X_n ; \; n \in \mathbb{N} \right)</math>在''n''趋向于无穷大时，会越来越接近某个固定的极限。这个极限可能是指：
#<math>X_n </math>趋向某个固定的数；
#<math>X_n </math>趋向某个确定函数的输出值；
#<math>X_n </math>的[[概率分布|概率分布]]越来越接近某个特定的随机变量的概率分布；
#<math>X_n </math>和某个特定随机变量的差别的平均值（[[数学期望|数学期望]]值）趋向于0；
#<math>X_n </math>和某个特定随机变量的差别的[[方差|方差]]趋向于0。
等等。这些不同的极限的定义，可以严格地写成不同的收敛方式的定义。

==依概率1收敛==
依概率1收敛又称为几乎处处收敛，其定义接近于函数[[逐点收敛|逐点收敛]]的定义。事实上，由于随机变量的本质是由样本空间<math>\mathit{\Omega}</math>到取值空间<math>\mathfrak{B}</math>上的函数。因此，给定一个[[概率空间|概率空间]] <math>\left( \mathit{\Omega},  \mathcal{F},   \mathbb{P} \right) </math>中的一列 随机变量<math>\left( X_n ; n \in \mathbb{N} \right)</math>，考虑事件<math>A_X = \left\{ \omega ; \; \lim_{n \to \infty} X_n(\omega) = X(\omega) \right\}</math>。如果存在一个随机变量<math>X</math>，使得事件<math>A_X  </math>的概率为1，那么就称随机变量序列 <math>\left( X_n ; n \in \mathbb{N} \right)</math> 依概率1收敛到 <math>X</math>（或称 <math>\left( X_n ; n \in \mathbb{N} \right)</math> 几乎处处收敛到 <math>X</math>），记作：
:<math>X_n \xrightarrow{a.s.} X</math> 或  <math>\mathbb{P} \left( \lim_{n \to \infty} X_n = X \right) = 1</math>
当取值空间<math>\mathfrak{B}</math>是一般的实数空间<math>\mathbb{R}</math>时，依概率1收敛的意义是：
:对任意的正实数<math>\varepsilon > 0</math>，<math>\mathbb{P} \Big( \liminf \big\{\omega \in \Omega : | X_n(\omega) - X(\omega) | < \varepsilon \big\} \Big) = 1</math>
当空间<math>\mathfrak{B}</math>是[[度量空间|度量空间]] (''S'', ''d'') 的时候，依概率1收敛的意义是：

: <math>\mathbb{P}\Big( \omega\in\Omega:\, d\big(X_n(\omega),X(\omega)\big)\, \xrightarrow[n\to\infty] \, \, 0 \Big) = 1  </math>

==依概率收敛==
{{main|依概率收敛}}
设<math>(X_n ; \, n \in \mathbb{N})</math> 是一个随机变量序列，<math>X</math>是一个随机变量。如果对于任意的正实数<math>\epsilon > 0</math>，都有：
:<math>\lim_{n \to \infty} \mathbb{P} ( |X - X_n| \ge \epsilon) = 0</math>
那么称序列<math> (X_n ; \, n \in \mathbb{N}) </math> 依概率收敛到<math>X</math>，记作：<math>X_n \xrightarrow[n \to \infty]{\mathbb{P}} X</math>

如果<math>(X_n ; \, n \in \mathbb{N})</math>的取值空间是一个[[可分空间|可分]]度量空间(''S'', ''d'')，那么依概率收敛的定义为<ref>{{harvnb|Dudley|2002|loc=Chapter 9.2, page 287}}</ref>：
: <math>
     \mathbb{P}  \big(d(X_n,X)\geq\varepsilon\big) \to 0, \quad \forall\varepsilon>0.
  </math>
依概率收敛和依概率1收敛的定义有相似之处，但本质上，依概率1收敛是比依概率收敛更“强”的收敛性质。如果一列随机变量依概率1收敛到某个极限，那么它必然也依概率收敛到这个极限，但反之则不然。一个实数上的例子是：设概率空间 <math>\left( \mathit{\Omega},  \mathcal{F},   \mathbb{P} \right) </math>是[[区间|区间]]<math> \mathit{\Omega} = [0,1)</math>上的一个[[连续型均匀分布|连续型均匀分布]]<math>\mathbb{P}=\mathbf{U} </math> 。一个随机变量序列<math>(X_n ; \, n \in \mathbb{N})</math>定义为：
:<math>X_1 = \mathbf{1}_{ \left\{ \omega \in [0,1) \right\} } =  \mathbf{1} </math>
:<math>X_2 = \mathbf{1}_{  \left\{ \omega \in [0,\frac12 ) \right\} } , \qquad X_3 = \mathbf{1}_{ \left\{ \omega \in [\frac12 ,1) \right\}}</math>
:<math>X_4 = \mathbf{1}_{  \left\{ \omega \in [0,\frac14 ) \right\} } , \qquad X_5 = \mathbf{1}_{ \left\{ \omega \in [\frac14 , \frac12 ) \right\}}, \qquad X_6 = \mathbf{1}_{ \left\{ \omega \in [\frac12 , \frac34 ) \right\}} , \qquad X_7 = \mathbf{1}_{ \left\{ \omega \in [\frac34 ,1) \right\}}</math>
<br> 

:<math> \cdots \;</math>
<br>
:<math>\forall (k, m ) \in \mathbb{N}, \, \, 0 \leqslant k \leqslant  2^m-1 , \, \, X_{2^m+k} = \mathbf{1}_{ \left\{ \omega \in [\frac{k}{2^m},\frac{k+1}{2^m}) \right\} }</math>
由于
:<math>\forall  2^m \leqslant n \leqslant 2^{m+1}-1 , \, \, \mathbb{P} \left( | X_{n} - 0 |  \geqslant \varepsilon \right) = \frac{1}{2^m}</math>
所以
:<math>X_n \xrightarrow{\mathbb{P}} 0</math>，
另一方面，考虑<math>X_{2^m}</math>到<math>X_{2^{m+1} -1}</math>这一组随机变量，它们取值为1的集合的并集恰好是总区间，因此对每一个<math>\omega \in [0,1)</math>，总会有<math>X_{2^m}</math>到<math>X_{2^{m+1} -1}</math>之间的某个变量<math>X_{2^m + k_m}</math>，使得
:<math>X_{2^m + k_m}(\omega) = 1</math> 
所以，对任意一个<math>\omega \in [0,1)</math>，
:<math> \lim_{n \to \infty} | X_{n}(\omega) - 0 | \neq 0</math>，
即是说，<math>(X_n ; \, n \in \mathbb{N})</math> 并不依概率1收敛到0。从例子中可以看到，依概率收敛比依概率1收敛更为宽松的地方是：当''n''趋于无穷大的时候，只要偏离极限函数的<math>\omega </math>（即是集合<math> \left\{ \omega_n ; \, | X_{n}(\omega_n) - X(\omega_n) | \geqslant \varepsilon \right\}</math>中的<math>\omega_n </math>）“足够少”，就能使得依概率收敛成立了，这些<math>\omega_n </math>的集合可以随着''n''不同而不同；而依概率1收敛则要求<math>\omega_n </math>的集合固定地缩减至一个概率为0的集合。因此，依概率1收敛要比依概率收敛更为严格。

===性质===
<ul>
<li>依概率收敛蕴含依分布收敛：一个依概率收敛的随机变量序列必然也依分布收敛到同一个极限。
<li>在离散概率空间中，依概率收敛和依概率1收敛是等价的。
<li>依分布收敛蕴含依概率收敛当且仅当依分布收敛的极限是一个常数。
<li>[[连续映射定理|连续映射定理]]说明：对任意连续函数<math>g</math>，如果随机变量序列<math>(X_n ; \, n \in \mathbb{N})</math>依概率收敛到<math>X</math>，那么序列<math>(g(X_n) ; \, n \in \mathbb{N})</math>依概率收敛到<math>g(X)</math>
<li>依概率收敛定义了确定概率空间上的随机变量空间上的一个拓扑。这个拓扑可以用凯范度量进行度量化<ref>{{harvnb|Dudley|2002|page=289}}</ref>。
: <math style="position:relative;top:.3em">
    d(X,Y) = \inf\!\big\{ \varepsilon>0:\ \Pr\big(|X-Y|>\varepsilon\big)\leq\varepsilon\big\}.
  </math>
</ul>

==平方平均收敛与<math> \mathbf{L}^{p} </math>收敛==
另一种收敛的定义与[[测度|测度]]的积分有关。在积分理论中，如果两个函数<math>f </math> 和<math>g </math>满足<math>\int_{\mathcal{I}} (f-g)^2 d\mu = 0 </math>，那么这两个函数在关于测度<math>\mu </math>的平方可积空间中相等。随机变量的平方平均收敛与此相似：如果对平方可积的随机变量序列<math>(X_n ; \, n \in \mathbb{N})</math>，存在随机变量<math>X</math>，使得<math>\lim_{n\to \infty} \mathbb{E}\left[ (X_n - X)^2\right] = 0</math>，那么就说序列<math> (X_n ; \, n \in \mathbb{N}) </math> 平方平均收敛到<math>X</math>，记作：
<center><math>X_n \xrightarrow{\mathbf{L}^2} X</math></center>
由于<math> \mathbf{L}^{2} </math>空间是[[完备空间|完备]]的，极限<math>X</math>也一定平方可积。

对于更一般的<math> \mathbf{L}^{p} </math>空间，也有类似的定义：如果对 <math> \mathbf{L}^{p} </math>空间中的随机变量序列<math>(X_n ; \, n \in \mathbb{N})</math>，存在<math> \mathbf{L}^{p} </math>中的随机变量<math>X</math>，使得<math>\lim_{n\to \infty} \mathbb{E}\left[ |X_n - X|^p\right] = 0</math>，那么就说序列<math> (X_n ; \, n \in \mathbb{N}) </math>依<math> \mathbf{L}^{p} </math>收敛到<math>X</math>，记作：
<center><math>X_n \xrightarrow{\mathbf{L}^p} X</math></center>

当常数<math>p=1</math>时，也称为平均收敛。

==依分布收敛==
依分布收敛是最宽松的收敛方式之一。这种收敛不要求查看每个<math>\omega</math>，只要求序列的分布趋向于某个极限。直觉上，一个随机变量序列<math>(X_n ; \, n \in \mathbb{N})</math>依分布收敛到某个随机变量<math>X</math>，如果：
:对所有的<math>a</math>，都有<math>\mathbb{P} ( X_n \leqslant a) \rightarrow \mathbb{P} ( X \leqslant a)</math>。
更严格的定义是探讨随机变量<math>X_n</math>的[[累积分布函数|累积分布函数]]<math>F_n(x) = \mathbb{P} ( X_n \leqslant x)</math>。设有[[实数|实值]]的随机变量序列 <math>(X_n ; \, n \in \mathbb{N})</math> 和某个随机变量<math>X</math>（其累积分布函数为 <math>F(x) </math>），如果对<math>F(x) </math>的每个连续点<math>x</math>，都有<math>  \lim_{n\to\infty} F_n(x) = F(x)</math>，那么就说 <math>(X_n ; \, n \in \mathbb{N})</math>依分布收敛到某个随机变量<math>X</math>。记作：
<center><math>X_n \xrightarrow[n\to \infty]{\mathcal{D}} X</math> ，<math>X_n \xrightarrow[n\to \infty]{\mathit{d}} X</math> 或 <math>X_n \xrightarrow[n\to \infty]{\mathcal{L}} X</math> </center>
由于依分布收敛只和随机变量的分布相关，所以也可以称一系列随机变量（依分布）收敛于某个分布。设<math> \mathcal{L}_X </math>是极限<math>X</math>的分布，那么依分布收敛也可以记作：
<center><math> X_n \ \xrightarrow{d}\ \mathcal{L}_X, \, \, X_n \rightsquigarrow X </math> 或 <math> \mathcal{L}(X_n)\to\mathcal{L}(X)</math> </center>
例如一个随机变量序列<math>(X_n ; \, n \in \mathbb{N})</math>依分布收敛到标准正态分布，就可以记作：
:<math> X_n \ \xrightarrow{d}\ \mathcal{N}(0,1).</math>

===性质===

<ul>
<li> 作为最弱的收敛方式之一，依分布收敛无法推出其它的收敛方式。对于存在[[概率密度函數|概率密度函數]]的连续型随机变量序列，依分布收敛并不能推出其概率密度函数也同样收敛。例如对于概率密度函數为<math>f_n(x) = \left( 1- \cos(2 \pi n x) \right)\mathbf{1}_{x \in (0,1) }</math>的随机变量序列，其依分布收敛到均匀分布的随机变量，但其概率密度函数不收敛<ref>{{harvnb|Romano|Siegel|1985|loc=Example 5.26}}</ref>。

<li>依分布收敛的等价定义：一个随机变量序列<math>(X_n ; \, n \in \mathbb{N})</math>依分布收敛到某个随机变量<math>X</math>和以下命题中的任意一个等价：
* 对所有的[[有界函数|有界]][[连续函数|连续函数]]<math>f</math>，都有： <math>\mathbb{E}[f(X_n)] \rightarrow  \mathbb{E}[f(X)]</math>；
* 对所有具有[[利普希茨連續|利普希茨連續]]性质的函数<math>f</math>，都有： <math>\mathbb{E}[f(X_n)] \rightarrow  \mathbb{E}[f(X)]</math> ；
* 对所有上有界的[[上半连续|上半连续]]函数<math>f</math>，都有： <math> \limsup \mathbb{E}[f(X_n)] \leqslant \mathbb{E}[f(X)]</math> ；
* 对所有下有界的[[下半连续|下半连续]]函数<math>f</math>，都有： <math> \liminf \mathbb{E}[f(X_n)] \geqslant \mathbb{E}[f(X)]</math>  ；
* 对所有[[闭集|闭集]]<math>C</math>，都有： <math> \limsup_{n \to \infty} \mathbb{P}\left( X_n \in C \right) \leqslant  \mathbb{P}\left( X \in C \right)  </math> ；
* 对所有[[开集|开集]]<math>U</math>，都有： <math> \liminf_{n \to \infty} \mathbb{P}\left( X_n \in U \right) \geqslant  \mathbb{P}\left( X \in U \right)  </math> ；
* 对关于<math>X</math>的所有[[连续集|连续集]]<math>A</math>，都有： <math> \lim_{n \to \infty} \mathbb{P}\left( X_n \in A \right) = \mathbb{P}\left( X \in A \right)  </math> 。

<li>'''[[连续映射定理|连续映射定理]]'''说明，对于连续函数''g''(·)，如果随机变量序列 <math>(X_n ; \, n \in \mathbb{N})</math>依分布收敛到随机变量<math>X</math>，那么
<math>(g(X_n) ; \, n \in \mathbb{N})</math>也依分布收敛到随机变量<math>g(X)</math>。
<li>'''[[列维连续性定理|列维连续性定理]]'''： 随机变量序列<math>(X_n ; \, n \in \mathbb{N})</math>依分布收敛到某个随机变量<math>X</math> 当且仅当对应的[[特征函数|特征函数]]序列<math>(\varphi_n(x) ; \, n \in \mathbb{N})</math>[[逐点收敛|逐点收敛]]到某个在0处连续的函数<math> \varphi </math>（此时随机变量<math>X</math>的分布为<math> \varphi </math>）。

<li> [[列维-普罗科洛夫度量|列维-普罗科洛夫度量]]是依分布收敛的[[度量化|度量化]]结果。

</ul>

== 关系 ==
各个收敛的定义有强弱之分。一个收敛性强于另一个是指从前者可以推出后者。例如依概率收敛强于依分布收敛，即是说如果一列随机变量依概率收敛到某个极限，那么必定也依分布收敛到这个极限。具体来说，收敛性的强弱关系可以用下图来表示：
: <math>\begin{matrix}
  \xrightarrow{L^r}  & \underset{r>s\geq1}{\Rightarrow} &  \xrightarrow{L^s}  &             & \\
                     &                                  &     \Downarrow      &             & \\
  \xrightarrow{a.s.} &            \Rightarrow           & \xrightarrow{\ p\ } & \Rightarrow & \xrightarrow{\ d\ }
  \end{matrix}</math>

<ul>
<li> {{anchor|propA1}}
依概率1收敛可以推出依概率收敛<ref name="vdv2">{{harvnb|van der Vaart|1998|loc=Theorem 2.7}}</ref>：
: <math>
    X_n\ \xrightarrow{a.s.}\ X  \quad\Rightarrow\quad  X_n\ \xrightarrow{p}\ X
  </math>

<li> {{anchor|propA1}}
依概率收敛可以推出存在依概率1收敛的子列<math>(k_n)</math><ref>{{cite book|last=Gut|first=Allan|title=Probability: A graduate course|year=2005|publisher=Springer|location=Theorem 3.4|isbn=0387228330}}</ref>：
: <math>    X_n\ \xrightarrow{p}\ X  \quad\Rightarrow\quad  X_{k_n}\ \xrightarrow{a.s.}\ X  </math>

<li> {{anchor|propA2}}
依概率收敛可以推出依分布收敛<ref name="vdv2"/>：
: <math>    X_n\ \xrightarrow{p}\ X \quad\Rightarrow\quad  X_n\ \xrightarrow{d}\ X  </math>

<li> {{anchor|propA3}}
对任意的<math>r>0</math>，<math>\mathbf{L}^r</math>-收敛可以推出依概率收敛：
: <math>
    X_n\ \xrightarrow{L^r}\ X  \quad\Rightarrow\quad  X_n\ \xrightarrow{p}\ X
  </math>
<li> {{anchor|propA4}}
如果<math>r > s \geqslant 1</math>，那么<math>\mathbf{L}^r</math>-收敛可以推出<math>\mathbf{L}^s</math>-收敛：
: <math>    X_n\ \xrightarrow{L^r}\ X  \quad\Rightarrow\quad  X_n\ \xrightarrow{L^s}\ X,  </math> 

<li> {{anchor|propB1}}
如果序列<math>\left( X_n ; \, n \in \mathbb{N} \right)</math>依分布收敛到常数''c''，那么它也依概率收敛到常数''c''<ref name="vdv2"/>：
: <math>
    X_n\ \xrightarrow{d}\ c \quad\Rightarrow\quad X_n\ \xrightarrow{p}\ c,
  </math>

<li> {{anchor|propB2}}
如果序列<math>\left( X_n ; \, n \in \mathbb{N} \right)</math>依分布收敛到随机变量<math>X</math>，并且<math> X_n </math>和<math> Y_n </math>的差依概率收敛到0，那么<math> Y_n </math> 也依分布收敛到随机变量<math>X</math><ref name="vdv2"/>：
: <math>    X_n\ \xrightarrow{d}\ X,\ \ |X_n-Y_n|\ \xrightarrow{p}\ 0\  \quad\Rightarrow\quad  Y_n\ \xrightarrow{d}\ X  </math>

<li> {{anchor|propB3}}
如果序列<math>\left( X_n ; \, n \in \mathbb{N} \right)</math>依分布收敛到随机变量<math>X</math>，并且 序列<math>\left( Y_n ; \, n \in \mathbb{N} \right)</math>依分布收敛到常数''c''，那么向量列<math>\left( (X_n, Y_n) ; \, n \in \mathbb{N} \right)</math>依分布收敛到随机变量<math>(X,c)</math><ref name="vdv2"/>：
: <math>    X_n\ \xrightarrow{d}\ X,\ \ Y_n\ \xrightarrow{d}\ c\ \quad\Rightarrow\quad (X_n,Y_n)\ \xrightarrow{d}\ (X,c)  </math> 
==参见==
*[[勒贝格控制收敛定理|勒贝格控制收敛定理]]
*[[单调收敛定理|单调收敛定理]]

== 参考资料 ==
{{reflist}}

===参考书籍===
{{refbegin}}
* {{cite book
  | last = Bickel
  | first = Peter J.
  | coauthors = Klaassen, Chris A.J.; Ritov, Ya’acov; Wellner, Jon A.
  | year = 1998
  | title = Efficient and adaptive estimation for semiparametric models
  | publisher = Springer-Verlag
  | location = New York
  | isbn = 0387984739
  | ref = CITEREFBickelKlaassenRitovWellner1998
  }}
* {{cite book
  | last = Billingsley
  | first = Patrick
  | title = Probability and Measure
  | year = 1986
  | edition = 2nd
  | series = Wiley Series in Probability and Mathematical Statistics
  | publisher = Wiley
  }}
* {{cite book
  | last = Billingsley
  | first = Patrick
  | year = 1999
  | title = Convergence of probability measures
  | publisher = John Wiley & Sons
  | edition = 2nd
  | pages = 1–28
  | isbn = 0471197459
  }}
* {{cite book
  | last = Dudley
  | first = R.M.
  | year = 2002
  | title = Real analysis and probability
  | publisher = Cambridge University Press
  | location = Cambridge, UK
  | isbn = 052180972X
  }}
* {{cite book
  | first = G.R.
  | last = Grimmett
  | coauthors = Stirzaker, D.R.
  | year = 1992
  | title = Probability and random processes
  | edition = 2nd
  | publisher = Clarendon Press, Oxford
  | pages = 271–285
  | isbn = 0-19-853665-8
  }}
* {{cite book
  | first = M.
  | last = Jacobsen
  | year = 1992
  | title = Videregående Sandsynlighedsregning (Advanced Probability Theory)
  | edition = 3rd
  | publisher = HCØ-tryk, Copenhagen
  | pages = 18–20
  | isbn = 87-91180-71-6
  }}
* {{cite book
| last1 = Ledoux
| first1 = Michel
| last2 = Talagrand | first2 = Michel | author2-link = Michel Talagrand
  | title = Probability in Banach spaces
  | publisher = Springer-Verlag
  | location = Berlin
  | year = 1991
  | pages = xii+480
  | isbn = 3-540-52013-9
  | mr = 1102015 
  }}
* {{cite book
  | last = Romano
  | first = Joseph P.
  | coauthor = Siegel, Andrew F.
  | year = 1985
  | title = Counterexamples in probability and statistics
  | publisher = Chapman & Hall
  | location = Great Britain
  | isbn = 0412989018
  | ref = CITEREFRomanoSiegel1985
  }}
* {{cite book
  | last = van der Vaart
  | first = Aad W.
  | coauthor = Wellner, Jon A.
  | year = 1996
  | title = Weak convergence and empirical processes
  | publisher = Springer-Verlag
  | location = New York
  | isbn = 0387946403
  | ref = CITEREFvan_der_VaartWellner1996
  }}
* {{cite book
  | last = van der Vaart
  | first = Aad W.
  | title = Asymptotic statistics
  | year = 1998
  | publisher = Cambridge University Press
  | location = New York
  | isbn = 9780521496032
  | ref = CITEREFvan_der_Vaart1998
  }}
* {{cite book
  | last = Williams
  | first = D.
  | title = Probability with Martingales
  | publisher = Cambridge University Press
  | year = 1991
  | isbn = 0521406056
  }}
* {{cite book
  | last = Wong
  | first = E.
  | coauthors = Hájek, B.
  | title = Stochastic Processes in Engineering Systems
  | publisher = Springer–Verlag
  | location = New York
  | year = 1985
  }}
{{refend}}

[[Category:概率论|Category:概率论]]
[[Category:统计学|Category:统计学]]
[[Category:随机过程|Category:随机过程]]
[[Category:极限|Category:极限]]