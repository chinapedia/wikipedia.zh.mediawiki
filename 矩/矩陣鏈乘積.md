'''矩阵链乘积'''（{{lang-en|Matrix chain multiplication}}，或{{lang|en|Matrix Chain Ordering Problem}}，{{lang|en|MOCP}}）是可用[[動態規劃|動態規劃]]解决的最佳化问题。給定一序列矩陣，期望求出[[矩陣乘法|相乘這些矩陣]]的最有效方法。此問題並不是真的去''執行''其乘法，而只是決定執行乘法的順序而已。

因為矩陣乘法具有[[結合律|結合律]]，所有其運算順序有很多種選擇。換句話說，不論如何括號其乘積，最後結果都會是一樣的。例如，若有四個矩陣<math>A</math>、<math>B</math>、<math>C</math>和<math>D</math>，將可以有：

<math>ABCD = (AB)(CD) = A(BCD) = A(BC)D = ...</math>

但括號其乘積的順序是會影響到需計算乘積所需簡單算術運算的數目，即其''效率''。例如，設<math>A</math>為一<math>10\times 30</math>矩陣，<math>B</math>為<math>30\times 5</math>矩陣與<math>C</math>為<math>5\times 60</math>矩陣，則：

* <math>(AB)C</math>有<math>(10\times 30\times 5)+(10\times 5\times 60)=1500+3000=4500</math>個運算
* <math>A(BC)</math>有<math>(30\times 5\times 60)+(10\times 30\times 60)=9000+18000=27000</math>個運算

明顯地，第一種方式要有效多了。既然已確認過此問題了，那要如何決定''n''個矩陣相乘的最佳順序呢？可以比較每一順序的運算量（使用蠻力），但這將需要時間[[大O符號|O]](2<sup>''n''</sup>)，是一種非常慢且對大''n''不實在的方法。那解決方法，如我們將看到的，是將問題分成一套相關的子問題。以解答子問題一次而再使用其解答數次，即可以徹底地得出其所需時間。此一方法稱為[[動態規劃|動態規劃]]。

== 動態規劃的算法 ==
一開始，假定真的想知道的是乘完矩陣所需的最小成本，或算術運算的最小量。若只有兩個矩陣相乘，則只會有一種方法去乘它們，所有其最小成本為乘積的成本。一般地，可以用下列的[[遞迴|遞迴演算法]]求出最小成本：

* 取得矩陣的序列且將其分成兩個子序列。
* 找出乘完每一子序列的最小成本。
* 將成本加起來，並加上兩個結果矩陣相乘的成本。
* 在每一矩陣序列可分開的位置運作，並取其最小值。

例如，若有四矩陣<math>ABCD</math>，計算每一分法<math>(A)(BCD)</math>、<math>(AB)(CD)</math>和<math>(ABC)(D)</math>所需的成本，遞迴計算<math>ABC</math>、<math>AB</math>、<math>CD</math>和<math>BCD</math>的最小成本。然後選擇最好的一個。這方法不只找出其最小成本，也決定做這乘積的最好辦法：儘只是以最小總成本分開，並對每一因子做相同的事情。

不幸地，若真實作此演算法，將會發現它和比較每一順序的運算量一樣慢！發生什麼事了嗎？答案是因為多做了許多多餘的工作。例如，上述遞迴計算了<math>ABC</math>與<math>AB</math>以找到最小成本，但在找出<math>ABC</math>的最小成本時，亦需要去找出<math>AB</math>的最小成本。當遞迴較深時，會有越來越多這種不需要的重複產生。

一簡單的解決方法為[[備忘錄法|備忘錄法]]：每次計算乘完一特定子序列所需的最小成本時，儲存其數值。若再遇到相同子序列時，便只需讀取已存的答案，而不需要再重計算一次。當<math>n</math>個矩陣會有約<math>n^2</math>個不同的子序列，其所需空間是合理的。可證明此一簡單的技術可使得運算時間由<math>O(2^n)</math>降至<math>O(n^3)</math>，使得其對實際應用有足夠的效率。此為由上而下動態規劃。

偽代碼：
<pre>
Matrix-Chain-Order(int p[])
{
    n = p.length - 1;
    for (i = 1; i <= n; i++) 
       m[i,i] = 0;

    for (l=2; l<=n; l++) { // l is chain length
        for (i=1; i<=n-l+1; i++) {
            j = i+l-1;
            m[i,j] = MAXINT;
            for (k=i; k<=j-1; k++) {
                q = m[i,k] + m[k+1,j] + p[i-1]*p[k]*p[j];//Matrix Ai has the dimension  p[i-1] x p[i].
                if (q < m[i,j]) {
                    m[i,j] = q;
                    s[i,j] = k;
                }
            }
        }
    }
}
</pre>
另一種解決方法是預先知道需要計算的成本並事先計算它們。其運作如下：
* 對每一由2至矩陣數目<math>n</math>的<math>k</math>：
** 計算長度<math>k</math>的子序列的最小成本，使用已計算過的成本。如此做過之後，將可以得到整個序列的最小成本。即使其亦需要<math>O(n^3)</math>的時間，此一方法有其實作的優點，它不需要使用遞迴，不需要測試是否為已計算的值，而且可以丟掉一些已不需要的結果來節省空間。此為由下而上動態規劃：可解答此問題的第二種方法。

== 更有效率的算法 ==
1981年由Hu與Shing發表了時間複雜度<math>O(n\log(n))</math>的算法。<ref>{{cite techreport
  | last1 = Hu
  | first1 = TC
  | last2 = Shing
  | first2 = MT
  | title = Computation of Matrix Chain Products, Part I, Part II
  | number = STAN-CS-TR-81-875
  | institution = Stanford University, Department of Computer Science
  | year = 1981
  | url = http://infolab.stanford.edu/pub/cstr/reports/cs/tr/81/875/CS-TR-81-875.pdf
  | format = [[Portable_Document_Format|PDF]]
}}
</ref><ref>
{{cite journal
  | last1 = Hu
  | first1 = TC
  | last2 = Shing
  | first2 = MT
  | title = Computation of Matrix Chain Products, Part I
  | journal = SIAM Journal on Computing
  | volume = 11
  | issue = 2
  | pages = 362–373
  | publisher = Society for Industrial and Applied Mathematics
  | year = 1982
  | url = http://www.cs.ust.hk/mjg_lib/bibs/DPSu/DPSu.Files/0211028.pdf
  | format = [[Portable_Document_Format|PDF]]
  | issn = 0097-5397
  | doi=10.1137/0211028
}}
</ref><ref>
{{cite journal
  | last1 = Hu
  | first1 = TC
  | last2 = Shing
  | first2 = MT
  | title = Computation of Matrix Chain Products, Part II
  | journal = SIAM Journal on Computing
  | volume = 13
  | issue = 2
  | pages = 228–251
  | publisher = Society for Industrial and Applied Mathematics
  | year = 1984
  | url = http://www.cs.ust.hk/mjg_lib/bibs/DPSu/DPSu.Files/0213017.pdf
  | format = [[Portable_Document_Format|PDF]]
  | issn = 0097-5397
  | doi=10.1137/0213017
}}
</ref>

== 此算法在其他领域的用途 ==

==實作==
* 於[https://web.archive.org/web/20061216113204/http://alexle.net/stuff/dynamic-programming-matrix-multiplication/ Alex Le's Blog]上的[[JavaScript|JavaScript]]實作
* 另一於[https://web.archive.org/web/20061019173224/http://docs.linux.cz/programming/algorithms/Algorithms-Morris/mat_chain.html Data Structures and Algorithms]上的[[JavaScript|JavaScript]]實作

== 引用 ==

* Viv. [http://citeseer.ist.psu.edu/268391.html Dynamic Programming]. A 1995 introductory article on dynamic programming.
* Cormen, T.H., C.E. Leiserson, and R.L. Rivest. ''Introduction to Algorithms''. McGraw-Hill, New York, NY. 1990. ISBN 0-262-03293-7. Section 15.2. The most popular reference where people encounter this algorithm.
* G. Baumgartner, D. Bernholdt, D. Cociorva, R. Harrison, M. Nooijen, J. Ramanujam and P. Sadayappan. [http://citeseer.ist.psu.edu/610463.html A Performance Optimization Framework for Compilation of Tensor Contraction Expressions into Parallel Programs]. ''7th International Workshop on High-Level Parallel Programming Models and Supportive Environments'' (HIPS '02). Fort Lauderdale, Florida. 2002.
* Heejo Lee, Jong Kim, Sungje Hong, and Sunggu Lee. [http://citeseer.ist.psu.edu/lee97parallelizing.html Parallelizing matrix chain products]. ''Tech. Rep.'' CS-HPC-97003, Pohang University of Science and Technology. 1997.
* [[Thomas_H._Cormen|Thomas H. Cormen]], [[Charles_E._Leiserson|Charles E. Leiserson]], [[Ronald_L._Rivest|Ronald L. Rivest]], and [[Clifford_Stein|Clifford Stein]]. ''[[Introduction_to_Algorithms|Introduction to Algorithms]]'', Second Edition. MIT Press and McGraw-Hill, 2001. ISBN 0-262-03293-7. Section 15.2: Matrix-chain multiplication, pp.331–339.

[[Category:最优化算法|Category:最优化算法]]
[[Category:矩陣論|J]]