在[[概率|概率]]的数学理论中，非正式地说，一个[[随机过程|随机过程]]的'''熵率'''或'''信源信息率'''是在一个随机过程的平均信息的时间密度。对于一个索引[[可数|可数]]的随机过程，熵率 Η(''X'') 是 ''n'' 个 ''X''<sub>''k''</sub> 过程作为成员的联合熵，在 ''n'' [[极限_(数学)|趋向]][[无穷|无穷]]时的极限：

:<math>\Eta(X) = \lim_{n \to \infty} \frac{1}{n} \Eta(X_1, X_2, \dots X_n)</math>

前提是该极限存在。另一种相关量为：

:<math>\Eta'(X) = \lim_{n \to \infty} \Eta(X_n|X_{n-1}, X_{n-2}, \dots X_1)</math>

对于[[平稳过程|强平稳]]随机过程， <math>\Eta(X) = \Eta'(X)</math>熵率可以被认为是随机信源的一般特性；这是渐近均分割性。

==马尔可夫链的熵率==
因为由不可约、非周期性、持久性的[[马尔可夫链|马尔可夫链]]定义的随机过程呈平稳分布，熵率与初始分布无关。

例如，对于在[[可数|可数]]状态下定义的，[[转移矩阵|转移矩阵]]为 ''P''<sub>''ij''</sub> 的马尔可夫链 ''Y''<sub>''k''</sub>，Η(''Y'') 由下式给出：

:<math>\displaystyle \Eta(Y) = - \sum_{ij} \mu_i P_{ij} \log P_{ij}</math>

其中 ''μ''<sub>''i''</sub> 是该链的[[平稳分布|平稳分布]]。

此定义的一个简单结果是，一个独立同分布的[[随机过程|随机过程]]的熵率与该过程中的任何个别成员的[[熵|熵]]相同。

==参见==
* 信源(数学)
* 马氏信源
* 渐近均分割性

==参考文献==

* Cover, T. and Thomas, J. (1991) Elements of Information Theory, John Wiley and Sons, Inc., ISBN 0-471-06259-6 [http://www3.interscience.wiley.com/cgi-bin/bookhome/110438582?CRETRY=1&SRETRY=0]

==外部链接==
* [https://web.archive.org/web/20120430015528/http://www.eng.ox.ac.uk/samp/ Systems Analysis, Modelling and Prediction (SAMP), University of Oxford] [[MATLAB|MATLAB]]代码，估计随机过程的信息论量。

[[Category:信息论|Category:信息论]]
[[Category:熵|Category:熵]]
[[Category:马尔可夫模型|Category:马尔可夫模型]]