{{noteTA
|G1=IT
}}
{{multiple issues|
{{expert|time=2018-06-29T04:46:43+00:00}}
{{orphan|time=2018-06-29T04:46:43+00:00}}
}}
在[[電腦視覺|電腦視覺]]中，顯著性是一種圖像分割的模式，而'''顯著圖'''（{{lang-en|Saliency map}}）是顯示每個[[像素|像素]]獨特性的圖像。顯著圖的目標在於將一般圖像的表示簡化或是改變為更容易分析的樣式。舉例來說，某個像素在一張[[彩色圖|彩色圖]]中具有較高的[[灰階|灰階]]，其會在顯著圖中以較為明顯的方式被顯示出來。

視覺刺激的觀點上，如果某些特徵特別能夠被捕捉到[[注意力|注意力]]，這樣子的特性在[[心理學|心理學]]上被稱為顯著性({{lang-en|saliency}})。

== 圖像顯著性 ==
如前述，顯著性是[[图像分割|圖像分割]]的一部分，圖像分割通常用於定位圖像中的物體和邊界(例：線條，曲線等）。更精確來說，圖像分割是為圖像中的每個[[像素|像素]](pixel)分配一個標籤的過程，以便讓相同標籤的像素能夠共享某些特徵。

圖像顯著性是圖像中重要的視覺特徵，體現出人眼對圖像各區域的重視程度，自從[[Laurent_Itti|Laurent Itti]]在1998年發表的論文<ref>{{Cite web|url=https://ieeexplore.ieee.org/document/730558/|title=A model of saliency-based visual attention for rapid scene analysis - IEEE Journals & Magazine|accessdate=2018-06-30|work=ieeexplore.ieee.org|language=en-US}}</ref>後，產生了大量的顯著性映射方法。圖像顯著性也廣泛運用在壓縮，編碼，圖像邊緣加強，顯著性目標分割和提取等方面。

== 視覺顯著性檢測<ref>{{Cite journal|title=引入视觉注意机制的目标跟踪方法综述|url=http://www.cqvip.com/qk/90250x/201404/49214675.html|last=黎万义|last2=王鹏|date=2014|journal=自动化学报|issue=4|volume=40|last3=乔红}}</ref>==
視覺注意機制，即面對一個場景時，人類自動地對感興趣區域進行處理而選擇性地忽略不感興趣區域，這些人們感興趣區域被稱之為顯著性區域。

[[視覺顯著性檢測|視覺顯著性檢測(英語：Visual Saliency Detection)]]，指透過演算法模擬人的視覺，提取出圖像中的顯著性區域。

人類的視覺注意機制主要分為兩種：

# 由下而上基於數據驅動的機制：受感知數據的驅動，將人的視點引導至圖像或場景中的顯著性區域；利用圖像的亮度，邊緣，顏色等特徵，判斷目標區塊與周圍的差異，進而計算出顯著性。
# 由上而下基於任務驅動目標的機制：由人的認知因素決定,對圖像的某些特定特徵來計算圖像區域的顯著性。

一般認為，良好的視覺顯著性檢測模型需要至少滿足以下三個標準：

# 良好的檢測率：要有較低丟失實際顯著區域的可能性以及將背景錯誤地標記為顯著區域的錯誤發生。
# 高分辨率：產生的顯著圖需要具有高分辨率以準確定位顯著物體並保留原始圖像訊息。
# 計算效率：作為其他復雜流程的起始點，這些模型應該要能夠快速檢測顯著區域。

=== 認知注意模型 ===

Itti於1998年提出基於顯著性的視覺注意模型，而後在2001年對該模型的理論作了更進一步的完善，現今，Itti的模型已經成為由下而上視覺注意模型的標準。

對於一幅輸入的圖像，該模型提取初級視覺特徵：顏色、亮度和方位、在多種尺度下使用中央環繞(Center-surround)操作產生體現顯著性量值的特徵圖，將這些特徵圖合併得到最終的顯著圖(Saliency map)後,利用生物學中贏者取全(Winner-take-all)的競爭機制得到圖像中最顯著的空間位置, 用來引導注意，最後採用返回抑制(Inhibition of return) 的方法來完成注意焦點的轉移。

=== 決策論注意模型 ===
在決策論模型的觀點中，感知系統因為不斷進化，從而能產生關於周遭環境在決策論概念下的最佳解。決策論注意模型能表達由下而上和由上而下的注意。其主要重點在於視覺注意應被當前任務有關的最優性所驅動。其理論已在計算機視覺中得到了成功的應用，如分類和注意定位預測，這兩者均獲得很高的準確率。

=== 頻域分析注意模型<ref>{{Cite journal|title=Frequency-tuned salient region detection|url=https://www.computer.org/csdl/proceedings/cvpr/2009/3992/00/05206596-abs.html|last=Achanta|first=R.|last2=Hemami|first2=S.|date=2009-06|journal=2009 IEEE Conference on Computer Vision and Pattern Recognition|publisher=IEEE|doi=10.1109/CVPRW.2009.5206596|pages=1597–1604|language=en|isbn=9781424439928|last3=Estrada|first3=F.|last4=Susstrunk|first4=S.}}</ref>===
這是一種基於頻譜分析的顯著性模型，非常容易解釋和實現，由於其理論基於[[快速傅利葉轉換|快速傅里葉轉換]]實現，能夠滿足實時(real-time)要求，此模型在注意焦點預測和顯著區域檢測方面取得了很大的成功，和iNVT類似的模型相比，運算速度可提高近10倍。

=== 圖論注意模型<ref>{{Cite web|url=https://authors.library.caltech.edu/65361/|title=Graph-Based Visual Saliency|accessdate=2018-07-01|date=2007|last=Jonathan|first=Harel,|work=authors.library.caltech.edu}}</ref>===
圖論模型是把眼球活動看作一個時間序列，由於有大量的隱變量影響眼球運動，因此，該類注意模型使用了隱馬爾科夫模型、動態貝葉斯網和條件隨機場等方法。圖論模型可以對複雜的注意機制建模，因此能取得較好的預測能力，缺點在於模型的高複雜度。

== 實作範例 ==
第一步，我們需要先計算出每一個像素與在同一幀（frame）其餘像素的距離。之後將所有的值相加，得到以下等式：

SALS(''I<sub>k</sub>'') ＝ ∑|''I<sub>k</sub>'' - ''I<sub>i</sub>''|

I<sub>i</sub>是在當前幀中除了I<sub>k</sub>之外其他的像素值，I<sub>k</sub>的範圍在[0,255]之間，展開之後如下：

SALS(''I<sub>k</sub>'') = |''I<sub>k</sub>'' - ''I''<sub>1</sub>| + |''I<sub>k</sub>'' - ''I''<sub>2</sub>| + ... + |''I<sub>k</sub>'' - ''I<sub>N</sub>''|

其中N是當前幀中的像素總和，若更進一步的擴展公式，將同樣的值放在一起，得到結果如下：

SALS(''I<sub>k</sub>'') = ∑ ''F<sub>n</sub>'' × |''I<sub>m</sub>'' - ''I<sub>n</sub>''|

F<sub>n</sub>代表I<sub>n</sub>的頻率，且n的範圍在[0,255]，頻率以[[直方图|直方圖]]的形式表示，此演算法的時間複雜度為O(N)。

=== 虛擬碼 ===
以pseudo [[MATLAB|matlab]] code為例，首先讀取數據。<syntaxhighlight lang="matlab" line="1">
for k = 2 : 1: 13  // which means from frame 2 to 13,  and in every loop K's value increase one.
I = imread(currentfilename); //read current frame
I1 = im2single(I);    //convert double image into single(requirement of command vlslic)
l = imread(lastfilename); //read last frame
I2 = im2single(l);
regionSize = 10; // set the parameter of SLIC this parameter setting are the experimental result. RegionSize means the superpixel size.
regularizer = 1; //set the parameter of SLIC 
segments1 = vlslic(I1, regionSize, regularizer);//get the superpixel of current frame
segments2 = vlslic(I2, regionSize, regularizer);//get superpixel of the previous frame
numsuppix = max(segments1(:)); //get the number of superpixel  all information about superpixel is in this link http://www.vlfeat.org/overview/slic.html
regstats1 = regionprops(segments1,’all’);
regstats2 = regionprops(segments2,’all’);//get the region characteristic based on segments1
</syntaxhighlight>在讀取數據之後，對每一幀進行超像素([[super-pixel|super-pixel]])處理，spnum1和spnum2分別表示當前幀與前一個幀的像素總數。<syntaxhighlight lang="matlab" line="1">
for i=1:1:spnum1   // From the first pixel to the last one. And in every loop i++
      for j=1:1:spnum2 //From the first pixel to the last one.j++. previous frame
           centredist(i:j)=sum((center(i)-center(j)));//calculate the center distance 
      end
end
</syntaxhighlight>之後計算每個像素之間的顏色距離，這流程稱為[[契約函數|契約函數]]。<syntaxhighlight lang="matlab" line="1">
for i=1:1:spnum1//From first pixel of current frame to the last one pixel. I ++
      for j=1:1:spnum2//From first pixel of previous frame to the last one pixel. J++
           posdiff(i,j)=sum((regstats1(j).Centroid’-mupwtd(:,i)));//Calculate the color distance.
      end
end
</syntaxhighlight>經過前述兩個處理後，可以得到一個顯著圖。

== 參見 ==

* [[图像分割|圖像分割]]

[[Category:图像处理|Category:图像处理]]
[[Category:计算机视觉|Category:计算机视觉]]