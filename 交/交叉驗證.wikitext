{{expand language|1=en|page=English Wikipedia|time=2020-03-06}}
'''交叉验证'''，有時亦稱'''循環估計'''<ref name="Kohavi95">{{cite journal | last = Kohavi | first = Ron | year = 1995 | title = A study of cross-validation and bootstrap for accuracy estimation and model selection | journal = Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence | url = http://citeseer.ist.psu.edu/kohavi95study.html | volume = 2 | issue = 12 | pages = 1137–1143 | access-date = 2008-07-14 | archive-date = 2008-03-25 | archive-url = https://web.archive.org/web/20080325104254/http://citeseer.ist.psu.edu/kohavi95study.html | dead-url = no }}(Morgan Kaufmann, San Mateo)</ref> <ref name="Chang92">Chang, J., Luo, Y., and Su, K. 1992. GPSM: a Generalized Probabilistic Semantic Model for ambiguity resolution. In Proceedings of the 30th Annual Meeting on Association For Computational Linguistics (Newark, Delaware, June 28 - July 02, 1992). Annual Meeting of the ACL. Association for Computational Linguistics, Morristown, NJ, 177-184</ref> <ref name="Devijver82">Devijver, P. A., and J. Kittler, Pattern Recognition: A Statistical Approach, Prentice-Hall, London, 1982</ref>，
是一種[[統計學|統計學]]上將[[数据|数据]][[樣本|樣本]][[集合划分|切割]]成較小子集的實用方法。於是可以先在一個子集上做分析，而其它子集則用來做後續對此分析的確認及驗證。一開始的子集被稱為'''訓練集'''。而其它的子集則被稱為'''驗證集'''或'''測試集'''。交叉验证的目的，是用未用来给模型作训练的新数据，测试模型的性能，以便減少诸如过拟合和选择偏差等問題，并给出模型如何在一个独立的数据集上通用化（即，一个未知的数据集，如实际问题中的数据）。

交叉驗證的理論是由{{tsl|en|Seymour Geisser|}}所開始的。它對於防範根据数据建议的测试假设是非常重要的，特別是當後續的[[樣本|樣本]]是危險、成本過高或科学上不适合时去搜集。

== 交叉验证的使用 ==
假设有个未知模型具有一个或多个待定的参数，且有一个数据集能够反映该模型的特征属性（训练集）。适应的过程是对模型的参数进行调整，以使模型尽可能反映训练集的特征。如果从同一个训练样本中选择独立的样本作为验证集合，当模型因训练集过小或参数不合适而产生过拟合时，验证集的测试予以反映。
交叉验证是一种预测模型拟合性能的方法。

== 常見的交叉驗證形式 ==

=== Holdout 驗證 ===

常識來說，Holdout 驗證並非一種交叉驗證，因為数据並沒有交叉使用。
隨機從最初的樣本中選出部分，形成交叉驗證数据，而剩餘的就當做訓練数据。
一般來說，少於原本樣本三分之一的数据被選做驗證数据。
<ref>{{cite web | title=Tutorial 12 | work=Decision Trees Interactive Tutorial and Resources | url=http://decisiontrees.net/node/36 | accessdate=2006-06-21 | deadurl=yes | archiveurl=https://web.archive.org/web/20060623055814/http://decisiontrees.net/node/36 | archivedate=2006-06-23 }}</ref>

=== ''k''折交叉验证 ===

''k''折交叉验证（{{lang-en|''k''-fold cross-validation}}），将训练集分割成''k''个子样本，一个单独的子样本被保留作为验证模型的数据，其他''k'' − 1个样本用来训练。交叉验证重复''k''次，每个子样本验证一次，平均''k''次的结果或者使用其它结合方式，最终得到一个单一估测。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10次交叉验证是最常用的。

=== 留一驗證 ===
<!-- This section is linked from [[数据挖掘|数据挖掘]] -->
正如名稱所建議，留一驗證（{{lang-en|leave-one-out cross-validation, LOOCV}}）意指只使用原本樣本中的一項來當做驗證資料，而剩餘的則留下來當做訓練資料。這個步驟一直持續到每個樣本都被當做一次驗證資料。
事實上，這等同於''k''折交叉验证，其中''k''為原本樣本個數。<ref>{{Cite web|url=https://web.stanford.edu/~hastie/ElemStatLearn/|title=Elements of Statistical Learning: data mining, inference, and prediction. 2nd Edition.|website=web.stanford.edu|access-date=2019-04-04|archive-date=2021-01-22|archive-url=https://web.archive.org/web/20210122061931/https://web.stanford.edu/~hastie/ElemStatLearn/|dead-url=no}}</ref>
在某些情況下是存在有效率的演算法，如使用{{tsl|en|kernel regression|}} 和[[吉洪诺夫正则化|吉洪诺夫正则化]]。

== 誤差估計 ==
可以計算估計誤差。常見的誤差衡量標準是[[均方差|均方差]]和[[方根均方差|方根均方差]]，
分別為交叉驗證的[[方差|方差]]和[[標準差|標準差]]。

== 另見 ==
* [[重抽样|重抽样]]
* [[提升方法|提升方法]]
* [[Bagging算法|引导聚集算法]]

== 參考文獻 ==
{{reflist|30em}}

== 外部連結 ==
* [https://web.archive.org/web/20090214023159/http://paul.luminos.nl/documents/show_document.php?d=198 Naive Bayes implementation with cross-validation in Visual Basic] (includes executable and source code)
* [https://web.archive.org/web/20081201180042/http://www.cs.technion.ac.il/%7Eronbeg/gcv/index.html A generic k-fold cross-validation implementation] (free open source; includes a distributed version that can utilize multiple computers and in principle can speed up the running time by several orders of magnitude.)

{{統計學}}

[[Category:统计检验|Category:统计检验]]