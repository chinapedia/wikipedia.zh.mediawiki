'''所罗门诺夫的归纳推理理论'''（Solomonoff's theory of inductive inference）是对[[奥卡姆剃刀|奥卡姆剃刀]]叙述的数学化描述。<ref name="ReferenceA">JJ McCall. Induction: From Kolmogorov and Solomonoff to De Finetti and Back to Kolmogorov – Metroeconomica, 2004 – Wiley Online Library.</ref><ref name="ReferenceB">D Stork. Foundations of Occam's razor and parsimony in learning from ricoh.com – NIPS 2001 Workshop, 2001</ref><ref name="ReferenceC">A.N. Soklakov. Occam's razor as a formal basis for a physical theory [[arxiv:math-ph/0009007|from arxiv.org]] – Foundations of Physics Letters, 2002 – Springer</ref><ref name="Hernandez.1999">{{cite journal|title=Beyond the Turing Test|author=Jose Hernandez-Orallo|url=http://users.dsic.upv.es/proy/anynt/Beyond.pdf|journal=Journal of Logic, Language and Information|year=1999|volume=9|access-date=2018-07-31|archive-date=2018-10-09|archive-url=https://web.archive.org/web/20181009045824/http://users.dsic.upv.es/proy/anynt/Beyond.pdf|dead-url=no}}</ref><ref name="Hutter.2003">M Hutter. On the existence and convergence of computable universal priors [[arxiv:cs/0305052|arxiv.org]] – Algorithmic Learning Theory, 2003 – Springer</ref>该理论指出：在所有能够完全描述的已观测的可计算类中，较短的可计算理论在估计下一次观测结果的概率时具有较大的权重。简而言之，在几组可以给出的答案的假设论述中，假设越少的越被大家选择。引申为“越简单的越易行”。

== 参考资料 ==
{{reflist}}

[[Category:归纳推理|Category:归纳推理]]
[[Category:算法信息论|Category:算法信息论]]
[[Category:贝叶斯统计|Category:贝叶斯统计]]
[[Category:机器学习|Category:机器学习]]