{{编程范式}}
'''可微分编程'''是一种[[编程范型|编程范型]]，在其中数值计算程序始终可通过[[自动微分|自动微分]]来求[[导数|导数]]<ref name="baydin2018automatic">{{cite journal|last=Baydin|first=Atilim Gunes|last2=Pearlmutter|first2=Barak|last3=Radul|first3=Alexey Andreyevich|last4=Siskind|first4=Jeffrey|title=Automatic differentiation in machine learning: a survey|journal=Journal of Machine Learning Research|year=2018|volume=18|pages=1–43|url=http://jmlr.org/papers/v18/17-468.html|access-date=2021-01-14|archive-date=2022-01-23|archive-url=https://web.archive.org/web/20220123051723/https://jmlr.org/papers/v18/17-468.html|dead-url=no}}</ref><ref>{{Citation|last=Wang|first=Fei|title=Backpropagation with Callbacks: Foundations for Efficient and Expressive Differentiable Programming|date=2018|url=http://papers.nips.cc/paper/8221-backpropagation-with-callbacks-foundations-for-efficient-and-expressive-differentiable-programming.pdf|work=Advances in Neural Information Processing Systems 31|pages=10201–10212|editor-last=Bengio|editor-first=S.|publisher=Curran Associates, Inc.|access-date=2019-02-13|last2=Decker|first2=James|last3=Wu|first3=Xilun|last4=Essertel|first4=Gregory|last5=Rompf|first5=Tiark|editor2-last=Wallach|editor2-first=H.|editor3-last=Larochelle|editor3-first=H.|editor4-last=Grauman|editor4-first=K.|archive-date=2021-02-15|archive-url=https://web.archive.org/web/20210215024547/https://papers.nips.cc/paper/2018/file/34e157766f31db3d2099831d348a7933-Paper.pdf|dead-url=no}}</ref><ref name="innes">{{Cite journal|last=Innes|first=Mike|date=2018|title=On Machine Learning and Programming Languages|url=http://math.mit.edu/~edelman/publications/on_machine_learning.pdf|journal=SysML Conference 2018|access-date=2021-01-14|archive-date=2020-06-05|archive-url=https://web.archive.org/web/20200605155354/http://math.mit.edu/~edelman/publications/on_machine_learning.pdf|dead-url=no}}</ref><ref name="diffprog-zygote">{{Citation|date=2019|title=∂P: A Differentiable Programming System to Bridge Machine Learning and Scientific Computing|arxiv=1907.07587|last1=Innes|first1=Mike|last2=Edelman|first2=Alan|last3=Fischer|first3=Keno|last4=Rackauckas|first4=Chris|last5=Saba|first5=Elliot|author6=Viral B Shah|last7=Tebbutt|first7=Will}}</ref>。这允许了对程序中的参数的{{en-link|梯度方法|Gradient method|基于梯度优化}}，通常通过[[梯度下降|梯度下降]]。可微分编程广泛用于各种领域，特别是[[科学计算|科学计算]]和[[人工智能|人工智能]]<ref name="diffprog-zygote" />。

==方式==
多数可微分编程框架是通过构造包含程序中的控制流和[[数据结构|数据结构]]的图来进行工作的<ref name="flux">{{cite arxiv|last=Innes|first=Michael|last2=Saba|first2=Elliot|last3=Fischer|first3=Keno|last4=Gandhi|first4=Dhairya|last5=Rudilosso|first5=Marco Concetto|last6=Joy|first6=Neethu Mariya|last7=Karmali|first7=Tejan|last8=Pal|first8=Avik|last9=Shah|first9=Viral|date=2018-10-31|title=Fashionable Modelling with Flux|eprint=1811.01457|class=cs.PL}}</ref>。早期的尝试一般可归入两组之中：

* 基于'''静态、[[编译器|编译]]图'''的方式，比如[[TensorFlow|TensorFlow]]<ref group=note>TensorFlow 1使用静态图方式，而TensorFlow 2缺省使用动态图方式。</ref>、[[Theano|Theano]]和[[MXNet|MXNet]]。它们意图允许良好的{{en-link|Optimizing compiler|优化编译器|编译器优化}}并易于伸缩成大系统，但是它们的静态本质，限制了交互性，和所能够容易建立的程序类型（比如涉及[[迴圈|循环]]或[[递归|递归]]的那些程序），还有使得用户难于针对他们的程序进行有效的推理<ref name="flux" /><ref name="myia1">{{Cite web|url=https://openreview.net/pdf?id=S1hcluzAb|title=Automatic Differentiation in Myia|access-date=2019-06-24|archive-date=2021-02-24|archive-url=https://web.archive.org/web/20210224030653/https://openreview.net/pdf?id=S1hcluzAb|dead-url=no}}</ref><ref name="pytorchtut">{{Cite web|url=https://pytorch.org/tutorials/beginner/examples_autograd/tf_two_layer_net.html|title=TensorFlow: Static Graphs|access-date=2019-03-04|archive-date=2021-09-02|archive-url=https://web.archive.org/web/20210902233332/https://pytorch.org/tutorials/beginner/examples_autograd/tf_two_layer_net.html|dead-url=no}}</ref>。

* 基于'''[[运算符重载|运算符重载]]、动态图'''的方式，比如[[PyTorch|PyTorch]]和[[NumPy|NumPy]]的AutoGrad。它们的动态和交互本质，使得多数程序可以更容易的书写和推理。但是它们导致了[[解释器|解释器]]开销（特别是在包含很多小运算的时候），较弱的可伸缩性，费力于从编译器优化中获益<ref name="myia1" /><ref name="pytorchtut" /><ref name="diffprog-zygote" />。

这些早期方式都只能微分以适合于这些框架的风格书写的代码，限制了同其他程序的互操作性。

更新近的包如[[Julia_(编程语言)|Julia]]编程语言的Zygote<ref>{{Cite web |url=https://github.com/FluxML/Zygote.jl |title=Zygote |access-date=2021-01-14 |archive-date=2021-02-14 |archive-url=https://web.archive.org/web/20210214153653/https://github.com/FluxML/Zygote.jl |dead-url=no }}</ref>，[[Swift_(程式语言)|Swift]]编程语言的Swift for TensorFlow<ref>{{Cite web |url=https://www.tensorflow.org/swift |title=Swift for TensorFlow |access-date=2021-01-14 |archive-date=2021-01-21 |archive-url=https://web.archive.org/web/20210121151159/https://www.tensorflow.org/swift |dead-url=no }}</ref>，和新的编程语言Myia<ref>{{Cite web |url=https://github.com/mila-iqia/myia |title=Myia |access-date=2021-01-14 |archive-date=2020-12-31 |archive-url=https://web.archive.org/web/20201231191544/https://github.com/mila-iqia/myia |dead-url=no }}</ref>，通过将编程语言的语法当作图来处理，解决了早期尝试所面临的问题。任意代码的[[中间语言|中间表示]]可以直接的微分、优化和编译<ref name="flux" /><ref>{{cite arxiv|last=Innes|first=Michael|date=2018-10-18|title=Don't Unroll Adjoint: Differentiating SSA-Form Programs|eprint=1810.07951|class=cs.PL}}</ref><ref name="myia1" />。

==应用==
可微分编程已经应用于多个领域，比如在[[机器人学|机器人学]]中结合[[深度学习|深度学习]]和[[物理引擎|物理引擎]]，用可微分[[密度泛函理论|密度泛函理论]]解决电子结构问题，可微分[[光线追踪|光线追踪]]，[[图像处理|图像处理]]和[[概率编程|概率编程]]<ref>{{cite arxiv|last=Degrave|first=Jonas|last2=Hermans|first2=Michiel|last3=Dambre|first3=Joni|last4=wyffels|first4=Francis|date=2016-11-05|title=A Differentiable Physics Engine for Deep Learning in Robotics|eprint=1611.01652|class=cs.NE}}</ref><ref name='Li2021'>{{cite journal |title=Kohn-Sham Equations as Regularizer: Building Prior Knowledge into Machine-Learned Physics |journal=Physical Review Letters |year=2021 |first1=Li |last1=Li | first2=Stephan | last2=Hoyer | first3=Ryan | last3=Pederson | first4=Ruoxi | last4=Sun | first5=Ekin D. | last5=Cubuk | first6=Patrick | last6=Riley |first7=Kieron | last7=Burke |volume=126 |issue=3 |pages=036401 |doi=10.1103/PhysRevLett.126.036401 }}</ref><ref>{{Cite web|url=https://people.csail.mit.edu/tzumao/diffrt/|title=Differentiable Monte Carlo Ray Tracing through Edge Sampling|website=people.csail.mit.edu|access-date=2019-02-13|archive-date=2021-05-12|archive-url=https://web.archive.org/web/20210512120913/https://people.csail.mit.edu/tzumao/diffrt/|dead-url=no}}</ref><ref>{{Cite web|url=https://sciml.ai/roadmap/|title=SciML Scientific Machine Learning Open Source Software Organization Roadmap|website=sciml.ai|access-date=2020-07-19|archive-date=2021-10-17|archive-url=https://web.archive.org/web/20211017214443/https://sciml.ai/roadmap/|dead-url=no}}</ref><ref>{{Cite web|url=https://people.csail.mit.edu/tzumao/gradient_halide/|title=Differentiable Programming for Image Processing and Deep Learning in Halide|website=people.csail.mit.edu|access-date=2019-02-13|archive-date=2021-05-06|archive-url=https://web.archive.org/web/20210506234355/https://people.csail.mit.edu/tzumao/gradient_halide/|dead-url=no}}</ref><ref name="diffprog-zygote" />。

==参见==
* [[机器学习|机器学习]]

==注释==
{{reflist|group=note}}

==引用==
{{reflist|2}}

{{Differentiable computing}}
[[Category:微分学|Category:微分学]]
[[Category:编程典范|Category:编程典范]]