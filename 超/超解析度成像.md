{{Expand language|en}}
'''超解析度成像'''（Super-resolution imaging，縮寫SR），是一種提高影片解析度的技術。在一些稱為「光學SR」的SR技術中，系統的繞射極限被超越；而在其他所謂的「幾何SR」中，數位[[感光元件|感光元件]]的分辨率因而提高。超解析度成像技術用於一般圖像處理和超高解析度顯微鏡。

== 深度神經網路相關技術 ==
隨著神經網路的流行，相關技術也被應用在提高圖片解析度。

=== SRCNN<ref>{{Cite arxiv|last=Chao|first=Dong|last2=Chen Change|first2=Loy|last3=Kaiming|first3=He|last4=Xiaoou|first4=Tang|date=2015-05-27|title=Image Super-Resolution Using Deep Convolutional Networks|arxiv=1501.00092}}</ref>===
SRCNN ( Super-resolution convolution neural network )是一個神經網路，輸入是一個低解析度（视觉上）的圖像，而輸出是一個高解析度的圖像，這裡需要注意的是，在將圖像餵進神經網路前，需要先經過一個預處理bicubic interpolation，將原始圖片變成跟想要的高解析度圖像一樣大小後，再餵進神經網路中。而神經網路做的事情，主要分成三個步驟區塊特徵抽取與表達（Patch extraction and representation）、非線性對應（non-linear mapping）以及重建（reconstruction）。

==== 區塊特徵抽取與表達（Patch extraction and representation） ====
這一步就如同一般的CNN ( convolution neural network )，只是沒有經過max-pooling，公式如下。
<center><math>F_1(Y) = \max(0, W_1 \ast Y + B_1)</math></center>
<math>Y</math>代表已經經過bicubic interpolation的圖像，<math>F_1(Y)</math>則為這層神經網路的輸出，<math>W_1</math>代表<math>n_1</math>個<math>c \times f_1 \times f_1</math>的filter（<math>c</math>是圖像的channel數量，而<math>f_1</math>則為filter的大小），<math>\ast</math>代表卷積（convolution），<math>B_1</math>是偏移量（bias），最後的<math>\max</math>則代表激活函數RELU。

==== 非線性對應（non-linear mapping） ====
非線性對應，基本上就是持續利用一般CNN的方式將前一步每一塊的<math>n_1</math>維的特徵向量，分別轉換成<math>n_2</math>維的特徵向量，公式如下。
<center><math>F_2(Y) = \max(0, W_2 \ast F_1(Y) + B_2)</math></center>

==== 重建（reconstruction） ====
在重建的步驟中，我們要考慮的是每一個像素所要的值是多少，這個步驟可以想成在多個相關的高維度的特徵向量中，取一個平均，很湊巧的，這剛好也很像一般的卷積層（convolution layer），公式如下。
<center><math>F(Y) = W_3 \ast F_2(Y) + B_3</math></center>

==== 訓練方法 ====
在SRCNN中所採用的差異函數（Loss Function）是簡單的平均方根差（Mean Square Error），定義為重建後的相片每一個像素與真正的圖片的每一個像素的差異，公式如下。
<center><math>L(\theta)=\frac{1}{n}\sum_{i=1}^n \| F(Y_i; \theta) - X_i \|^2</math></center>
<math>\theta</math>為SRCNN的參數，<math>F(Y_i;\theta)</math>為給定的SRCNN重建<math>Y_i</math>的圖像，<math>X_i</math>則為真正的高解析度圖像，<math>n</math>為拿來訓練神經網路的圖像數量或者是一個batch中所有的圖像數量。

=== [https://arxiv.org/abs/1603.08155"Perceptual Losses for Real-Time Style Transfer and Super-Resolution"]<ref>{{Cite arxiv|last=Johnson|first=Justin|last2=Alahi|first2=Alexandre|last3=Fei-Fei|first3=Li|date=2016-03-26|title=Perceptual Losses for Real-Time Style Transfer and Super-Resolution|arxiv=1603.08155}}</ref>===
這篇論文提供了一個做法，可以應用在圖像風格轉移（Style Transfer）以及超高解析度（Super-resolution）。

整個系統由兩個神經網路組成，其中一個是圖像轉移網路<math>f_W</math>，另一個則是可以用來定義各種差異的差異網路<math>\phi</math>。

==== 圖像轉移網路<math>f_W</math> ====
圖像轉移網路的輸入為一張圖像，輸出也是一張圖像，而這個網路的參數以<math>W</math>表示。

這個圖像轉移網路由5個residual block<ref>{{Cite arxiv|last=Kaiming|first=He|last2=Xiangyu|first2=Zhang|last3=Shaoqing|first3=Ren|last4=Jian|first4=Sun|date=2015-12-10|title=Deep Residual Learning for Image Recognition|arxiv=1512.03385}}</ref>所組成，而所有非residual的convolution layer後面都會接上batch normalization。激活函數（activation function）的部分，除了在最後的輸出層（output layer）使用scaled tanh使得輸出的數值在0到255之間，其他都是使用RELU。

convolution layer的filter（kernel）的數量上，第一層和最後一層使用<math>9 \times 9</math>個，其他層則是使用<math>3 \times 3</math>個。

==== 差異網路<math>\phi</math> ====
差異網路定義了各種差異函數（loss function），輸入為兩張圖像，一張來自圖像轉移網路，一張則是真正的高解析度影像，輸出為一個實數（scalar）。

而這篇論文所使用的差異網路是16層的VGG網路<ref>{{Cite arxiv|last=Karen|first=Simonyan|last2=Andrew|first2=Zisserman|date=2014-09-04|title=Very Deep Convolutional Networks for Large-Scale Image Recognition|arxiv=1409.1556}}</ref>，並事先利用Image Net訓練過。差異函數的部分，使用了兩個不同於傳統簡單的差異函數。（CHW代表feature map各個維度的數值）

===== 特徵重建差異（Feature Reconstruction Loss）=====
這個差異函數的設計理念在於，當我們在看兩張圖片像不像時，我們並不是一個一個像素的比較，而是比較兩張圖片中的特徵像不像。因此，他拿差異網路中某一層的輸出，當作一個圖片特徵值，再以兩張圖片的特徵值的Euclidean Distance當作差異。
<center><math>l_{feat}^{\phi, j}(\hat{y},y)=\frac{1}{C_j H_j W_j}\| \phi_j(\hat{y}) - \phi_j(y)\|_2^2</math></center>

===== 風格重建差異（Style Reconstruction Loss）<ref>{{Cite arxiv|last=Leon A.|first=Gatys|last2=Alexander S.|first2=Ecker|last3=Matthias|first3=Bethge|date=2015-05-27|title=Texture Synthesis Using Convolutional Neural Networks|arxiv=1505.07376}}</ref><ref>{{Cite arxiv|last=Leon A.|first=Gatys|last2=Alexander S.|first2=Ecker|last3=Matthias|first3=Bethge|date=2015-05-27|title=A Neural Algorithm of Artistic Style|arxiv=1508.06576}}</ref>=====
除了一般的特徵以外，我們也會需要圖像轉移網路正確的重建顏色、材質等等的內容，因此必須再加上風格重建差異函數。
在定義風格重建差異之前，我們先定義Gram矩陣<math>G_j^{\phi}(x)_{c,c'}</math>。
<center><math>G_j^{\phi}(x)_{c,c'}=\frac{1}{C_j H_j W_j}\sum_{h=1}^{H_j}\sum_{w=1}^{W_j}\phi_j(x)_{h,w,c}\phi_j(x)_{h,w,c'}</math></center>

接著差異函數就可以定義為
<center><math>l_{style}^{\phi,j}(\hat{y},y)=\| G_j^{\phi}(\hat{y}) - G_j^{\phi}(y) \|_F^2</math></center>

而一般比較每一個像素差異的差異函數，則可以寫為
<center><math>l_{pixel}(\hat{y},y)=\|\hat{y}-y\|_2^2/CHW</math></center>

有了這兩個網路後，訓練圖像轉移網路的方法則是最小化各式差異函數的權重和（weighted sum），優化的方法是梯度下降法（Stochastic Gradient Descent（l()是差異函數（loss function）））。
<center><math>W^* = arg \min_W E_{x,\{y_i\}}[\sum_{i=1} \lambda_i l_i( f_W(x), y_i ) ]</math></center>

這篇論文在高解析度圖像這個傳統問題上，給了一個快速且有效的解法，快速的原因在於，在遇到一張新的圖片時，只需要把圖像餵進圖像轉移網路就好（一次forward pass）。而在結果上，也大大的超越了之前的做法（一樣使用深度神經網路）SRCNN。

== 参见条目 ==
*{{le|超分辨率显微镜|Super-resolution microscopy}}
*[[光學解析度|光學解析度]]
*[[混疊|混疊]]
*[[过采样|过采样]]
*[[壓縮感知|壓縮感知]]
*[[核磁共振成像|核磁共振成像]]（MRI）
*[[迭代稀疏漸近最小方差算法|迭代稀疏漸近最小方差算法]]

== 參考資料 ==
{{reflist}}

[[Category:图像处理|Category:图像处理]]
[[Category:光學|Category:光學]]
[[Category:信号处理|Category:信号处理]]