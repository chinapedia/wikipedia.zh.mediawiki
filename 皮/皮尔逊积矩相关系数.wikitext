{{roughtranslation|time=2017-04-04T03:36:08+00:00}}
{{NoteTA
|G1=Math
|T=zh-hans:皮尔逊积矩相关系数;zh-tw:皮爾森積動差相關係數
|1=zh-hans:皮尔逊;zh-tw:皮爾森
|2= zh-cn:矩; zh-tw:動差; zh-hant:矩;
|3= zh-cn:矩阵; zh-tw:矩陣; zh-hant:矩陣
|4=zh-cn:系数; zh-tw:係數; zh-hk:系數;
}}

在[[统计学|统计学]]中，'''皮尔逊积矩相关系数'''（{{lang-en|'''P'''earson '''p'''roduct-'''m'''oment '''c'''orrelation '''c'''oefficient}}，缩写：'''PPMCC'''，或'''PCCs'''<ref>"The human disease network", Albert Barabasi et al., Plos.org</ref>{{notetag|文献中常用r或Pearson's r表示}}）用于度量兩組數據的变量X和Y之间的[[線性關係|線性]][[相關_(概率論)|相關]]的程度。它是兩個變量的[[協方差|協方差]]<ref>{{cite web|url=https://en.wikipedia.org/wiki/Covariance |website=Wikipedia |access-date=2022-04-26}}</ref>{{Circular reference|date=June 2022}}與其[[標準差|標準差]]的乘積之比； 因此，它本質上是協方差的歸一化度量，因此結果始終具有介於-1和1之間的值。與協方差本身一樣，該度量只能反映變量的線性相關性，而忽略了許多其他類型的關係或相關性。舉個簡單的例子，可以預期高中青少年樣本的年齡和身高的皮尔逊积矩相关系数顯著大於0，但小於1（因為1表示不切實際的完美相關性）。

[[File:Correlation_coefficient.png|thumb]]
[[Image:Correlation_examples2.svg|thumb]]

== 命名和歷史 ==
它是由[[卡尔·皮尔逊|卡尔·皮尔逊]]从[[弗朗西斯·高尔顿|弗朗西斯·高尔顿]]在1880年代提出的一个相似却又稍有不同的想法演变而来，<ref name="thirteenways">J. L. Rodgers and W. A. Nicewander. [http://www.jstor.org/stable/2685263 Thirteen ways to look at the correlation coefficient] {{Wayback|url=http://www.jstor.org/stable/2685263 |date=20160529032823 }}. The American Statistician, 42(1):59–66, February 1988.</ref><ref>{{Cite journal| doi = 10.1214/ss/1177012580| last = Stigler | first = Stephen M. | title = Francis Galton's Account of the Invention of Correlation | journal = Statistical Science | volume=4 | issue=2 | pages = 73–79 | year = 1989 | jstor=2245329}}</ref>并且其数学公式由[[奥古斯特·布拉菲|奥古斯特·布拉菲]](Auguste Bravais)于1844年推导出和发表{{NoteTag|As early as 1877, Galton was using the term "reversion" and the symbol "''r''" for what would become "regression".<ref>{{cite journal |first=F. |last=Galton |date=5–19 April 1877 |title=Typical laws of heredity |journal=Nature |volume=15 |issue=388, 389, 390 |pages=492–495 ; 512–514 ; 532–533 |doi=10.1038/015492a0 |bibcode=1877Natur..15..492. |s2cid=4136393 |url=https://books.google.com/books?id=eskKAAAAYAAJ&pg=PA512|doi-access=free }} In the "Appendix" on page 532, Galton uses the term "reversion" and the symbol ''r''.</ref><ref>{{cite journal |first=F. |last=Galton |date=24 September 1885 |title=The British Association: Section II, Anthropology: Opening address by Francis Galton, F.R.S., etc., President of the Anthropological Institute, President of the Section |journal=Nature |volume=32 |issue=830 |pages=507–510 |url=https://books.google.com/books?id=lN3RjXLUuWsC&pg=PA499}}</ref><ref>{{cite journal |first=F. |last=Galton |year=1886 |title=Regression towards mediocrity in hereditary stature |journal=Journal of the Anthropological Institute of Great Britain and Ireland |volume=15 |pages=246–263 |doi=10.2307/2841583 |jstor=2841583 |url=https://books.google.com/books?id=JPcRAAAAYAAJ&pg=PA246}}</ref>}}<ref>{{cite journal |first=Karl |last=Pearson |date=20 June 1895 |title=Notes on regression and inheritance in the case of two parents |journal=Proceedings of the Royal Society of London |volume=58 |pages=240–242 |bibcode=1895RSPS...58..240P |url=https://books.google.com/books?id=60aL0zlT-90C&pg=PA240}}</ref><ref>{{cite journal |last=Stigler |first=Stephen M. |year=1989 |title=Francis Galton's account of the invention of correlation |journal=Statistical Science |volume=4 |issue=2 |pages=73–79 |jstor=2245329 |doi=10.1214/ss/1177012580 |doi-access=free}}</ref><ref>{{cite journal |title=Analyse mathematique sur les probabilités des erreurs de situation d'un point |journal=Mem. Acad. Roy. Sci. Inst. France |series=Sci. Math, et Phys. |volume=9 |pages=255–332 |year=1844 |url=https://books.google.com/books?id=y3s_AAAAcAAJ&q=Sur%20Les%20Probabilit%C3%A9s%20des%20Erreurs%20de%20Situation%20d'un%20Point&pg=PA1 |via=Google Books |language=fr}}</ref><ref>{{cite journal |last1=Wright |first1=S. |year=1921 |title=Correlation and causation |journal=Journal of Agricultural Research |volume=20 |issue=7 |pages=557–585}}</ref>。系数的命名因此是[[Stigler名字由來法則|Stigler名字由來法則]]的一个例子。

这个相关系数也称作“皮尔森相关系数r”。

==定义==
两个变量之间的皮尔逊相关系数定义为两个变量的[[协方差|-{zh-hans:协方差; zh-hant:共變異數; zh-cn:协方差; zh-tw:共變異數; zh-hk:共變異數; zh-sg:协方差}-]]除以它们[[标准差|标准差]]的乘积：
:<math>\rho_{X,Y}={\mathrm{cov}(X,Y) \over \sigma_X \sigma_Y} ={E[(X-\mu_X)(Y-\mu_Y)] \over \sigma_X\sigma_Y}</math>

上式定义了'''总体'''相关系数，常用希腊小寫字母 ''ρ'' (rho) 作為代表符號。估算[[样本|样本]]的-{zh-hans:协方差; zh-hant:共變異數; zh-cn:协方差; zh-tw:共變異數; zh-hk:共變異數; zh-sg:协方差}-和标准差，可得到'''样本相关系数'''(样本皮尔逊系数)，常用英文小寫字母 r 表示：

:<math>r = \frac{\sum\limits ^n _{i=1}(X_i - \overline{X})(Y_i - \overline{Y})}{\sqrt{\sum\limits ^n _{i=1}(X_i - \overline{X})^2} \sqrt{\sum\limits ^n _{i=1}(Y_i - \overline{Y})^2}}  </math>

r 亦可由<math>(X_i,Y_i)</math>[[样本|样本]]点的[[標準分數|標準分數]]均值估算，得到與上式等價的表達式：

:<math>r = \frac{1}{n-1} \sum\limits ^n _{i=1} \left( \frac{X_i - \overline{X}}{\sigma_X} \right) \left( \frac{Y_i - \overline{Y}}{\sigma_Y} \right)</math>

其中 <math>\frac{X_i - \overline{X}}{\sigma_X}</math>、<math> \overline{X}</math> 及 <math>\sigma_X</math> 分别是 <math>X_i</math> 样本的標準分數、样本[[平均值|平均值]]和样本标准差。

==数学特性==
总体和样本皮尔逊系数的绝对值小于或等于1。如果样本数据点精确的落在直线上{{notetag|计算样本皮尔逊系数的情况}}，或者双变量分布完全在直线上（计算总体皮尔逊系数的情况），则相关系数等于1或-1。皮尔逊系数是对称的：corr(X,Y) = corr(Y,X)。

皮尔逊相关系数有一个重要的数学特性是，因两个变量的位置和尺度的变化并不会引起该系数的改变，即它该变化的[[不变量|不变量]] (由符号确定)。也就是说，我们如果把X移动到a + bX和把Y移动到c + dY，其中a、b、c和d是常数，并不会改变两个变量的相关系数{{notetag|该结论在总体和样本皮尔逊相关系数中都成立}}。我们发现更一般的线性变换则会改变相关系数：参见[[#去除相关性|之后章节]]对该特性应用的介绍。

由于μ<sub>X</sub> = E(X), σ<sub>X</sub><sup>2</sup> = E[(X − E(X))<sup>2</sup>] = E(X<sup>2</sup>) − E<sup>2</sup>(X)，Y也类似, 并且

:<math>E[(X-E(X))(Y-E(Y))]=E(XY)-E(X)E(Y),\,</math>

故相关系数也可以表示成

:<math>\rho_{X,Y}=\frac{E(XY)-E(X)E(Y)}{\sqrt{E(X^2)-(E(X))^2}~\sqrt{E(Y^2)- (E(Y))^2}}.</math>

对于'''样本'''皮尔逊相关系数:

:<math>
r_{xy}=\frac{\sum x_iy_i-n \bar{x} \bar{y}}{(n-1) s_x s_y}=\frac{n\sum x_iy_i-\sum x_i\sum y_i}
{\sqrt{n\sum x_i^2-(\sum x_i)^2}~\sqrt{n\sum y_i^2-(\sum y_i)^2}}.
</math>

以上方程给出了计算样本皮尔逊相关系数简单的单流程算法，但是其依赖于涉及到的数据，有时它可能是[[數值穩定性|数值不稳定]]的。

==解释==
皮尔逊相关系数的变化范围为-1到1。 系数的值为1意味着''X'' 和 ''Y''可以很好的由直线方程来描述，所有的数据点都很好的落在一条[[直线|直线]]上，且 ''Y'' 随着 ''X'' 的增加而增加。系数的值为−1意味着所有的数据点都落在直线上，且 ''Y'' 随着 ''X'' 的增加而减少。系数的值为0意味着两个变量之间没有线性关系。

更一般的, 我们发现，当且仅当 ''X''<sub>''i''</sub> 和 ''Y''<sub>''i''</sub> 均落在他们各自的均值的同一侧， 则(''X''<sub>''i''</sub> − <font style="text-decoration: overline;">''X''</font>)(''Y''<sub>''i''</sub> − <font style="text-decoration: overline;">''Y''</font>) 的值为正。    也就是说，如果''X''<sub>''i''</sub> 和 ''Y''<sub>''i''</sub> 同时趋向于大于, 或同时趋向于小于他们各自的均值，则相关系数为正。  如果 ''X''<sub>''i''</sub> 和 ''Y''<sub>''i''</sub> 趋向于落在他们均值的相反一侧，则相关系数为负。

===几何学角度的解释===
[[File:Regression_lines.png|thumb]]]

对于没有进行中心化的数据, 相关系数与两条可能的[[線性回歸|回归线]]y=g<sub>x</sub>(x) 和 x=g<sub>y</sub>(y) 夹角的余弦值一致。

对于中心化过的数据（也就是说, 数据移动一个样本平均值以使其均值为0），相关系数也可以被视作由两个随机变量[[向量|向量]][[夹角|夹角]]<math>\ \theta</math> 的[[cosine|余弦值]]（见下方）。

一些人{{who|date=September 2010}} 倾向于使用非中心化的相关系数 (non-Pearson-compliant) 。 比较如下。

例如，有5个国家的国民生产总值分别为 10, 20, 30, 50 和 80 亿美元。 假设这5个国家 (顺序相同) 的贫困百分比分别为 11%, 12%, 13%, 15%, 和 18% 。 令 '''x''' 和 '''y''' 分别等于包含上述5个数据的向量: '''x''' = (1, 2, 3, 5, 8) 和 '''y''' = (0.11, 0.12, 0.13, 0.15, 0.18)。

利用通常的方法计算两个向量之间的夹角 <math>\ \theta</math>  (参见 [[dot_product|数量积]]),  ''未中心化'' 的相关系数是:

<!-- cos theta = (X dot Y) / ||X|| ||Y|| = 2.93 / sqrt(103 * 0.0983) = 0.920814711. -->
:<math> \cos \theta = \frac { \mathbf{x} \cdot \mathbf{y} } { \left\| \mathbf{x} \right\| \left\| \mathbf{y} \right\| } = \frac { 2.93 } { \sqrt { 103 } \sqrt { 0.0983 } } = 0.920814711. </math>

我们发现以上的数据特意选定为完全相关: ''y'' = 0.10 + 0.01 ''x''。 于是，皮尔逊相关系数应该等于1。将数据中心化 (通过E('''x''') = 3.8移动 '''x'''  和通过 E('''y''') = 0.138 移动 '''y''' ) 得到 '''x''' = (−2.8, −1.8, −0.8, 1.2, 4.2) 和 '''y''' = (−0.028, −0.018, −0.008, 0.012, 0.042), 从中，

<!-- cos theta = (X dot Y) / ||X|| ||Y|| = 0.308 / sqrt(30.8 * 0.00308) = 1. -->
:<math> \cos \theta = \frac { \mathbf{x} \cdot \mathbf{y} } { \left\| \mathbf{x} \right\| \left\| \mathbf{y} \right\| } = \frac { 0.308 } { \sqrt { 30.8 } \sqrt { 0.00308 } } = 1 = \rho_{xy}, </math>

===对相关系数大小的解释===
{|class="wikitable" align="right"
|-
! 相关性 !! 负 !! 正
|-
| 无 || −0.09 to 0.0 || 0.0 to 0.09
|-
| 弱 || −0.3 to −0.1 || 0.1 to 0.3
|-
| 中 || −0.5 to −0.3 || 0.3 to 0.5
|-
| 强 || −1.0 to −0.5|| 0.5 to 1.0
|}

一些著作的作者<ref name="Buda">A. Buda and A.Jarynowski (2010) ''Life-time of correlations and its applications vol.1'', Wydawnictwo Niezalezne: 5–21, December 2010, ISBN 978-83-915272-9-0</ref><ref name="Cohen88"/> 给出了某些解释相关系数的指南。 然而, 所有这些标准从某种意义上说是武断的和不严格的。<ref name="Cohen88">Cohen, J. (1988). ''Statistical power analysis for the behavioral sciences'' (2nd ed.)</ref>   对相关系数的解释是依赖于具体的应用背景和目的的。  例如，若是在运用高性能的仪器来验证一个物理定律实验这样的应用背景下，0.9的相关系数可能是很低的。但如果是应用在社会科学中，由于社会科学受到各种复杂多变因素影响，0.9的相关系数是相当高的。 

===皮尔逊距离 ===
''皮尔逊距离''度量的是两个变量X和Y，它可以根据皮尔逊系数定义成<ref>Fulekar (Ed.), M.H. (2009) ''Bioinformatics: Applications in Life and Environmental Sciences'', Springer (pp. 110) ISBN 1402088795</ref>
:<math>d_{X,Y}=1-\rho_{X,Y}.</math>
我们可以发现，皮尔逊系数落在<math>[-1, 1]</math>，而皮尔逊距离落在<math>[0, 2]</math>。

==统计推断：显著性检验与置信区间==
[[Image:correlation_significance.svg|300px]]基于皮尔逊相关系数的统计推断通常关注以下两个目标。
#验证[[零假设|零假设]]是否为真，即相关系数 ''ρ'' 是否等于 0, 该相关系数使用的是样本相关系数 ''r''。
#在給定的[[置信水平|置信水平]]α之下，构建一个围绕''r''的[[置信区间|置信区间]]。

===随机采样方法===
{{le|显著性检验|Resampling (statistics)#Permutation tests}}提供了一种假设检验和构造置信区间的直接方法。

对皮尔逊相关系数的'''显著性检验'''包括以下两个步骤：
#随机地将原始的数据对 (''x''<sub>''i''</sub>, ''y''<sub>''i''</sub>)重新定义成数据集 (''x''<sub>''i''</sub>, ''y''<sub>''i′''</sub>), 其中 ''i′'' 表示数列 {1,...,''n''}。  数列 ''i′'' 的选取是随机的, 以相同的概率落在 ''n''! 种可能的数列中。这等价于随机地"不可重复地"从数列{1,..., ''n''}中选取 ''i′''。一种相近的且合乎情理的方法（[[自助法|自助抽样法]]）是“可重复地”从数列{1,..., ''n''}中选取 ''i'' 和 ''i′''  
#由随机数据构造相关系数''r''。

为了完成显著性检验，需要多次重复步骤(i)和(ii) 。显著性检验的[[P值|P值]]是由测试数据除以步骤（ii）得到的''r''，其中''r''大于由原始数据计算出的皮尔逊相关系数。在这里“大”可能是绝对值比较大或者是数值比较大，这取决于测试使用的是{{le|双尾检验|two-tailed test}}或者是{{le|单尾检验|one-tailed test}}。

===自助抽样法===
[[自助法|自助抽样法]]可以被用来构造皮尔逊系数的置信区间。在"非参数"的自助抽样法中，“可重复”地从观测数据集''n''中重新采样''n'' 对的 (''x''<sub>''i''</sub>, ''y''<sub>''i''</sub>) 数据，用来计算相关系数''r''。这个过程重复了大量次数,。重新采样后数据的 ''r''值的分布被用来估计统计学上的{{le|样本分布|sampling distribution}}。''ρ''的95%的[[置信区间|置信区间]]可以被定义成重新采样样本 ''r''值的%2.5到%97.5之间。

===基于数学近似的方法===
对于近似[[高斯分布|高斯分布]]的数据，皮尔逊相关系数的{{le|样本分布|sampling distribution}}'''近似於自由度为''N'' − 2的[[t分布|t分布]]'''。特别地，如果两个变量服从双变量正态分布，变量

:<math>t = r\sqrt{\frac{n-2}{1 - r^2}}</math>

也會服从不相关的t分布。<ref>N.A Rahman, A Course in Theoretical Statistics; Charles Griffin and Company, 1968</ref> 如果样本容量不是特别小，这个结论也大致成立，即便观测数据不是正态分布的。<ref>Kendall, M.G., Stuart, A. (1973)''The Advanced Theory of Statistics, Volume 2: Inference and Relationship'', Griffin. ISBN 0852642156 (Section 31.19)</ref>如果需要构建置信区间和进行有力的分析，还需要采用如下的可逆变换

:<math>r = \frac{t}{\sqrt{n - 2 + t^2}}.</math>

或者，也可以采用大量采样数据的方法。

早期对样本相关系数的研究得益于[[R._A._Fisher|R. A. Fisher]]<ref>{{Cite journal
 | last = Fisher | first = R.A.
 | authorlink = R. A. Fisher
 | title = Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population
 | url = https://archive.org/details/sim_biometrika_1915-05_10_4/page/507 | journal = [[Biometrika|Biometrika]]
 | volume = 10
 | issue = 4
 | pages = 507–521
 | year = 1915
 | doi = 10.1093/biomet/10.4.507
}}</ref><ref>{{Cite journal
 | last = Fisher | first = R.A.
 | authorlink = R. A. Fisher
 | title = On the probable error of a coefficient of correlation deduced from a small sample
 | journal = [[Metron|Metron]]
 | year = 1921
 | volume = 1
 | issue = 4
 | pages = 3–32
 | url = http://hdl.handle.net/2440/15169
 | accessdate = 2009-03-25
 | format = [[PDF|PDF]]
}}</ref>和A. K. Gayen.<ref>{{Cite journal
 | first = A.K. | last = Gayen
 | title = The frequency distribution of the product moment correlation coefficient in random samples of any size draw from non-normal universes
 | url = https://archive.org/details/sim_biometrika_1951-06_38_part-1-2/page/219 | journal = [[Biometrika|Biometrika]]
 | year = 1951
 | volume = 38
 | pages = 219–247
 | doi = 10.1093/biomet/38.1-2.219
}}</ref>的工作。
另一篇早期的论文<ref>Soper, H.E., Young, A.W., Cave, B.M., Lee, A., Pearson, K. (1917). "On the distribution of the correlation coefficient in small samples. Appendix II to the papers of "Student" and R. A. Fisher. A co-operative study", ''[[Biometrika|Biometrika]]'', 11, 328-413. doi:10.1093/biomet/11.4.328</ref> 给出了在小样本的情况下总体相关系数 ''ρ''的图表, 并讨论了相关的计算方法。

===准确服从高斯分布的数据===
准确的双变量样本相关系数的分布是<ref>Kenney, J. F. and Keeping, E. S., ''Mathematics of Statistics'', Pt. 2, 2nd ed. Princeton, NJ: Van Nostrand, 1951.</ref><ref>{{Cite web |url=http://mathworld.wolfram.com/CorrelationCoefficientBivariateNormalDistribution.html |title=Correlation Coefficient - Bivariate Normal Distribution |accessdate=2012-03-17 |archive-date=2012-05-11 |archive-url=https://web.archive.org/web/20120511050705/http://mathworld.wolfram.com/CorrelationCoefficientBivariateNormalDistribution.html |dead-url=no }}</ref>

:<math>f\left(r\right) = \frac{\left(n - 2\right)\, \mathbf{\Gamma}\left(n - 1\right) \left(1 - \rho^2\right)^{\frac{n - 1}{2}} \left(1 - r^2\right)^{\frac{n - 4}{2}}}{\sqrt{2\pi}\, \mathbf{\Gamma}\left(n - \frac{1}{2}\right) \left(1 - \rho r\right)^{n - \frac{3}{2}}} \,\mathbf{_2F_1}\left(\frac{1}{2}, \frac{1}{2}; \frac{2n - 1}{2}; \frac{\rho r + 1}{2}\right)</math>

其中 <math>\mathbf{\Gamma}</math>是[[Γ函数|伽玛函数]]，<math>\,\mathbf{_2F_1}(a,b;c;z)</math> 是[[超几何函数|高斯超几何函数]]。

注意到 <math>E\left(r\right) = \rho - \frac{\rho \left(1 - \rho^2\right)}{2 \left(n - 1\right)} + \cdots </math>, 因此 ''r'' 是<math>\,\rho</math>的一个有偏估计。一种获得无偏估计的方法是解<math>\,\rho</math>的方程 <math>r = E\left(r\right) = \rho - \frac{\rho \left(1 - \rho^2\right)}{2 \left(n - 1\right)}</math> 。 然而，解 <math>\breve{\rho} = r \left[1 + \frac{1 - r^2}{2\left(n - 1\right)}\right]</math>是次优的。 一种无偏估计, 可以从 ''n''较大情况下的最小方差和有偏序列 <math>\frac{1}{n - 1}</math>, 通过最大化 <math>\log{f\left(r\right)}</math>, 也就是<math>\hat{\rho} = r \left[1 - \frac{1 - r^2}{2\left(n - 1\right)}\right]</math>获得。

特殊情况下，当 <math>\,\rho = 0</math>时，分布可以被写成
:<math>f\left(r\right) = \frac{\left(1 - r^2\right)^{\frac{n - 4}{2}}}{\mathbf{B}\left(\frac{1}{2}, \frac{n - 2}{2}\right)}</math>
其中 <math>\mathbf{B}</math>是[[Β函数|贝塔函数]]。

===費雪轉換===

实际应用中, 与ρ相关的[[置信区间|置信区间]]和[[假设检验|假设检验]]通常是通过[[费雪变换|費雪轉換]]获得

: <math>F(r) = {1 \over 2}\ln{1 + r \over 1 - r} = \operatorname{arctanh}(r).</math>

如果''F''(''r'')是''r''的費雪轉換，''n'' 是样本容量，那么''F''(''r'')近似服从[[正态分布|正态分布]] 

:<math>\text{mean} = F(\rho) = \operatorname{arctanh}(\rho)</math>    and standard error    <math>\text{SE} = \frac{1}{\sqrt{n - 3}}.</math>

也就是[[标准分数|Z-分數]]是

:<math>z = \frac{x - \text{mean}}{\text{SE}} = [F(r) - F(\rho_0)]\sqrt{n - 3}</math>

对<math>\rho = \rho_0</math> 进行[[零假设|零假设]]，可以设想样本数据对是[[独立同分布|独立同分布]]并且服从[[双变量正态分布|双变量正态分布]]。因此[[P值|P值]]估计可以从正态分布概率表中获得。比如，如果观测数据 ''z'' = 2.2，并且要用双尾p值对 <math>\rho = 0</math>进行零假设检验，p值是 2·Φ(−2.2) = 0.028， 其中''Φ''是正态分布的[[累积分布函数|累积分布函数]]。

===置信区间===
为了获得''ρ''的置信区间，首先，我们应该计算 ''F''(''<math>\rho</math>'')的置信区间：
:<math>100(1 - \alpha)\%\text{CI}: \operatorname{arctanh}(\rho) \in [\operatorname{arctanh}(r) \pm z_{\alpha/2}SE]</math>

通过可逆Fisher变换可以获得相关尺度上的区间。
:<math>100(1 - \alpha)\%\text{CI}: \rho \in [\operatorname{tanh}(\operatorname{arctanh}(r) - z_{\alpha/2}SE), \operatorname{tanh}(\operatorname{arctanh}(r) + z_{\alpha/2}SE)]</math>

举例来说，假设我们观测到 ''r'' = 0.3，样本容量 ''n''=50，并且我们期望获得''ρ''的95%的置信区间。变换后的值是artanh(''r'') = 0.30952，所以在变换尺度上的置信区间是 0.30952 ± 1.96/√47，或者 (0.023624, 0.595415)。变换回相关尺度上是 (0.024, 0.534)。

==皮尔逊相关系数和最小方差回归分析==
样本相关系数的平方，亦称作[[决定系数|决定系数]], 利用[[线性回归|简单线性回归]]估计由''X''引起的 ''Y''的变化。 一开始,  ''Y''<sub>''i''</sub> 围绕它们平均值上的变化可以分解成

:<math>
\sum_i (Y_i - \bar{Y})^2 = \sum_i (Y_i-\hat{Y}_i)^2 + \sum_i (\hat{Y}_i-\bar{Y})^2,
</math>

其中 <math>\hat{Y}_i</math> 是作回归分析时的适应值。  整理后得

:<math>
1 = \frac{\sum_i (Y_i-\hat{Y}_i)^2}{\sum_i (Y_i - \bar{Y})^2} + \frac{\sum_i (\hat{Y}_i-\bar{Y})^2}{\sum_i (Y_i - \bar{Y})^2}.
</math>

两个被加数是由''X'' (右边)引起的''Y''的变化和不是由''X'' (左边) 引起的变化。

接下来, 我们利用最小方差回归模型, 使 <math>\hat{Y}_i</math> 和 <math>Y_i-\hat{Y}_i</math> 的样本协方差为0。  于是, 观测数据和适应值的样本相关系数可以被写成

<math>
\begin{align}
r(Y,\hat{Y}) &= \frac{\sum_i(Y_i-\bar{Y})(\hat{Y}_i-\bar{Y})}{\sqrt{\sum_i(Y_i-\bar{Y})^2\cdot \sum_i(\hat{Y}_i-\bar{Y})^2}}\\
&= \frac{\sum_i(Y_i-\hat{Y}_i+\hat{Y}_i-\bar{Y})(\hat{Y}_i-\bar{Y})}{\sqrt{\sum_i(Y_i-\bar{Y})^2\cdot \sum_i(\hat{Y}_i-\bar{Y})^2}}\\
&= \frac{ \sum_i [(Y_i-\hat{Y}_i)(\hat{Y}_i-\bar{Y}) +(\hat{Y}_i-\bar{Y})^2 ]}{\sqrt{\sum_i(Y_i-\bar{Y})^2\cdot \sum_i(\hat{Y}_i-\bar{Y})^2}}\\
&= \frac{ \sum_i (\hat{Y}_i-\bar{Y})^2 }{\sqrt{\sum_i(Y_i-\bar{Y})^2\cdot \sum_i(\hat{Y}_i-\bar{Y})^2}}\\

&= \sqrt{\frac{\sum_i(\hat{Y}_i-\bar{Y})^2}{\sum_i(Y_i-\bar{Y})^2}}.
\end{align}
</math>

于是

:<math>
r(Y,\hat{Y})^2 = \frac{\sum_i(\hat{Y}_i-\bar{Y})^2}{\sum_i(Y_i-\bar{Y})^2}
</math>

是由''X''的线性方程引起的 ''Y'' 的平均变化。

==数据分布的敏感度==
===存在性===
总体皮尔逊相关系数被定义成 [[矩_(數學)|矩]]，因此任意的双变量[[概率分布|概率分布]]是非零的，也就是说是由[[总体|总体]][[协方差|协方差]]和[[边缘分布|边缘]][[方差|总体方差]]定义的。一些概率分布，如[[柯西分布|柯西分布]]的方差未定义，因此若''X''或''Y''服从这种分布，ρ便是未定义的。在实际应用中，若有懷疑数据服从[[重尾分布|重尾分布]]，就需要重视這个条件。然而，相关系数的存在性通常無關緊要，例如若分布有界，則ρ必有意义。

===大样本的特性===
在双变量[[正态分布|正态分布]]的案例中，只要边缘均值和方差是已知的，总体相关系数描述的是便是联合分布。在其他的双变量分布中，这个结论并不正确。总之，不论两个随机变量的联合分布是不是正态的，相关系数都對研究它们之间的线性依赖性有帮助。<ref name="thirteenways"/>样本相关系数是对两个正态分布变量总体相关系数的[[最大似然估计|最大似然估计]]，并且是[[渐进分布|渐进]][[估计量的偏差|无偏]]和{{link-yue|效率 (統計學)|效率 (統計學)|有效率}}的。換言之，如果数据是遵循正态分佈，并且样本容量不太小，就不可能构造出一个比样本相关系数更准确的估计。对于非正态的数据，样本相关系数大致上是无偏的，但有可能是无效的。只要样本均值、方差和协方差是一致的（当[[大數法則|大数定理]]可以应用的情况下），样本相关系数是总体相关系数的[[一致估计量|一致估计]] 。

===稳健性===
与其他常用的统计指标類似，样本指标''r''不{{link-yue|穩健統計|頑健統計|穩健}}<ref name="wilcox">{{Cite book| title=Introduction to robust estimation and hypothesis testing | last = Wilcox | first = Rand R. | publisher= Academic Press | year=2005}}</ref> 。因此如果由[[離群值|離群值]]，这个指标是有误导性的。<ref>{{Cite journal| title= Robust Estimation and Outlier Detection with Correlation Coefficients | url= https://archive.org/details/sim_biometrika_1975-12_62_3/page/531 | last= Devlin | first = Susan J | coauthors = Gnanadesikan, R; Kettenring J.R. | journal= Biometrika | volume= 62 |  issue= 3 |year=1975 | pages=531–545 | doi= 10.1093/biomet/62.3.531 | jstor=2335508}}</ref><ref>{{Cite book| title=Robust Statistics | last = Huber | first = Peter. J.| publisher= Wiley | year=2004}}{{Page needed|date=September 2010}}</ref>特别地，PMCC既不是稳健分布的{{Citation needed|date=November 2009}}，也不是异常值稳健的<ref name="wilcox"/> （見{{link-yue|穩健統計|頑健統計}}）。观察''X''和''Y''的[[散布图|散点图]]，可以認出是否缺乏稳健性，在这种情况下，采用的联合的方法是比较明智的。注意到，虽然大多数稳健的估计量，都有某程度的[[独立_(概率论)|统计依赖]]，但总括而言，在总体相关系数的尺度上都是可辨的。

基于皮尔逊相关系数的统计推断，对数据分布敏感。如果数据大致是正态分布的，可以使用精确检验和基于[[费雪变换|费雪变换]]的渐进检验，但是它们可能有误导性。在一些情况下，[[自助法|自助采样]]可以用来构造置信区间。同时，[[重抽样|重复抽样]]可以应用在假设检验中。这些[[無母數統計|非参数化]]的方法在某些情况下，如不能保证是双变量正态分布时，可能得出更有意义的结论。然而，这些方法的标准形式，依赖于数据要{{link-en|可交換隨機變量|exchangeable random variables|可交換}}。这也就意味着要分析的数据没有顺序的和组别之分，否則可能会影响估计相关系数的特性。

分层分析是一种容许缺少双变量正态性的方法，或者说是用来隔离相互关联因素的关联结果。如果''W''代表聚类成员或者其它需要控制的因素，則可以分离基于''W''的数据，然后可以再逐层计算相关系数。当控制变量''W''，便能在层的等级上估计与所有相关系数相关的各自的相关系数。<ref>Katz., Mitchell H. (2006) ''Multivariable Analysis - A Practical Guide for Clinicians''. 2nd Edition.  Cambridge University Press. ISBN 9780521549851. ISBN 052154985X {{DOI|10.2277/052154985X}}</ref>

==计算加权相关系数==
假设我们要计算关联性的观测数据有着不同的重要程度，表示成权值向量 ''w''。 利用权值向量''w'' (总长度 ''n'')计算向量 ''x'' 和 ''y'' 的相关系数,<ref>http://sci.tech-archive.net/Archive/sci.stat.math/2006-02/msg00171.html</ref><ref{{Dead link|date=2018年6月 |bot=InternetArchiveBot |fix-attempted=no }}>[http://www.mathworks.com/matlabcentral/fileexchange/20846 A MATLAB Toolbox for computing Weighted Correlation Coefficients] {{Wayback|url=http://www.mathworks.com/matlabcentral/fileexchange/20846 |date=20120224230118 }}</ref>

* 加权均值:

:: <math>\operatorname{m}(x; w) = {\sum_i w_i x_i \over \sum_i w_i}.</math>

* 加权协方差
:: <math>\operatorname{cov}(x,y;w) = {\sum_i w_i (x_i - \operatorname{m}(x; w)) (y_i - \operatorname{m}(y; w)) \over \sum_i w_i }.</math>

* 加权相关系数
:: <math>\operatorname{corr}(x,y;w) = {\operatorname{cov}(x,y;w) \over \sqrt{\operatorname{cov}(x,x;w) \operatorname{cov}(y,y;w)}}.</math>

==去除相关性==
我们总是可以通过一定的线性变换去除随机变量之间的相关性, 即便变量间的关系是非线性的。 Cox & Hinkley<ref>Cox, D.R., Hinkley, D.V. (1974) ''Theoretical Statistics'', Chapman & Hall (Appendix 3) ISBN 0412124203</ref>给出了在总体相关系数中的表达形式。

与此相应的，样本相关系数也存在这样的结论，使得样本相关系数变为0。假设长度为 ''n'' 的随机变量被随机采样 ''m'' 次。  令 ''X'' 是一个矩阵，其中 <math>X_{i,j}</math> 是第''i''次采样的第 ''j''个变量。  令 <math>Z_{m,m}</math> 是一个所有元素都为1的 ''m'' * ''m'' 的方阵。  那么 ''D'' 是变换后的数据，使得随机变量的均值为0, 并且 ''T'' 是变换后的数据，使得所有的变量均值为0和与除自身外的其他变量的相关系数为0 - ''T''的矩作为身份矩阵。 为了得到单位方差，还需要除以标准差。  虽然变换后的数据有可能不是[[Statistical_independence|独立的]]，但他们一定是不相关的。

:<math>D = X -\frac{1}{m} Z_{m,m} X</math>

<!-- extra blank line between two lines of "displayed" [[TeX|TeX]], for legibility -->

:<math>T = D (D^T D)^{-\frac{1}{2}}</math>

其中，指数-1/2表示矩阵置换后的 [[矩阵方根|矩阵方根]]。T的协方差被当做身份矩阵。如果新的样本数据x是n个元素的向量, 那么相同的变换可以应用到x中以获得变换向量d和t：

:<math>d = x - \frac{1}{m} Z_{1,m} X</math>

<!-- extra blank line between two lines of "displayed" [[TeX|TeX]], for legibility -->

:<math>t = d (D^T D)^{-\frac{1}{2}}</math>
这个去相关性的方法被应用到多变量的[[主成分分析|主成分分析]]中。

==反射相关性==
反射相关系数是皮尔逊相关系数的变体，数据并不是以他们的均值为中心。{{Citation needed|date=January 2011}}总体反射相关系数是

:<math>
\text{Corr}_r(X,Y) = \frac{E[XY]}{\sqrt{EX^2\cdot EY^2}}.
</math>

反射相关系数是对称的, 但在如下的变换中并不是不变的

:<math>
\text{Corr}_r(X, Y) = \text{Corr}_r(Y, X) = \text{Corr}_r(X, bY) \neq \text{Corr}_r(X, a + b Y), \quad a \neq 0, b > 0.
</math>

样本反射相关系数是

:<math>
rr_{xy} = \frac{\sum x_i y_i}{\sqrt{(\sum x_i^2)(\sum y_i^2)}}.
</math>

样本加权相关系数是

:<math>
rr_{xy, w} = \frac{\sum w_i x_i y_i}{\sqrt{(\sum w_i x_i^2)(\sum w_i y_i^2)}}.
</math>


==比例关系==
规模的相关性是一个变种的皮尔森相关数据的范围限制故意以受控的方式揭示时间序列之间的快速成分的相关性。比例相关的定义是在短数据段的平均相关性。
对于给定规模S，令K为可以适应信号的总长度的段数：
:<math>
\mathbf{K}=\mathbf{Sound}\left( \frac{T}{s} \right)
</math>
比例相关的整个信号的r<sub>s</sub>的计算公式为
:<math>
\overrightarrow{r_s}=\frac{1}{K}\sum_{k=1}^K r_k
</math>
r<sub>s</sub>为k的部分皮尔森相关系数。
通过对参数s的选择，减少值的范围和较长的时间尺度上的相关性被过滤掉，只有在很短的时间尺度上的相关性被发现。因此，慢分量的贡献被删除，快分量被保留。

==强噪声条件下==
强噪声条件下，提取相关系数两个随机变量之间的是平凡的，特别是在典型相关分析报告在退化的相关值的情况下，由于存在大量噪声。一种概括的方法在其他地方给出。

==相關條目==
* [[安斯库姆四重奏|安斯库姆四重奏]]
* [[相關_(概率論)|相關]]
* [[斯皮尔曼等级相关系数|斯皮尔曼等级相关系数]](Spearman's rank correlation coefficient)
* {{le|回归衰减|Regression dilution}}
* {{le|最大信息系数|Maximal information coefficient}}
* [[圖模式|圖模式]]
* [[马尔可夫链|马尔可夫链]]
* [[马尔可夫逻辑网络|马尔可夫逻辑网络]]

==外部連結==
* [http://mail.cmu.edu.tw/~tcli/%B2%C4%A4Q%A4%BB%B3%B9.pdf 相關係數：使用皮爾森檢定與斯皮爾曼等級檢定的研究問題]{{Dead link|date=2018年6月 |bot=InternetArchiveBot |fix-attempted=no }}（中國醫藥大學，生物統計課程）
* [http://www2.cmu.edu.tw/~biostat/online/teaching_corner_038-2.pd 相關係數：資料型態與適用統計方法]{{Dead link|date=2018年6月 |bot=InternetArchiveBot |fix-attempted=no }}（中國醫藥大學，生物統計課程）

==註腳==
{{notefoot}}
==参考资料==
{{reflist|2}}

{{Statistics}}

{{DEFAULTSORT:Pearson Product-Moment Correlation Coefficient}}
[[Category:协方差与相关性|Category:协方差与相关性]]
[[Category:统计学比率|Category:统计学比率]]

[[ru:Корреляция#Линейный_коэффициент_корреляции|ru:Корреляция#Линейный коэффициент корреляции]]