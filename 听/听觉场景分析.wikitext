{{multiple issues|
{{copyedit|time=2012-03-23T03:05:49+00:00}}
{{orphan|time=2012-03-23T03:05:49+00:00}}
}}
在计算机听觉研究领域里，'''听觉场景分析'''是由类比[[计算机视觉|计算机视觉]]研究中的“视觉场景分析”概念而建立的声音信号处理模型。听觉场景分析部分借助于[[格式塔学派|格式塔学派]]提出的规则来研究听觉组织的加工过程。
它包括：
* 初级分析：着重研究序列整合与同时性整合；
* 图式加工：涉及到注意与知识的作用以及言语知觉的特殊性等；
场景分析能够较好地说明简单音和复合音的知觉组织过程，但目前尚不能很全面地解释言语加工过程，故其理论仍然存在一定局限性。

== 研究状况 ==

人类对于声音信号的处理依据有哪些规则？对于这个问题，[[认知心理学|认知心理学]]很早就有了较为全面的答案。Bergman在1990年对此方面的研究进行了详尽的整理，总结出了以格式塔规则为基础的一系列感知结论，首次提出了“听觉场景分析”的概念。
<ref>A. S. Bregman. Auditory Scene Analysis. MIT Press, Cambridge, MA, 1990.</ref>。

而在此之前，Weintraub于1985年就已建立了世界上第一个模拟单耳声源分离原理的人工[[听觉|听觉]]系统，将两个声音信号成功分离<ref>M. Weintraub. A Theory and Computational Model of Auditory Monaural Sound Separation. PhD thesis, Stanford University, August 1985.</ref>。这便成为了听觉场景分析模型的雏形。后续的研究沿着类似的思想，不断地对模型进行完善<ref>M. P. Cooke. Modelling Auditory Processing and Organization. PhD thesis, University of Sheffield, 1991.</ref><ref>G. Hu and D. L. Wang. Monaural speech segregation based on pitch tracking and amplitude modulation. IEEE Transactions on Neural Networks,  15(5):1135-1150,2004.</ref><ref>Martin Cooke. A glimpsing model of speech perception in noise. J. Acoust. Soc. Am. 119(3), March 2006.</ref>。到2006年，根据人类听觉信号处理规则和特点建立起来的听觉场景分析模型已经相当完善，能够较好地将基频分布范围内处于相同频带上的多个声音信号同时进行分离。

== 参考 ==
<references />

[[Category:信息技术|T]]