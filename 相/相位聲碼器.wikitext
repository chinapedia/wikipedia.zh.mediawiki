{{copypaste|time=2019-03-10T11:50:59+00:00}}
{{unreferenced|time=2019-03-10T11:50:59+00:00}}
<!-- 檔案不存在 [[File:Autotuneevo6.jpg|thumb]]。]] ，可從英文維基百科取得 -->
'''相位聲碼器'''是[[聲碼器|聲碼器]]的一種，它藉由改變聲音訊號的[[相位|相位]]資訊，而達到音訊時域與頻域上的延展。時域與頻域的延展分別對應到此音訊在時間上的縮放（速度快慢改變），與聲音音高的改變。

==原理==

相位聲碼器的與傳統聲碼器最主要的差別在於：不同於傳統聲碼器將音訊切割成多個頻帶，相位聲碼器是使用[[短時距傅立葉變換|短時距傅立葉變換]]（STFT），得到不只各頻格(frequency bin)的強度(ampiltude)，也得到相位(phase)的資訊。此技術之所以被稱為「相角」音碼器，是因為我們把聲音訊號轉為頻譜之後， 並非只是單純地在強度頻譜上，時間或者頻率的維度內插，還必須考慮相角與頻率的關係，並在相角頻譜上進行相對應的調整。相位聲碼器將特定頻率分量的振幅或相位修改後，透過反向短時傅立葉轉換(inverse STFT)將頻譜還原成時域的音訊。若改變STFT音框在時間上的位置，可以改變重新合成的聲音的時間演變。

==STFT的物理意義==

===振幅===
由於傅立葉轉換的物理意義，是將一段訊號表示為許多正弦波成分(sinusoid component)之疊加，現假設訊號的取樣率(sampling rate)為R，則Xm[k]可視為在第m個音框之中，頻率落在R⋅ k 附近的正弦波成分；而Xm[k]的強度就是這個正弦N波成分的振幅(amplitude)，它的平方就是這個正弦波成分的能量(energy)大小。然而根據訊號處理的原理，若訊號的取樣率為R，至多只能觀察到頻率為 R/2，也就是小於或等於[[奈奎斯特頻率|奈奎斯特頻率]](Nyquist frequency)的正弦波成分。
因此經由短時間傅立葉轉換得到的頻譜，實際上只有前(N/2 +1)個元素是有效的，之後的元素皆對稱於第 ( N /2+1) 個元素，與之前的元素為[[共軛複數|共軛複數]]對(complex conjugate pairs)。

===相位===
至於頻譜中的另一個成分: 相角，其物理意義則與正弦波成分的「瞬時頻率」(instantaneous frequency)有關。
考慮兩個相鄰音框中，同樣位於第 k 個頻道(frequency channel)的頻譜元素：X(m,k)以及 X(m−1,k)。這兩個元素的相角差(phase difference)除以音框平移時間量 Δt ，計算第 m 個音框的第 k 個頻率箱中，正弦波成分的角速度ω(m,k) :

ω(m,k) =2π⋅f(m,k)<br />

=Δθ/Δt <br />

= (∠X(m,k)−∠X(m−1,k))/Δt<br />

其中Δθ ≥0, f(m,k) 即為瞬時頻率。

從另一個方向來說,此正弦波成分之所以落在第 k 個頻道中,就是因為它的頻率位於此頻道所代表的頻率值範圍之內。它的頻率可以表示為此頻道的中心頻率 f(k) ，加上一個極小的頻率值:

f(m,k) = f(k) +  δ(m,k)/Δt<br />

其中 f(k)= R⋅k/N ， δ(m,k) 是一個極小的相角改變量。<br />


利用頻譜上相鄰音框的第 k 個頻率箱成分之相角差，可以計算此正弦波成分之瞬時頻率。但在實際情況中，相角只會落在一個 2π 的區間之內,因而無法得知真實的相角差。利用上式將相角差分為兩項，一項是落在此頻率箱的正弦波必然具有之相角改變量，另一項則記錄了漏未計算的相角改變量:

∠X(m,k)−∠X(m−1,k)= 2πk ⋅Δn/N+δ(m,k)<br />

其中 Δn = Δt ⋅ R 是音框平移的取樣值數目。<br />

因此 ( 2π k/N ⋅ Δn) 代表的是一個頻率為 f(k)= R⋅k/N 的正弦波，在經過時間 Δt 之後的相角改變量。
之後將δ(m,k)加上或減去2π,直到0≤δ(m,k)<2π，並重新加上2πk⋅Δn。如此一來就可以得到一個大於 0 的相角差值。
 以上的步驟稱為「相位重建」(phase unwrapping)。
注意到如果δ(m,k)在訊號中真實的相角變化超過 2π，會使得相位重建無法實行。 因此必須限制時間框的平移量。

==相位連貫性問題==

在操縱短時傅里葉變換的時，會遇到的一大問題，是各個信號分量（正弦信號，脈衝）將分散在多個時間框，以及頻譜的多個頻格。這是因為STFT分析是通過使用重疊分析[[窗函數|窗函數]]。
如果考慮的是離散的時間軸，則我們對一離散訊號 x[n] 進行短時間傅立葉轉換，可表示為：

X(η,ω)= ∑x[n]w[n−η]exp(−jωn)    for n= -∞ to ∞

其中 n 跟η 為離散時間索引(discrete time index)，ω 為頻率索引，w[n] 為離散窗函數。

經過窗函數的訊號使得單個正弦分量的信息分佈在相鄰的時間框中。為了避免邊界效應，短時傅里葉分析的時間框會有時間上的重疊。這樣的重疊使相鄰的時間框有強烈的相關性（一個存在於時間“t”時間框中的正弦成分，在時間"t+1"中也會存在）。因此相位聲碼器的信號轉換問題涉及到相位連貫性的問題，也就是在做短時傅里葉與反向短時傅里葉後，相鄰的頻格應仍要保有適當的連貫性（縱向的連貫性）；而相鄰的時間框也會要保有適當的連貫性（橫向連貫性）。除極其簡單的聲音合成外，這些連貫性只能大概的被保留，而相位聲碼器的研究的主要關心便是找出適當的演算法，足以保存修改後的短時間傅立葉分析表示的垂直和水平的連貫性。時間縮放操作幅度的連貫性是一個較次要的問題，因為改變時間框在振幅上只有微小的影響。


==歷史==

相位聲碼器的演算法最初於1966年由Flanagan提出，可保存頻格相位水平水平的連貫性。這種原始相位聲碼器沒有顧及相鄰頻格之間的縱向的連貫性，因此這個系統做的時間縮放得到的聲音信號不清晰。

在 1981 年，波氏(Michael R. Portnoff)首先提出利用短時間傅立葉轉換 ，將聲音轉入頻域，並在不影響音高的前提之 下調整速度，亦即時間量度調整(time-scale modification)；之後在 1982 年，齊氏(Stephanie Seneff)同樣提出利用短時間傅立葉轉換，並導入音源—濾波器分解 (source-filter decomposition)的觀念，在不改變速度的前提之下，調整聲音檔案的音高，亦即音高平移(pitch shifting)。將這兩項技術結合，便是所謂「相角音碼器」 的雛形。

Griffin 和Lim在1984年提出將短時傅立葉轉換後的聲音訊號最佳化重建的演算法。此演算法不考慮連貫性的問題，但它能找到一個擁有與修改過後類似的短時傅立葉轉換的聲音信號；即便修改後的短時傅里葉轉換是不連貫的（不代表任何信號）。
縱向的連貫性的問題，直到1999年仍然是一個重大的問題，直到Laroche和Dolson提出了一個相當簡單的手段來保持頻格的相位連貫性。Laroche和Dolson的發現造成相位聲碼器歷史的一個轉折點。有了垂直相位的連貫性，聲音訊號可以得到很高品質的時間縮放。

==音樂==

如今相位聲碼器的技術被包裝成編曲工具[[auto-tune|auto-tune]]，被廣泛運用在流行音樂當中，不僅可以透過時間縮放達到調整音樂節拍的效果；還可以藉由音高的微調，將音訊量化到指定的音高，達到修正走音的功能，也可以將人聲轉換成類似機器人的聲音，或是高頻類似花栗鼠的聲線。