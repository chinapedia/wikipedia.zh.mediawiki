{{expert|time=2014-09-30T15:39:12+00:00}}
{{nofootnotes|time=2014-09-30T15:39:12+00:00}}
'''霍普菲爾德神经网络'''(Hopfield neural network)是一种[[循环神经网络|循环神经网络]]，由[[约翰·霍普菲尔德|约翰·霍普菲尔德]]在1982年发明。Hopfield网络是一种[[结合存储|结合存储]]系统和[[二元|二元]]系统的神经网络。它保证了向[[局部极小|局部极小]]的收敛，但收敛到错误的局部极小值（local minimum），而非全局极小（global minimum）的情况也可能发生。霍普菲尔德网络也提供了模拟人类记忆的模型。

== 构造 ==
[[Image:Hopfield-net.png|thumb]]
霍普菲尔德网络的单元是二元的（binary），即这些单元只能接受两个不同的值，并且值取决于输入的大小是否达到阈值。Hopfield网络通常接受值为-1或1，也可以是0或者1。输入是由[[sigmoid函数|sigmoid函数]]处理得到的。 sigmoid函数定义为：

<math>S(t) = \frac{1}{1 + e^{-t}}</math>，

用于将输入化简为两个极值。

每一对霍普菲尔德网络的单元''i''和''j''间都有一对以一定权重（weight）的连接<math> w_{ij} </math>。因此，霍普菲尔德网络可被描述为一个完整的[[无向图|无向图]]<math> G = <V, f> </math>，其中<math>V</math>是[[人工神经元|人工神经元]]集合。 

霍普菲尔德网络的连接有以下特征：
* <math>w_{ii}=0, \forall i</math> （没有神经元和自身相连）
* <math>w_{ij} = w_{ji}, \forall i,j</math> （连接权重是对称的）

权重对称的要求是一个重要特征，因为它保证了能量方程（称向函数某一点收敛的过程为势能转化为能量）在神经元激活时单调递减，而不对称的权重可能导致周期性的递增或者噪声。然而，霍普菲尔德网络也证明噪声过程会被局限在很小的范围，并且并不影响网络的最终性能。

==更新==
使用下述公式更新霍普菲尔德中节点的值:

<math>s_i \leftarrow \left\{\begin{array}{ll} +1 & \mbox {if }\sum_{j}{w_{ji}s_j}\geq\theta_i, \\
 -1 & \mbox {otherwise.}\end{array}\right.</math>

公式中：
* <math>w_{ji}</math> 是节点j到节点i的权重。
* <math>s_i</math> 节点i的值（状态s）.
* <math>\theta_i</math> 节点i的阈值，常为0.

霍普菲尔德的更新有两种方式：
* '''异步''': 每个更新一个节点。此节点可以是随机选中的，也可是按照预设顺序选中的。
* '''同步''': 同时更新所有节点的状态。这种更新方式要求系统中具有中央时钟以便维持同步。这种方式被认为是不太现实的，因为在生物或物理系统中常常没有中央时钟（用于保持同步状态，即各个节点常常是自行其是的。）

==参见==
* [[玻尔兹曼机|玻尔兹曼机]] – 像一个霍普菲尔德网络，可采用退火吉布斯抽样代替梯度下降
*[[受限玻尔兹曼机|受限玻尔兹曼机]]
* [[易辛模型|易辛模型]]
* [[赫布理论|赫布理论]]

==参考文献==
{{Reflist}}

{{Refbegin}}
* J. J. Hopfield, "Neural networks and physical systems with emergent collective computational abilities", ''Proceedings of the National Academy of Sciences of the USA'', vol. 79 no. 8 pp. 2554–2558, April 1982.

* Hebb, D.O. (1949). Organization of behavior. New York: Wiley

* Hertz, J., Krogh, A., & Palmer, R.G. (1991). Introduction to the theory of neural computation. Redwood City, CA: Addison-Wesley.

* McCullough, W.S., & Pitts, W.H. (1943). A logical calculus of the ideas immanent in nervous activity. Bulletin of Mathematical Biophysics,5, 115-133

* Polyn, S.M., & Kahana, M.J. (2008). Memory search and the neural representation of context. Trends in Cognitive Sciences, 12, 24-30.

* Rizzuto, D.S., & Kahana, M.J. (2001). An autoassociative neural network model of paired-associate learning. Neural Computation, 13, 2075-2092.

* Kruse, Borgelt, Klawonn, Moewes, Russ, Steinbrecher (2011). Computational Intelligence.

{{Refend}}

== 外部链接 ==
{{commons|Hopfield net}}
* Chapter 13 [http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf The Hopfield model]{{Wayback|url=http://page.mi.fu-berlin.de/rojas/neural/chapter/K13.pdf |date=20160303192200 }} of [http://page.mi.fu-berlin.de/rojas/neural/index.html.html ''Neural Networks - A Systematic Introduction'']{{Wayback|url=http://page.mi.fu-berlin.de/rojas/neural/index.html.html |date=20160122162741 }} by Raul Rojas (ISBN 978-3-540-60505-8)
*[https://web.archive.org/web/20130521214528/http://www.heatonresearch.com/articles/61/page1.html Hopfield Neural Network Applet]
*[http://ai4r.org Hopfield Neural Network implementation in Ruby (AI4R)]{{Wayback|url=http://ai4r.org/ |date=20161023184847 }}
*[http://to-campos.planetaclix.pt/neural/hope.html The Travelling Salesman Problem]{{Wayback|url=http://to-campos.planetaclix.pt/neural/hope.html |date=20150530022419 }} - Hopfield Neural Network JAVA Applet
*[http://www.scholarpedia.org/article/Hopfield_network scholarpedia.org- Hopfield network]{{Wayback|url=http://www.scholarpedia.org/article/Hopfield_network |date=20151208142252 }} - Article on Hopfield Networks by John Hopfield
*[https://web.archive.org/web/20111005202201/http://www.tristanfletcher.co.uk/DLVHopfield.pdf Hopfield Network Learning Using Deterministic Latent Variables] - Tutorial by Tristan Fletcher
*[https://web.archive.org/web/20121025125326/http://gna.org/projects/neurallab/ Neural Lab Graphical Interface] - Hopfield Neural Network graphical interface (Python & gtk)

{{Stochastic processes}}

[[Category:神經網路|Category:神經網路]]