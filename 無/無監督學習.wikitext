{{expand|time=2018-04-15T01:00:11+00:00}}
{{expert|time=2018-04-15T01:00:11+00:00}}
{{noteTA
|G1=IT
}}
{{机器学习导航栏}}
'''無監督學習'''（{{lang-en|unsupervised learning}}），又稱非監督式學習，是[[機器學習|機器學習]]的一種方法，沒有給定事先標記過的訓練範例，自動對輸入的資料進行分類或分群。無監督學習的主要運用包含：[[聚类分析|聚类分析]]（cluster analysis）、[[關聯規則學習|關聯規則]]（association rule）、維度縮減（dimensionality reduce）。它是[[監督式學習|監督式學習]]和[[強化學習|強化學習]]等策略之外的一種選擇。

一個常見的無監督學習是[[数据聚类|数据聚类]]。在[[人工神經網路|人工神經網路]]中，[[生成對抗網絡|生成對抗網絡]]（GAN）、[[自組織映射|自組織映射]]（SOM）和[[適應性共振理論|適應性共振理論]]（ART）則是最常用的非監督式學習。

ART模型允許叢集的個數可隨著問題的大小而變動，並讓使用者控制成員和同一個叢集之間的相似度分數，其方式為透過一個由使用者自定而被稱為[[警覺參數|警覺參數]]的常數。ART也用於[[模式識別|模式識別]]，如[[自動目標辨識|自動目標辨識]]和[[數位信號處理|數位信號處理]]。第一個版本為"ART1"，是由卡本特和葛羅斯柏格所發展的。

== 方法 ==
非監督式學習常使用的方法有很多種，包括：
*[[聚類分析|分群法]]
**[[K-平均演算法|K-平均演算法]]
**[[混合模型|混合模型]]
**[[階層式分群|階層式分群]]
*[[異常檢測|異常檢測]]
*[[自編碼|自編碼]]
*{{le|深度置信网络|Deep belief network}}
*[[赫布理論|赫布學習]]
*[[生成對抗網路|生成對抗網路]]
*[[自組織映射|自組織映射]]
*學習[[潛在變數模型|潛在變數模型]]的方法
**[[最大期望演算法|最大期望演算法]]
**[[矩估計|矩估計]]
**[[盲信號分離|盲信號分離]]技術，例如：
***[[主成份分析|主成份分析]]
***[[獨立成份分析|獨立成份分析]]
***{{le|非負矩陣分解|Non-negative matrix factorization}}
***[[奇異值分解|奇異值分解]]

== 另見 ==
* [[無監督式學習網路|無監督式學習網路]]
* [[人工神經網路|人工神經網路]]
* [[數據聚類|數據聚類]]
* [[最大期望演算法|最大期望演算法]]

== 參考文獻 ==
{{reflist}}
{{reflist|list=
*[[Geoffrey_Hinton|Geoffrey Hinton]], [[Terrence_J._Sejnowski|Terrence J. Sejnowski]]（editors，1999) Unsupervised Learning and Map Formation: Foundations of Neural Computation, MIT Press, ISBN 0-262-58168-X（這本書專注於[[人工神經網路|人工神經網路]]的非監督式學習）
*S. Kotsiantis, P. Pintelas, Recent Advances in Clustering: A Brief Survey, WSEAS Transactions on Information Science and Applications, Vol 1, No 1 (73-81), 2004.
*Richard O. Duda, Peter E. Hart, David G. Stork. Unsupervised Learning and Clustering, Ch. 10 in ''Pattern classification'' (2nd edition), p. 571, Wiley, New York, ISBN 0-471-05669-3, 2001.
}}

{{-}}
{{Computer Science}}

[[Category:機器學習|Category:機器學習]]