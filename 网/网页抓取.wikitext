{{NoteTA|G1=IT}}
{{unreferenced|time=2016-03-15T16:04:52+00:00}}
'''网页抓取'''（{{lang-en|web scraping}}）是一种从网页上获取页面内容的计算机软件技术。通常透過软件使用低级别的[[超文本传输协议|超文本传输协议]]模仿人类的正常访问。

网页抓取和网页索引极其相似，其中网页索引指的是大多数[[搜索引擎|搜索引擎]]采用使用的[[机器人|机器人]]或[[网络爬虫|网络爬虫]]等技术。与此相反，网页抓取更侧重于转换网络上非结构化数据（常见的是HTML格式）成为能在一个中央[[数据库|数据库和]][[电子表格|电子表格]]中储存和分析的结构化数据。网页抓取也涉及到网络自动化，它利用计算机软件模拟了人的浏览。网页抓取的用途包括在线的价格比较，联系人抓取，气象数据监测，网页变化检测，科研，[[混搭_(互聯網)|混搭]]和Web数据集成。

== 技术层面 ==
网络抓取用于自动化获取[[万维网|万维网]]上的信息

*人工复制与粘贴：最好的网页抓取技术也比不上人类的手工复制与粘贴，尤其是在某些网站采取技术手段禁止自动化网页抓取的情况下，人工的复制与粘贴就成了唯一的解决方案。

*文本搜索与正则表达式：文本搜索并且配合正则表达式可以有效的从页面上提取需要的内容。在基于UNIX的系统上可以使用grep，在其他平台或其他编程语言（例如[[Perl|Perl]]，[[Python|Python]]）中也有相应的命令或语法。

*基于HTTP编程：无论是[[静态网页|静态网页]]还是[[动态网页|动态网页]]均可以通过发送HTTP请求给服务器来获得，所以可以通过直接进行[[socket编程|socket编程]]来实现。

*HTML语法分析器：很多网站都是使用数据库来存储他们的数据，用户访问的时候再通过程序自动按照指定的格式生成，由于生成的这些网页都采用了相同的的格式或者模板等，所以可以通过对获取到的HTML页面使用语法分析器进行语法分析，然后就可以使用[[HTML标签|HTML标签]]来提取需要的内容。使用HTML语法分析器同文本搜索与正则表达式相比较程序更加的[[鲁棒性_(计算机科学)|健壮]]，也免于构造复杂的正则表达式。

==著名工具==
{{colbegin|3}}
* [[Apache_Camel|Apache Camel]]
* [[archive.is|archive.is]]
* [[Automation_Anywhere|Automation Anywhere]]
* [[Convertigo|Convertigo]]
* [[cURL|cURL]]
* [[Data_Toolbar|Data Toolbar]]
* [[Diffbot|Diffbot]]
* [[Firebug|Firebug]]
* [[Greasemonkey|Greasemonkey]]
* [[Heritrix|Heritrix]]
* [[HtmlUnit|HtmlUnit]]
* [[HTTrack|HTTrack]]
* [[iMacros|iMacros]]
* [[Import.io|Import.io]]
* [[Aptana#Aptana_Jaxer|Jaxer]]
* [[Node.js|Node.js]]
* [[nokogiri|nokogiri]]
* [[PhantomJS|PhantomJS]]
* [[ScraperWiki|ScraperWiki]]
* [[Scrapy|Scrapy]]
* [[Selenium|Selenium]]
* [[SimpleTest|SimpleTest]]
* [[UiPath|UiPath]]
* [[watir|watir]]
* [[Wget|Wget]]
* [[Wireshark|Wireshark]]
* [[WSO2_Mashup_Server|WSO2 Mashup Server]]
* [[Yahoo!_Query_Language|Yahoo! Query Language]] (YQL)
{{colend}}

==参见==
{{colbegin|3}}
* [[网络爬虫|网络爬虫]]
{{colend}}
[[Category:网页抓取|Category:网页抓取]]