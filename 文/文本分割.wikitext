{{Expert needed|time=2020-10-07T14:59:16+00:00}}
{{NoteTA|G1=IT|time=2016-03-12T10:20:50+00:00}}
'''文本分割'''（Text segmentation）将书面文本分割成有意义单位的过程，如单词、句子或主题。这个术语既适用于人类阅读文本时的心理过程，也适用于在计算机中实现的人工过程，后者属于[[自然语言处理|自然语言处理]]的领域。一些书面语言有明确的单词分界标记，例如英语的词之间有[[空格|空格]]标识，阿拉伯语有独特的首、中、末字母形状，但这种标记不是所有书面语言都有。

== 分割问题 ==
=== 分词 ===
分词（Word segmentation）是将一串书面语言分成其组成词的问题。中文分词指的是使用[[电子计算机|计算机]]自动对[[中文|中文]]文本进行[[词语|词语]]的切分，即像英文那样使得中文句子中的词之间有[[空格|空格]]以标识。中文分词被认为是中文[[自然语言处理|自然语言处理]]中的一个最基本的环节。

Unicode联盟已经发表了一个关于文本分割的标准附件<ref>{{Cite web |url=http://unicode.org/reports/tr29/ |title=UAX #29 |access-date=2020-10-07 |archive-date=2020-12-16 |archive-url=https://web.archive.org/web/20201216060956/http://unicode.org/reports/tr29/ |dead-url=no }}</ref>。

=== 意图分割 ===
意图分割（Intent segmentation）是将书面语言分割为关键词（2个或2个以上的词组）的问题。

== 参考文献 ==
{{reflist}}

== 外部連結 ==
*[http://ckipsvr.iis.sinica.edu.tw/ 中央研究院資訊科學所詞庫小組的中文斷詞系統] {{Wayback|url=http://ckipsvr.iis.sinica.edu.tw/ |date=20131207195736 }}
*[https://api.droidtown.co/ 卓騰語言科技 - 基於句法規則的中文斷詞系統 (同時完成 POS 和 NER 標記)] {{Wayback|url=https://api.droidtown.co/ |date=20191223150653 }}
*[https://archive.is/20130705181751/http://www.zhihuita.org/service/zh.tokenizer 基于机器学习的智慧塔中文分词系统]

{{自然语言处理}}

[[Category:自然语言处理|Category:自然语言处理]]
[[Category:计算语言学|Category:计算语言学]]
[[Category:汉字信息处理|Category:汉字信息处理]]