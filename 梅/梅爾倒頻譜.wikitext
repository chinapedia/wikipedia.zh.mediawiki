{{mergefrom|梅尔频率倒谱系数}}
{{orphan|time=2015-07-02T16:55:39+00:00}}

{{NoteTA
|G1 = IT
|G2 = Electronics
|G3 = Communication
}}

在[[訊號處理|訊號處理]]中，'''梅爾倒頻譜'''（Mel-Frequency Cepstrum, MFC）係一個可用來代表短期音訊的頻譜，其原理基于用非線性的[[梅爾刻度|梅爾刻度]]（mel scale）表示的對數[[頻譜|頻譜]]及其線性餘弦轉換（linear cosine transform）上。

[[梅尔频率倒谱系数|梅尔频率倒谱系数]]（Mel-Frequency Cepstral Coefficients, MFCC）是一組用來建立梅爾倒頻譜的關鍵係數。由音樂訊號當中的片段，可以得到一組足以代表此音樂訊號之[[倒頻譜|倒頻譜]]（Cepstrum），而梅爾倒頻譜係數即是從這個倒頻譜中推得的倒頻譜（也就是頻譜的頻譜）。與一般的倒頻譜不同 ，梅爾倒頻譜最大的特色在於，於梅爾倒頻譜上的頻帶是均勻分布於梅爾刻度上的，也就是說，這樣的頻帶相較於一般所看到、線性的倒頻譜表示方法，和人類非線性的[[聽覺系統|聽覺系統]]更為接近。例如：在音訊壓縮的技術中，便常常使用梅爾倒頻譜來處理。

梅爾倒頻譜係數通常是用以下方法得到的：<ref>{{cite book | chapter = HMM-based audio keyword generation | author = Min Xu et al. | title = Advances in Multimedia Information Processing – PCM 2004: 5th Pacific Rim Conference on Multimedia | editor = Kiyoharu Aizawa, Yuichi Nakamura, Shin'ichi Satoh | publisher = Springer | year = 2004 | isbn = 3-540-23985-5 | url = http://cemnet.ntu.edu.sg/home/asltchia/publication/AudioAnalysisUnderstanding/Conference/HMM-Based%20Audio%20Keyword%20Generation.pdf | access-date = 2015-07-02 | archive-date = 2007-05-10 | archive-url = https://web.archive.org/web/20070510193153/http://cemnet.ntu.edu.sg/home/asltchia/publication/AudioAnalysisUnderstanding/Conference/HMM-Based%20Audio%20Keyword%20Generation.pdf | dead-url = yes }}</ref><ref>{{cite journal|last=Sahidullah|first=Md.|author2=Saha, Goutam|title=Design, analysis and experimental evaluation of block based transformation in MFCC computation for speaker recognition|journal=Speech Communication|date=May 2012|volume=54|issue=4|pages=543–565|doi=10.1016/j.specom.2011.11.004|url=http://www.sciencedirect.com/science/article/pii/S0167639311001622|access-date=2015-07-02|archive-date=2015-09-24|archive-url=https://web.archive.org/web/20150924163941/http://www.sciencedirect.com/science/article/pii/S0167639311001622|dead-url=no}}</ref>

#將一訊號進行[[傅利葉轉換|傅利葉轉換]]
#利用[[三角窗函數|三角窗函數]]（triangular overlapping window），將頻譜映射（mapping）至梅爾刻度
#取[[對數|對數]]
#取[[離散餘弦轉換|離散餘弦轉換]]
#MFCC是轉換後的頻譜

取得梅爾倒頻譜的方法眾多，上述只是其中一種。

另外，ETSI在2000年左右有定義一套專為行動電話設計的梅爾倒頻譜係數演算法。

==應用==

梅爾倒頻譜係數通常可以用於作為[[语音识别|语音识别]]系統中的特徵質觀察，例如：可以自動辨認一個人透過電話說的數字。梅爾倒頻譜係數通常也可以作為[[声纹识别|声纹识别]]（Speaker Recognition），也就是、用來辨識某段語音訊號的發話者是誰的技術。

梅爾倒頻譜係數在近年來於音樂分類（music genre classification）相關應用的領域也逐漸嶄露頭角，例如尋找一段音樂的相似程度等。
<ref>
{{cite book
 | title = Information Retrieval for Music and Motion
 | author = Meinard Müller
 | publisher = Springer
 | year = 2007
 | isbn = 978-3-540-74047-6
 | page = 65
 | url = http://books.google.com/books?id=kSzeZWR2yDsC&pg=PA65&dq=mfcc+music+applications#PPA65,M1
 }}</ref>

===語音辨識===

梅爾頻率倒譜係數MFCC和感知線性預測PLP：不同於LPC等通過對人的發聲機理的研究而得到的聲學特徵，Mel倒譜係數MFCC和感知線性預測PLP是受人的聽覺系統研究成果推動而導出的聲學特徵。對人的聽覺機理的研究發現，當兩個頻率相近的音調同時發出時，人只能聽到一個音調。臨界帶寬指的就是這樣一種令人的主觀感覺發生突變的帶寬邊界，當兩個音調的頻率差小於臨界帶寬時，人就會把兩個音調聽成一個，這稱之為屏蔽效應。Mel刻度是對這一臨界帶寬的度量方法之一。
MFCC的計算首先用FFT將時域信號轉化成頻域，之後對其對數能量譜用依照Mel刻度分布的三角濾波器組進行卷積，最後對各個濾波器的輸出構成的向量進行離散餘弦變換DCT，取前N個係數。PLP仍用德賓法去計算LPC參數，但在計算自相關參數時用的也是對聽覺激勵的對數能量譜進行DCT的方法。

==雜訊==

梅爾倒頻譜係數並非相當穩定，在計算當中，一組係數其實相當容易受到外加的雜訊影響；為了對抗雜訊，通常會將梅爾倒頻譜係數在語音辨認上進行正規化（normalization）的動作，以減少雜訊造成的影響。

另外，有些研究者會將梅爾倒頻譜係數基礎的演算法設計的更加頑強，例如：在進行餘弦轉換前增加對數化梅爾係數的能量值至一個合適的範圍，以減少諸如雜訊等低能量項對於整個係數結果的影響。

==歷史==

一般認為Paul Mermelstein<ref name=merm76>P. Mermelstein (1976), "[http://books.google.com/books?id=wW9QAAAAMAAJ&q=%22Distance+measures+for+speech+recognition,+psychological+and+instrumental%22&dq=%22Distance+measures+for+speech+recognition,+psychological+and+instrumental%22&lr=&as_brr=0&as_pt=ALLTYPES&ei=zdRmSZjKLoH4lQTfqaXhBg&pgis=1 Distance measures for speech recognition, psychological and instrumental," in ''Pattern Recognition and Artificial Intelligence],'' C. H. Chen, Ed., pp. 374–388. Academic, New York.</ref><ref name=merm80>S.B. Davis, and P. Mermelstein (1980), "[http://books.google.com/books?id=yjzCra5eW3AC&pg=PA65&dq=cosine+mel+pols&lr=&as_brr=3&ei=ytJmSZGLNI6ukAThwuGxCA#PPA65,M1 Comparison of Parametric Representations for Monosyllabic Word Recognition in Continuously Spoken Sentences]," in ''IEEE Transactions on Acoustics, Speech, and Signal Processing'', 28(4), pp. 357–366.</ref> 是主要致力於發展梅爾倒頻譜的人，然而 Mermelstein 本人卻將主要的概念功勞歸給 Bridle 和 Brown<ref>J. S. Bridle and M. D. Brown (1974), "An Experimental Automatic Word-Recognition System", JSRU Report No. 1003, Joint Speech Research Unit, Ruislip, England.</ref> for the idea:

<blockquote>
Bridle 和 Brown 運用了一組十九個、由餘弦轉換導出的頻譜型的係數，轉換的輸入值是訊號在一組在頻帶上有非均勻間隔分布的[[帶通濾波器|帶通濾波器]]後的輸出。

濾波器的間隔是呈現對數分布的；因此，一般稱之為梅爾式的導頻譜係數<ref name=merm76/>
</blockquote>

通常此兩組起源都會被人當作參照使用。

另外，許多作者包括Mermelstein都認為，梅爾倒頻譜中這樣以頻譜為基準的餘弦轉換函式，非常接近早期用於語音表徵和辨認、對對數化頻譜進型的主成分分析；關於這部分相關的資訊，可參考Pols和它同事的研究。<ref>L. C. W. Pols (1966), "Spectral Analysis and Identification of Dutch Vowels in Monosyllabic Words," Doctoral dissertion, Free University, Amsterdam, The Netherlands</ref><ref>R. Plomp, L. C. W. Pols, and J. P. van de Geer (1967). "[http://dare.uva.nl/document/36194 Dimensional analysis of vowel spectra] {{Wayback|url=http://dare.uva.nl/document/36194 |date=20120702045502 }}." ''J. Acoustical Society of America,'' 41(3):707–712.</ref>

==係數推導==

1. 對該信號做[[傅立葉變換|傅立葉變換]]


<math>X[k]=FT{x[n]}</math>


2. 根據下面公式算出Y[m]


<math>Y[m]=\log \left( \sum_{k=f_{m-1}}^{f_{m+1}} \left| X[k] \right|^2 B_m[k] \right)</math><br>


其中<math>B_m[k]</math>是梅爾頻率倒頻譜的遮罩


<math>B_m[k]= \begin{cases} 0 & \mbox{for } k<f_{m-1} \mbox{ and } k>f_{m+1}\\ 
\cfrac {k-f_{m-1}}{f_m-f_{m-1}} & \mbox{for } f_{m-1} \leq k \leq f_m \\
\cfrac {f_{m+1}-k}{f_{m+1}-f_m} & \mbox{for } f_m \leq k \leq f_{m+1}  \end{cases}</math>


3.對Y[m]做IDCT得<math>c_x[n]</math>，因為Y[m]是偶函數,故用IDCT(反離散餘弦變換)取代IDFT(反離散傅立葉變換)


<math>c_x[n]= \frac{1}{M} \sum_{m=1}^{M} Y[m]cos \left( \cfrac{\pi n(m-1/2)}{M} \right) </math><br>


==參考==
{{reflist}}

[[Category:信号处理|Category:信号处理]]