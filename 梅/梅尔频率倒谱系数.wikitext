{{mergeto|梅爾倒頻譜}}
{{NoteTA|G1=Signals and Systems}}
在聲音處理領域中，'''梅爾頻率倒譜'''(Mel-Frequency Cepstrum)是基於聲音頻率的非線性[[梅爾刻度|梅爾刻度]](mel scale)的[[對數|對數]]能量頻譜的線性變換。

'''梅爾頻率倒譜系數''' ('''Mel-Frequency Cepstral Coefficients，MFCCs''')就是組成梅爾頻率倒譜的係數。它衍生自音訊片段的[[倒頻譜|倒頻譜]](cepstrum)。倒譜和梅爾頻率倒譜的區別在於，梅爾頻率倒譜的頻帶劃分是在[[梅爾刻度|梅爾刻度]]上等距劃分的，它比用於正常的對數[[倒頻譜|倒頻譜]]中的線性間隔的頻帶更能近似人類的聽覺系統。
這樣的非線性表示，可以在多個領域中使聲音信號有更好的表示。例如在[[音訊壓縮|音訊壓縮]]中。

梅爾頻率倒譜係數（MFCC）廣泛被應用於[[語音識別|語音識別]]的功能。他們由Davis和Mermelstein在1980年代提出，並在其後持續是最先進的技術之一。在MFCC之前，線性預測係數（LPCS）和線性預測倒譜系數（LPCCs）是自動語音識別的的主流方法。


MFCC通常有以下之過程:<ref>{{cite book | chapter = HMM-based audio keyword generation | author = Min Xu ''et al.'' | title = Advances in Multimedia Information Processing - PCM 2004: 5th Pacific Rim Conference on Multimedia | editor = Kiyoharu Aizawa, Yuichi Nakamura, Shin'ichi Satoh | publisher = Springer | year = 2004 | isbn = 3-540-23985-5 | url = http://cemnet.ntu.edu.sg/home/asltchia/publication/AudioAnalysisUnderstanding/Conference/HMM-Based%20Audio%20Keyword%20Generation.pdf | access-date = 2013-04-26 | archive-date = 2007-05-10 | archive-url = https://web.archive.org/web/20070510193153/http://cemnet.ntu.edu.sg/home/asltchia/publication/AudioAnalysisUnderstanding/Conference/HMM-Based%20Audio%20Keyword%20Generation.pdf | dead-url = yes }}</ref><ref>{{cite journal|last=Sahidullah|first=Md.|coauthors=Saha, Goutam|title=Design, analysis and experimental evaluation of block based transformation in MFCC computation for speaker recognition|journal=Speech Communication|volume=54|issue=4|pages=543–565|doi=10.1016/j.specom.2011.11.004|url=http://www.sciencedirect.com/science/article/pii/S0167639311001622|date=May 2012|access-date=2013-04-26|archive-date=2015-09-24|archive-url=https://web.archive.org/web/20150924163941/http://www.sciencedirect.com/science/article/pii/S0167639311001622|dead-url=no}}</ref>

# 將一段語音信號分解為多個[[訊框|訊框]]。
# 將語音信號[[預強化|預強化]]，通過一個[[高通濾波器|高通濾波器]]。
# 進行[[傅立叶变换|傅立叶变换]]，將信號轉換至頻域。
# 將每個[[訊框|訊框]]獲得的频譜通過梅爾濾波器(三角重叠窗口)，得到[[梅爾刻度|梅爾刻度]]。
# 在每个梅爾刻度上提取[[對數|對數]]能量。
# 对上面获得的结果进行[[離散餘弦轉換|離散餘弦轉換]]，轉換到[[倒頻譜|倒頻譜]]域。
# MFCC就是這個[[倒频谱|倒频谱]]图的幅度(amplitudes)。一般使用12個係數，與訊框能量疊加得13維的係數。

===MFCC的原理===

聲音信號是連續變化的，為了將連續變化信號簡化，我們假設在一個短時間尺度內，音頻信號不發生改變。因此將信號以多個取樣點集合成一個單位，稱為[['''訊框'''|'''訊框''']]。一個訊框多為20-40毫秒，如果訊框長度更短，那每個訊框內的取樣點將不足以做出可靠的頻譜計算，但若長度太長，則每個訊框信號會變化太大。

'''預強化'''的目的就是為了消除發聲過程中，聲帶和嘴唇造成的效應，來補償語音信號受到發音系統所壓抑的高頻部分。並且能突顯高頻的共振峰。

由於訊號在時域上的變化通常很難看出訊號的特性，所以通常透過[[傅立葉轉換|傅立葉轉換]]將它轉換成頻域上的能量分佈來觀察，不同的能量分佈，就能代表不同語音的特性。

由於能量頻譜中還存在大量的無用訊息，尤其人耳無法分辨高頻的頻率變化，因此讓頻譜通過梅爾濾波器。
'''梅爾濾波器'''，也就是一組20個非線性分布的'''三角帶通濾波器（Triangular Bandpass Filters）'''，能求得每一個濾波器輸出的對數能量。必須注意的是：這 20 個三角帶通濾波器在[['''梅爾刻度'''|'''梅爾刻度''']]的頻率上是平均分佈的。
梅爾頻率代表一般人耳對於頻率的感受度，由此也可以看出人耳對於頻率 f 的感受是呈對數變化的。


http://i.stack.imgur.com/YUH48.gif {{Wayback|url=http://i.stack.imgur.com/YUH48.gif |date=20130627223941 }}


最後的步驟是計算對數濾波器的能量的[[離散傅立葉反變換|離散傅立葉反變換]]，在此相當於離散餘弦反變換(IDCT)。值得注意的是，雖然通常的會有24-26個係數，但我們只保留前12個係數。這是因為丟棄高[[倒頻域|倒頻域]]值的DCT係數，代表一個類似低通濾波器的概念，可以使信號平滑化，能增進語音處理的性能。

<ref>{{Cite web |url=http://mirlab.org/jang/books/audiosignalprocessing/speechFeatureMfcc_chinese.asp?title=12-2+MFCC |title=存档副本 |accessdate=2014-06-27 |archive-date=2015-09-21 |archive-url=https://web.archive.org/web/20150921222357/http://mirlab.org/jang/books/audiosignalprocessing/speechFeatureMfcc_chinese.asp?title=12-2+MFCC |dead-url=no }}</ref>
<ref>{{Cite web |url=http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/ |title=存档副本 |accessdate=2014-06-27 |archive-date=2014-06-27 |archive-url=https://web.archive.org/web/20140627130711/http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/ |dead-url=no }}</ref>
<ref>http://djj.ee.ntu.edu.tw/ADSP_tutorial_D98921028.pdf{{dead link|date=2018年3月 |bot=InternetArchiveBot |fix-attempted=yes }}</ref>



在此过程中可以有很多变化，例如，映射时的窗口的形状和间距。<ref>Fang Zheng, Guoliang Zhang and Zhanjiang Song (2001), "[http://link.springer.com/article/10.1007%2FBF02943243?LI=true#page-1 Comparison of Different Implementations of MFCC] {{Wayback|url=http://link.springer.com/article/10.1007%2FBF02943243?LI=true#page-1 |date=20140202104247 }}," ''J. Computer Science & Technology,'' 16(6): 582–589.</ref> The [[欧洲电信标准协会|欧洲电信标准协会]]在2000年初定义了一个可以用在移动电话上的标准MFCC算法.<ref name="etsi01">European Telecommunications Standards Institute (2003), [http://webapp.etsi.org/workprogram/Report_WorkItem.asp?wki_id=18820 Speech Processing, Transmission and Quality Aspects (STQ); Distributed speech recognition; Front-end feature extraction algorithm; Compression algorithms] {{Wayback|url=http://webapp.etsi.org/workprogram/Report_WorkItem.asp?wki_id=18820 |date=20050315110721 }}. Technical standard ES 201 108, v1.1.3.</ref>



===參考===
{{Reflist}}

== 詳細推導 ==
1.對該信號做[[傅立葉變換|傅立葉變換]]<br>
X[k]=FT{x[n]}<br>
2.根據下面公式算出Y[m]<br>
<math>Y[m]=\log \left( \sum_{k=f_{m-1}}^{f_{m+1}} \left| X[k] \right|^2 B_m[k] \right)</math><br>

其中<math>B_m[k]</math>是梅爾頻率倒頻譜的遮罩<br>
[[File:B_m-k-.png|有框]]
<math>B_m[k]= \begin{cases} 0 & \mbox{for } k<f_{m-1} \mbox{ and } k>f_{m+1}\\ 
\cfrac {k-f_{m-1}}{f_m-f_{m-1}} & \mbox{for } f_{m-1} \leq k \leq f_m \\
\cfrac {f_{m+1}-k}{f_{m+1}-f_m} & \mbox{for } f_m \leq k \leq f_{m+1}  \end{cases}</math><br>

3.對Y[m]做IDCT得<math>c_x[n]</math><br>
因為Y[m]是偶函數,故用IDCT(反離散餘弦變換)取代IDFT(反離散傅立葉變換)<br>
<math>c_x[n]= \frac{1}{M} \sum_{m=1}^{M} Y[m]cos \left( \cfrac{\pi n(m-1/2)}{M} \right) </math><br>
<br>
與原倒頻譜的差異<br>
一.log裡面因為使用了sum,故等於0的機率變小<br>
二.避免了相位的問題<br>
三.使用IDCT取代IDFT,減少了運算量<br>
四.<math>B_m[k]</math>隨著頻率的增加而增寬,該特性符合人類聽覺,更適合用來描述語音特徵<br>

== 应用 ==

MFCC主要作为[[语音识别|语音识别]]系统中的特征，这样的系统可以自动识别语音中的数字内容。MFCC同样也用于{{Link-en|说话人识别|Speaker Recognition}}，该技术尝试通过语音该鉴别说话人。<ref>T. Ganchev, N. Fakotakis, and G. Kokkinakis (2005), "[http://www.wcl.ece.upatras.gr/ganchev/Papers/ganchev17.pdf Comparative evaluation of various MFCC implementations on the speaker verification task] {{webarchive|url=https://web.archive.org/web/20110717210107/http://www.wcl.ece.upatras.gr/ganchev/Papers/ganchev17.pdf |date=2011-07-17 }}," in ''10th International Conference on Speech and Computer (SPECOM 2005),'' Vol. 1, pp. 191–194.</ref>

MFCC也被用于{{Link-en|语音信息检索|music information retrieval}}领域，如流派分类(genre classification)、音频相似性计算等。<ref>
{{cite book
 | title = Information Retrieval for Music and Motion
 | author = Meinard Müller
 | publisher = Springer
 | year = 2007
 | isbn = 978-3-540-74047-6
 | page = 65
 | url = http://books.google.com/books?id=kSzeZWR2yDsC&pg=PA65&dq=mfcc+music+applications#PPA65,M1
 }}</ref>

<br>比起倒頻譜,梅爾倒頻譜更接近人耳對於語音的區別性(因為遮罩<math>B[k]</math>)<br>
用<math>c_x[1],c_x[2],...,c_x[13]</math>,MFCCs的前13項足以描述語音特徵<br>

==噪声的敏感性==

MFCC特征在加性噪声的情况下并不稳定，因此在语音识别系统中通常要对其进行归一化处理(normalise)以降低噪声的影响。一些研究人员对MFCC算法进行修改以提升其強健性，如在进行DCT之前将log-mel-amplitudes提升到一个合适的能量(2到3之间)，以此来降低低能量成分的影响.<ref>V. Tyagi and C. Wellekens (2005), {{doi-inline|10.1109/ICASSP.2005.1415167|On desensitizing the Mel-Cepstrum to spurious spectral components for Robust Speech Recognition}}, in Acoustics, Speech, and Signal Processing, 2005. Proceedings. (ICASSP ’05). IEEE International Conference on, vol. 1, pp. 529–532.</ref>

== 参考文献 ==

{{reflist}}

==外部链接==
*[http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/ A tutorial on MFCCs for Automatic Speech Recognition] {{Wayback|url=http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/ |date=20130301055837 }}

[[Category:信号处理|Category:信号处理]]