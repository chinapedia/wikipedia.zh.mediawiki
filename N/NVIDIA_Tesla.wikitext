{{noteTA|G1=IT}}
{{Otheruses|Tesla}}
{{infobox Hardware
| name        = Tesla
| image       = 634218_Badge_Tesla_3D.jpg
| caption     = 2007年開始使用的Tesla標誌
| invent-date = 
| invent-name = [[NVIDIA|NVIDIA]]
| type        = [[圖形處理器|圖形處理器]]
| introduced  = 2007年
}}
'''Tesla'''是一個[[NVIDIA|NVIDIA]]的[[GPU|顯示核心]]系列品牌，主要用於[[伺服器|伺服器]]高性能電腦運算，用於對抗[[AMD|AMD]]的[[FireStream|FireStream]]系列。這是继[[NVIDIA_GeForce|GeForce]]和[[NVIDIA_Quadro|Quadro]]之后，第三个顯示核心商标。NVIDIA將顯示核心分為三大系列。GeForce用於提供家庭娛樂；Quadro用於專業繪圖設計；Tesla用於大規模的並聯電腦運算。

Tesla以發明家[[尼古拉·特斯拉|尼古拉·特斯拉]]的名字命名。

==產品系列==
[[File:NvidiaTesla.jpg|thumb]]
目前，Tesla有三個系列：
*Tesla GPU运算处理器 - 外形與普通顯示卡大致相同，C870採用[[GeForce_8|GeForce 8]]顯示核心，而C1060採用[[GeForce_200|GeForce 200]]顯示核心，不設任何顯示輸出。
*Tesla GPU Deskside Supercomputer - 桌面平台用，外形與[[QuadroPlex|QuadroPlex]]相似，D870包含兩張C870运算处理器，可透過接線互联多個裝置。Tesla 10系列中沒有相關產品。
*Tesla GPU Server - [[服务器|服务器]]用，外形與1U伺服器相似，S870包含四張C870运算处理器，而S1070包含四張C1060运算处理器，可透過接線互联多個裝置。

較早的時候，人們已意識到[[GPU|GPU]]能運算大量數據。所以开发者通过图形语言，利用顯示核心，來进行并行计算，亦即是GPGPU（通用繪圖核心）。但开发者需要有一定程度的图形处理知識，才能發揮顯示核心效能。隨後，NVIDIA推出了[[CUDA|CUDA]]。开发者利用[[C++语言|C++语言]]，再通過CUDA编译器，就能利用顯核運算。开发者可忽略图形处理技術，而直接利用熟悉的C++语言。开发者和科学家，就可以利用顯示核心，研究[[物理|物理]]、[[生化|生化]]和[[勘探|勘探]]等領域。

Tesla比較專注於高性能運算，并且C1060以上（G200）系列能支援双精度浮点格式。另一方面，CUDA被所有的NVIDIA顯示核心支援，包括GeForce和Quadro系列。

將來，顯示核心能普及化地，輔助[[中央處理器|中央處理器]]，進行[[视频|视频]][[压缩|压缩]]、[[数据库|数据库]]搜索等工作。並支援更多程式語言，例如[[Fortran|Fortran]]、[[C++|C++]]、[[JAVA|JAVA]]和[[Python|Python]]等。

== 完整型號列表 ==
{{main|NVIDIA顯示核心列表}}
{| class="wikitable sortable " style="font-size: 80%; text-align: center;"
|-
! rowspan=2 style="width:16em" | Model
! rowspan=2 | [[微架構|微架構]]
! rowspan=2 | Launch
! rowspan=2 | Chips
! rowspan=2 | Core clock<br/>([[Hertz|MHz]])
! colspan=3 | Shaders
! colspan=5 | Memory
! colspan=3 | Processing power ([[每秒浮點運算次數|每秒浮點運算次數]]){{efn|name="Calculate"|group="NvidiaTesla"|To calculate the processing power see {{link-en|Tesla (microarchitecture)}}, {{link-en|Fermi (microarchitecture)}}, [[Kepler_(微架构)|Kepler (微架构)]],  {{link-en|Maxwell (microarchitecture)}}, or [[帕斯卡_(微架构)|帕斯卡 (微架构)]]. A number range specifies the minimum and maximum processing power at, respectively, the base clock and maximum boost clock.}}
! rowspan=2 | CUDA<br/>compute<br/>ability{{efn|group="NvidiaTesla|Core architecture version according to the [[CUDA|CUDA]] programming guide.}}
! rowspan=2 | [[热设计功耗|热设计功耗]]<br/>(watts)
! rowspan=2 | Notes, form_factor
|-
! Cuda cores<br/>(total)
! Base clock ([[赫兹|赫兹]])
! Max boost<br/>clock ([[赫兹|赫兹]]){{efn|name="GPUBoost"|group="NvidiaTesla"|GPU Boost is a default feature that increases the core clock rate while remaining under the card's predetermined power budget. Multiple boost clocks are available, but this table lists the highest clock supported by each card.<ref>{{cite web |url=https://www.nvidia.com/content/PDF/kepler/nvidia-gpu-boost-tesla-k40-06767-001-v02.pdf |title=Nvidia GPU Boost For Tesla |date=January 2014 |access-date=7 December 2015 |archive-date=2020-05-16 |archive-url=https://web.archive.org/web/20200516090655/https://www.nvidia.com/content/PDF/kepler/nvidia-gpu-boost-tesla-k40-06767-001-v02.pdf |dead-url=no }}</ref>}}
! Bus type
! Bus width<br/>([[位元|位元]])
! Size<br/>([[吉字节|吉字节]])
! Clock<br/>({{link-en|Transfer (computing)}})
! Bandwidth<br/>([[吉字节|吉字节]]/s)
! [[單精度浮點數|單精度浮點數]]<br/>(MAD+MUL)
! [[單精度浮點數|單精度浮點數]]<br/>(MAD or [[乘積累加運算|乘積累加運算]])
! [[雙精度浮點數|雙精度浮點數]]<br/>([[乘積累加運算|乘積累加運算]])
|-
! Units !! !! !! !! !! !! MHz !! MHz !! !! !! !! !! !! !! !! !! !! W !!
|-
! style="text-align:left;" | C870 GPU Computing Module{{efn|group="NvidiaTesla"|name="Assumed8800"|Specifications not specified by Nvidia assumed to be based on the [[NVIDIA_GeForce_8|NVIDIA GeForce 8]]GTX}}
| rowspan=9 | {{link-en|Tesla (microarchitecture)}}
| May 2, 2007
| 1× G80
| 600
| 128
| 1350
| {{n/a}}
| GDDR3
| 384
| 1.5
| 1600
| 76.8
| 518.4
| 345.6
| {{no}}
| 1.0
| 170.9
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | D870 Deskside Computer{{efn|group="NvidiaTesla"|name="Assumed8800"}}
| May 2, 2007
| 2× G80
| 600
| 256
| 1350
| {{n/a}}
| GDDR3
| 2× 384
| 2× 1.5
| 1600
| 2× 76.8
| 1036.8
| 691.2
| {{no}}
| 1.0
| 520
| Deskside or 3U {{link-en|19-inch rack}} external GPUs
|- style="vertical-align:top;"
! style="text-align:left;" | S870 GPU Computing Server{{efn|group="NvidiaTesla"|name="Assumed8800"}}
| May 2, 2007
| 4× G80
| 600
| 512
| 1350
| {{n/a}}
| GDDR3
| 4× 384
| 4× 1.5
| 1600
| 4× 76.8
| 2073.6
| 1382.4
| {{no}}
| 1.0
|
| 1U {{link-en|19-inch rack}} external GPUs, connect via 2× PCIe (×16)
|- style="vertical-align:top;"
! style="text-align:left;" | C1060 GPU Computing Module{{efn|name="Assumed280"|group="NvidiaTesla"|Specifications not specified by Nvidia assumed to be based on the [[NVIDIA_GeForce_200|NVIDIA GeForce 200]]}}
| April 9, 2009
| 1× GT200
| 602
| 240
| 1296<ref>{{cite web |url=http://www.nvidia.com/docs/IO/56483/Tesla_C1060_boardSpec_v03.pdf |format=PDF |title=Tesla C1060 Computing Processor Board |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2020-11-24 |archive-url=https://web.archive.org/web/20201124222334/https://www.nvidia.com/docs/IO/56483/Tesla_C1060_boardSpec_v03.pdf |dead-url=no }}</ref>
| {{n/a}}
| GDDR3
| 512
| 4
| 1600
| 102.4
| 933.12
| 622.08
| 77.76
| 1.3
| 187.8
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | S1070 GPU Computing Server "400 configuration"{{efn|name="Assumed280"|group="NvidiaTesla"}}
| June 1, 2008
|rowspan=2| 4× GT200
|rowspan=2| 602
|rowspan=2| 960
| 1296
| {{n/a}}
|rowspan=2| GDDR3
|rowspan=2| 4× 512
|rowspan=2| 4× 4
|rowspan=2| 1538.4
|rowspan=2| 4× 98.5
| 3732.5
| 2488.3
| 311.0
|rowspan=2| 1.3
|rowspan=2| 800
|rowspan=2| 1U {{link-en|19-inch rack}} external GPUs, connect via 2× PCIe (×8 or ×16)
|- style="vertical-align:top;"
! style="text-align:left;" | S1070 GPU Computing Server "500 configuration"{{efn|name="Assumed280"|group="NvidiaTesla"}}
| 
| 1440
| {{n/a}}
| 4147.2
| 2764.8
| 345.6
|- style="vertical-align:top;"
! style="text-align:left;" | S1075 GPU Computing Server{{efn|name="Assumed280"|group="NvidiaTesla"}}<ref>{{cite web |url=http://forums.nvidia.com/index.php?showtopic=80850 |title=Difference between Tesla S1070 and S1075 |date=31 October 2008 |access-date=January 29, 2017 |quote=S1075 has one interface card |archive-date=2012-02-26 |archive-url=https://web.archive.org/web/20120226001759/http://forums.nvidia.com/index.php?showtopic=80850 |dead-url=no }}</ref>
| June 1, 2008
| 4× GT200
| 602
| 960
| 1440
| {{n/a}}
| GDDR3
| 4× 512
| 4× 4
| 1538.4
| 4× 98.5
| 4147.2
| 2764.8
| 345.6
| 1.3
|
| 1U {{link-en|19-inch rack}} external GPUs, connect via 1× PCIe (×8 or ×16)
|- style="vertical-align:top;"
! style="text-align:left;" | Quadro Plex 2200 D2 Visual Computing System{{efn|group="NvidiaTesla"|name="Assumed5800"|Specifications not specified by Nvidia assumed to be based on the Quadro FX 5800}}
| 
| 2× GT200GL
| 648
| 480
| 1296
| {{n/a}}
| GDDR3
| 2× 512
| 2× 4
| 1600
| 2× 102.4
| 1866.2
| 1244.2
| 155.5
| 1.3
|
| Deskside or 3U {{link-en|19-inch rack}} external GPUs with 4 dual-link DVI outputs
|- style="vertical-align:top;"
! style="text-align:left;" | Quadro Plex 2200 S4 Visual Computing System{{efn|group="NvidiaTesla"|name="Assumed5800"}}
| 
| 4× GT200GL
| 648
| 960
| 1296
| {{n/a}}
| GDDR3
| 4× 512
| 4× 4
| 1600
| 4× 102.4
| 3732.5
| 2488.3
| 311.0
| 1.3
| 1200
| 1U {{link-en|19-inch rack}} external GPUs, connect via 2× PCIe (×8 or ×16)
|- style="vertical-align:top;"
! style="text-align:left;" | C2050 GPU Computing Module<ref name="nvidia1">{{cite web |url=http://www.nvidia.com/docs/io/43395/tesla_c2050_board_specification.pdf |format=PDF |title=Tesla C2050 and Tesla C2070 Computing Processor |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2020-11-24 |archive-url=https://web.archive.org/web/20201124215355/https://www.nvidia.com/docs/io/43395/tesla_c2050_board_specification.pdf |dead-url=no }}</ref>
| rowspan=8 | {{link-en|Fermi (microarchitecture)}}
| July 25, 2011
|rowspan=2| 1× GF100
|rowspan=2| 575
|rowspan=2| 448
|rowspan=2| 1150
| {{n/a}}
|rowspan=2| GDDR5
|rowspan=2| 384
|rowspan=2| 3{{efn|name="ECC"|group="NvidiaTesla|With ECC on, a portion of the dedicated memory is used for ECC bits, so the available user memory is reduced by 12.5%. (e.g. 4 GB total memory yields 3.5 GB of user available memory.)}}
| 3000
| 144
| {{no}}
|rowspan=2| 1030.4
|rowspan=2| 515.2
|rowspan=2| 2.0
| 247
|rowspan=2| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | M2050 GPU Computing Module<ref>{{cite web |url=http://www.nvidia.com/docs/io/43395/bd-05238-001_v03.pdf |format=PDF |title=Tesla M2050 and Tesla M2070/M2070Q Dual-Slot Computing Processor Modules |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2020-11-24 |archive-url=https://web.archive.org/web/20201124215116/https://www.nvidia.com/docs/io/43395/bd-05238-001_v03.pdf |dead-url=no }}</ref>
| July 25, 2011
| {{n/a}}
| 3092
| 148.4
| {{no}}
| 225
|- style="vertical-align:top;"
! style="text-align:left;" | C2070 GPU Computing Module<ref name="nvidia1"/>
| July 25, 2011
|rowspan=3| 1× GF100
|rowspan=3| 575
|rowspan=3| 448
|rowspan=3| 1150
| {{n/a}}
|rowspan=3| GDDR5
|rowspan=3| 384
|rowspan=3| 6{{efn|name="ECC"|group="NvidiaTesla"}}
| 3000
| 144
| {{no}}
|rowspan=3| 1030.4
|rowspan=3| 515.2
|rowspan=3| 2.0
| 247
|rowspan=3| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | C2075 GPU Computing Module<ref>{{cite web |url=https://www.nvidia.com/docs/IO/43395/BD-05880-001_v02.pdf |format=PDF |title=Tesla C2075 Computing Processor Board |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2020-11-24 |archive-url=https://web.archive.org/web/20201124212405/https://www.nvidia.com/docs/IO/43395/BD-05880-001_v02.pdf |dead-url=no }}</ref>
| July 25, 2011
| {{n/a}}
| 3000
| 144
| {{no}}
| 225
|- style="vertical-align:top;"
! style="text-align:left;" | M2070/M2070Q GPU Computing Module<ref>{{cite web |last=Hand |first=Randall |url=http://www.vizworld.com/2010/08/nvidia-tesla-m2050-m2070m2070q-specs-online/ |title=NVidia Tesla M2050 & M2070/M2070Q Specs OnlineVizWorld.com |website=VizWorld.com |date=2010-08-23 |accessdate=2015-12-11 |archive-date=2020-08-17 |archive-url=https://web.archive.org/web/20200817185337/https://vizworld.com/2010/08/nvidia-tesla-m2050-m2070m2070q-specs-online/ |dead-url=no }}</ref>
| July 25, 2011
| {{n/a}}
| 3132
| 150.336
| {{no}}
| 225
|- style="vertical-align:top;"
! style="text-align:left;" | M2090 GPU Computing Module<ref>{{cite web |url=http://www.nvidia.com/docs/IO/43395/Tesla-M2090-Board-Specification.pdf |format=PDF |title=Tesla M2090 Dual-Slot Computing Processor Module |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2020-10-26 |archive-url=https://web.archive.org/web/20201026170151/https://www.nvidia.com/docs/IO/43395/Tesla-M2090-Board-Specification.pdf |dead-url=no }}</ref>
| July 25, 2011
| 1× GF110
| 650
| 512
| 1300
| {{n/a}}
| GDDR5
| 384
| 6{{efn|name="ECC"|group="NvidiaTesla"}}
| 3700
| 177.6
| {{no}}
| 1331.2
| 665.6
| 2.0
| 225
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | S2050 GPU Computing Server
| July 25, 2011
|rowspan=2| 4× GF100
|rowspan=2| 575
|rowspan=2| 1792
|rowspan=2| 1150
| {{n/a}}
|rowspan=2| GDDR5
|rowspan=2| 4× 384
| 4× 3{{efn|name="ECC"|group="NvidiaTesla"}}
|rowspan=2| 3
|rowspan=2| 4× 148.4
| {{no}}
|rowspan=2| 4121.6
|rowspan=2| 2060.8
|rowspan=2| 2.0
|rowspan=2| 900
|rowspan=2| 1U {{link-en|19-inch rack}} external GPUs, connect via 2× PCIe (×8 or ×16)
|- style="vertical-align:top;"
! style="text-align:left;" | S2070 GPU Computing Server
| 
| {{n/a}}
| 4× 6{{efn|name="ECC"|group="NvidiaTesla"}}
| {{no}}
|- style="vertical-align:top;"
! style="text-align:left;" | K10 GPU accelerator<ref>{{cite web |url=http://www.nvidia.com/content/PDF/kepler/Tesla_K10_BD-06280-001_v05.pdf |format=PDF |title=Tesla K10 GPU accelerator |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2020-11-24 |archive-url=https://web.archive.org/web/20201124214105/https://www.nvidia.com/content/PDF/kepler/Tesla_K10_BD-06280-001_v05.pdf |dead-url=no }}</ref>
| rowspan=5 | [[Kepler_(微架构)|Kepler (微架构)]]
| May 1, 2012
| 2× GK104
| {{n/a}}
| 3072
| 745
| {{dunno}}
| GDDR5
| 2× 256
| 2× 4
| 5000
| 2× 160
| {{no}}
| 4577
| 190.7
| 3.0
| 225
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | K20 GPU accelerator<ref>{{cite web |url=http://www.nvidia.com/content/PDF/kepler/Tesla-K20-Active-BD-06499-001-v02.pdf |format=PDF |title=Tesla K20 GPU active accelerator |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2017-07-12 |archive-url=https://web.archive.org/web/20170712234519/http://www.nvidia.com/content/PDF/kepler/Tesla-K20-Active-BD-06499-001-v02.pdf |dead-url=no }}</ref><ref>{{cite web |url=https://www.nvidia.com/content/PDF/kepler/Tesla-K20-Passive-BD-06455-001-v05.pdf |format=PDF |title=Tesla K20 GPU accelerator |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2020-03-26 |archive-url=https://web.archive.org/web/20200326145257/https://www.nvidia.com/content/PDF/kepler/Tesla-K20-Passive-BD-06455-001-v05.pdf |dead-url=no }}</ref>
| November 12, 2012
| 1× GK110
| {{n/a}}
| 2496
| 706
| 758
| GDDR5
| 320
| 5
| 5200
| 208
| {{no}}
| 3524
| 1175
| 3.5
| 225
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | K20X GPU accelerator<ref>{{cite web |url=http://www.nvidia.com/content/pdf/kepler/tesla-k20x-bd-06397-001-v07.pdf |format=PDF |title=Tesla K20X GPU accelerator |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2020-11-24 |archive-url=https://web.archive.org/web/20201124204809/https://www.nvidia.com/content/pdf/kepler/tesla-k20x-bd-06397-001-v07.pdf |dead-url=no }}</ref>
| November 12, 2012
| 1× GK110
| {{n/a}}
| 2688
| 732
| {{dunno}}
| GDDR5
| 384
| 6
| 5200
| 250
| {{no}}
| 3935
| 1312
| 3.5
| 235
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | K40 GPU accelerator<ref>{{cite web |url=http://www.nvidia.com/content/PDF/kepler/Tesla-K40-PCIe-Passive-Board-Spec-BD-06902-001_v05.pdf |format=PDF |title=Tesla K40 GPU accelerator |website=Nvidia.com |accessdate=2015-12-11 |archive-date=2020-06-17 |archive-url=https://web.archive.org/web/20200617151953/https://www.nvidia.com/content/PDF/kepler/Tesla-K40-PCIe-Passive-Board-Spec-BD-06902-001_v05.pdf |dead-url=no }}</ref>
| October 8, 2013
| 1× GK110B
| {{n/a}}
| 2880
| 745
| 875
| GDDR5
| 384
| 12{{efn|name="ECC"|group="NvidiaTesla"}}
| 6000
| 288
| {{no}}
| 4291–5040
| 1430–1680
| 3.5
| 235
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | K80 GPU accelerator<ref>{{cite web |url=http://images.nvidia.com/content/pdf/kepler/Tesla-K80-BoardSpec-07317-001-v05.pdf |format=PDF |title=Tesla K80 GPU accelerator |website=Images.nvidia.com |accessdate=2015-12-11 |archive-date=2018-07-12 |archive-url=https://web.archive.org/web/20180712151016/http://images.nvidia.com/content/pdf/kepler/Tesla-K80-BoardSpec-07317-001-v05.pdf |dead-url=no }}</ref>
| November 17, 2014
| 2× GK210
| {{n/a}}
| 4992
| 560
| 875
| GDDR5
| 2× 384
| 2× 12
| 5000
| 2× 240
| {{no}}
| 5591–8736
| 1864–2912
| 3.7
| 300
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | M4 GPU accelerator<ref name="anandtech1">{{cite web |url=http://www.anandtech.com/show/9776/nvidia-announces-tesla-m40-m4-server-cards-data-center-machine-learning |title=Nvidia Announces Tesla M40 & M4 Server Cards - Data Center Machine Learning |website=Anandtech.com |date= |accessdate=2015-12-11 |archive-date=2020-11-08 |archive-url=https://web.archive.org/web/20201108124231/https://www.anandtech.com/show/9776/nvidia-announces-tesla-m40-m4-server-cards-data-center-machine-learning |dead-url=no }}</ref><ref name="nvidia2">{{cite web |url=http://devblogs.nvidia.com/parallelforall/accelerating-hyperscale-datacenter-applications-tesla-gpus/ |title=Accelerating Hyperscale Datacenter Applications with Tesla GPUs | Parallel Forall |website=Devblogs.nvidia.com |date=2015-11-10 |accessdate=2015-12-11 |archive-date=2017-07-09 |archive-url=https://web.archive.org/web/20170709172435/https://devblogs.nvidia.com/parallelforall/accelerating-hyperscale-datacenter-applications-tesla-gpus/ |dead-url=no }}</ref>
| rowspan=5 | {{link-en|Maxwell (microarchitecture)}}
| November 10, 2015
| 1× GM206
| {{n/a}}
| 1024
| 872
| 1072
| GDDR5
| 128
| 4
| 5500
| 88
| {{no}}
| 1786–2195
| 55.81–68.61
| 5.2
| 50–75
| Internal PCIe GPU (half-height, single-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | M6 GPU accelerator<ref>{{cite web |url=http://images.nvidia.com/content/pdf/tesla/tesla-m6-product-brief.pdf |format=PDF |title=Tesla M6 |website=Images.nvidia.com |accessdate=2016-05-28 |archive-date=2020-10-22 |archive-url=https://web.archive.org/web/20201022155840/http://images.nvidia.com/content/pdf/tesla/tesla-m6-product-brief.pdf |dead-url=no }}</ref>
| August 30, 2015
| 1× GM204-995-A1
| {{n/a}}
| 1536
| 722
| 1051
| GDDR5
| 256
| 8
| 4600
| 147.2
| {{no}}
| 2218–3229
| 69.3–100.9
| 5.2
| 75–100
| Internal MXM GPU
|- style="vertical-align:top;"
! style="text-align:left;" | M10 GPU accelerator<ref>{{cite web |url=http://images.nvidia.com/content/pdf/tesla/Tesla-M10-Product-Brief.pdf |format=PDF |title=Tesla M10 |website=Images.nvidia.com |accessdate=2016-10-29 |archive-date=2017-05-10 |archive-url=https://web.archive.org/web/20170510101626/http://images.nvidia.com/content/pdf/tesla/Tesla-M10-Product-Brief.pdf |dead-url=no }}</ref>
| 
| 4× GM107
| {{n/a}}
| 2560
| 1033
| {{dunno}}
| GDDR5
| 4× 128
| 4× 8
| 5188
| 4× 83
| {{no}}
| 5289
| 165.3
| 5.2
| 225
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | M40 GPU accelerator<ref name="nvidia2"/><ref>{{cite web |url=http://images.nvidia.com/content/tesla/pdf/tesla-m40-product-brief.pdf |format=PDF |title=Tesla M40 |website=Images.nvidia.com |accessdate=2015-12-11 |archive-date=2016-10-21 |archive-url=https://web.archive.org/web/20161021031653/http://images.nvidia.com/content/tesla/pdf/tesla-m40-product-brief.pdf |dead-url=no }}</ref>
| November 10, 2015
| 1× GM200
| {{n/a}}
| 3072
| 948
| 1114
| GDDR5
| 384
| 12
| 6000
| 288
| {{no}}
| 5825–6844
| 182.0–213.9
| 5.2
| 250
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | M60 GPU accelerator<ref>{{cite web |url=http://images.nvidia.com/content/pdf/tesla/tesla-m60-product-brief.pdf |format=PDF |title=Tesla M60 |website=Images.nvidia.com |accessdate=2016-05-27 |archive-date=2020-10-22 |archive-url=https://web.archive.org/web/20201022152228/http://images.nvidia.com/content/pdf/tesla/tesla-m60-product-brief.pdf |dead-url=no }}</ref>
| August 30, 2015
| 2× GM204-895-A1
| {{n/a}}
| 4096
| 899
| 1178
| GDDR5
| 2× 256
| 2× 8
| 5000
| 2× 160
| {{no}}
| 7365–9650
| 230.1–301.6
| 5.2
| 225–300
| Internal PCIe GPU (full-height, dual-slot)
|- style="vertical-align:top;"
! style="text-align:left;" | P4 GPU accelerator<ref name="Anand_P40">{{cite news|last1=Smith|first1=Ryan|title=Nvidia Announces Tesla P40 & Tesla P4 - Network Inference, Big & Small|url=http://www.anandtech.com/show/10675/nvidia-announces-tesla-p40-tesla-p4|accessdate=13 September 2016|publisher=Anandtech|date=13 September 2016|archive-date=2021-01-16|archive-url=https://web.archive.org/web/20210116101008/https://www.anandtech.com/show/10675/nvidia-announces-tesla-p40-tesla-p4|dead-url=no}}</ref>
| rowspan=6 | [[帕斯卡_(微架构)|帕斯卡 (微架构)]]
| September 13, 2016
| 1× GP104
| {{n/a}}
| 2560
| 810
| 1063
| GDDR5
| 256
| 8
| 6000
| 192.0
| {{no}}
| 4147–5443
| 129.6–170.1
| 6.1
| 50-75
| [[PCI_Express|PCI Express]] card
|-
|- style="vertical-align:top;"
! style="text-align:left;" | P6 GPU accelerator<ref>{{cite web |url=https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/Tesla-P6-Product-Brief.pdf |format=PDF |title=Tesla P6 |website=www.nvidia.com |accessdate=2019-03-07 |archive-date=2020-07-28 |archive-url=https://web.archive.org/web/20200728182944/https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/solutions/resources/documents1/Tesla-P6-Product-Brief.pdf |dead-url=no }}</ref><ref>{{cite web |url=https://www.techpowerup.com/gpu-specs/tesla-p6.c3036 |title=Tesla P6 Specs |website=www.techpowerup.com |accessdate=2019-03-07 |archive-date=2020-07-28 |archive-url=https://web.archive.org/web/20200728180652/https://www.techpowerup.com/gpu-specs/tesla-p6.c3036 |dead-url=no }}</ref>
| March 24, 2017
| 1× GP104-995-A1
| {{n/a}}
| 2048
| 1012
| 1506
| GDDR5
| 256
| 16
| 3003
| 192.2
| {{no}}
| 6169
| 192.8
| 6.1
| 90
| [[行動PCI_Express模組|行動PCI Express模組]] card
|-
|- style="vertical-align:top;"
! style="text-align:left;" | P40 GPU accelerator<ref name="Anand_P40"/>
| September 13, 2016
| 1× GP102
| {{n/a}}
| 3840
| 1303
| 1531
| GDDR5
| 384
| 24
| 7200
| 345.6
| {{no}}
| 10007–11758
| 312.7–367.4
| 6.1
| 250
| [[PCI_Express|PCI Express]] card
|-
|- style="vertical-align:top;"
! style="text-align:left;" | P100 GPU accelerator (mezzanine)<ref>{{cite news|last1=Smith|first1=Ryan|title=Nvidia Announces Tesla P100 Accelerator - Pascal GP100 for HPC|url=http://www.anandtech.com/show/10222/nvidia-announces-tesla-p100-accelerator-pascal-power-for-hpc|accessdate=5 April 2016|agency=Anandtech.com|publisher=Anandtech.com|date=5 April 2016|archive-date=2016-07-30|archive-url=https://web.archive.org/web/20160730213045/http://www.anandtech.com/show/10222/nvidia-announces-tesla-p100-accelerator-pascal-power-for-hpc|dead-url=no}}</ref><ref>{{cite news|last1=Harris|first1=Mark|title=Inside Pascal: Nvidia’s Newest Computing Platform|url=https://devblogs.nvidia.com/parallelforall/inside-pascal/|accessdate=13 September 2016|archive-date=2017-05-07|archive-url=https://web.archive.org/web/20170507110037/https://devblogs.nvidia.com/parallelforall/inside-pascal/|dead-url=no}}</ref>
| April 5, 2016
| 1× GP100-890-A1
| {{n/a}}
| rowspan=3 | 3584
| 1328
| 1480
| rowspan=3 | [[高頻寬記憶體|高頻寬記憶體]]
| rowspan=2 | 4096
| rowspan=2 | 16
| rowspan=3 | 1430
| rowspan=2 | 732
| {{no}}
| 9519–10609
| 4760–5304
| rowspan=3 | 6.0
| 300
| [[NVLink|NVLink]] card
|-
|- style="vertical-align:top;"
! style="text-align:left;" | P100 GPU accelerator (16 GB card)<ref name="P100-PCIe">{{cite news|last1=Smith|first1=Ryan|title=NVidia Announces PCI Express Tesla P100|url=http://www.anandtech.com/show/10433/nvidia-announces-pci-express-tesla-p100|accessdate=21 June 2016|publisher=Anandtech.com|date=20 June 2016|archive-date=2020-11-11|archive-url=https://web.archive.org/web/20201111203959/https://www.anandtech.com/show/10433/nvidia-announces-pci-express-tesla-p100|dead-url=no}}</ref>
| June 20, 2016
| rowspan=2 | 1× GP100
| {{n/a}}
| rowspan=2 | 1126
| rowspan=2 | 1303
| {{no}}
| 8071‒9340
| 4036‒4670
| rowspan=2 | 250
| rowspan=2 | [[PCI_Express|PCI Express]] card
|-
|- style="vertical-align:top;"
! style="text-align:left;" | P100 GPU accelerator (12 GB card)<ref name="P100-PCIe"></ref>
| June 20, 2016
| {{n/a}}
| 3072
| 12
| 549
| {{no}}
| 8071‒9340
| 4036‒4670
|-
|- style="vertical-align:top;"
! style="text-align:left;" | V100 GPU accelerator (mezzanine)<ref name='v100_1'>{{cite news|last1=Smith|first1=Ryan|title=The Nvidia GPU Technology Conference 2017 Keynote Live Blog|url=http://www.anandtech.com/show/11360/the-nvidia-gpu-tech-conference-2017-keynote-live-blog|accessdate=10 May 2017|publisher=Anandtech|date=10 May 2017|archive-date=2020-11-12|archive-url=https://web.archive.org/web/20201112025146/https://www.anandtech.com/show/11360/the-nvidia-gpu-tech-conference-2017-keynote-live-blog|dead-url=no}}</ref><ref name='v100_2'>{{cite news|last1=Smith|first1=Ryan|title=NVIDIA Volta Unveiled: GV100 GPU and Tesla V100 Accelerator Announced|url=http://www.anandtech.com/show/11367/nvidia-volta-unveiled-gv100-gpu-and-tesla-v100-accelerator-announced|accessdate=10 May 2017|publisher=Anandtech|date=10 May 2017|archive-date=2020-11-12|archive-url=https://web.archive.org/web/20201112031428/https://www.anandtech.com/show/11367/nvidia-volta-unveiled-gv100-gpu-and-tesla-v100-accelerator-announced|dead-url=no}}</ref><ref name="V100_3">{{cite news|last1=Oh|first1=Nate|title=NVIDIA Formally Announces V100: Available later this Year|url=http://www.anandtech.com/show/11559/nvidia-formally-announces-pcie-tesla-v100-available-later-this-year|accessdate=20 June 2017|publisher=Anandtech.com|date=20 June 2017|archive-date=2021-01-24|archive-url=https://web.archive.org/web/20210124235540/https://www.anandtech.com/show/11559/nvidia-formally-announces-pcie-tesla-v100-available-later-this-year|dead-url=no}}</ref>
| rowspan='2'| [[伏打微架構|伏打微架構]]
| 
| 1× GV100-895-A1
| {{n/a}}
| rowspan='2'| 5120
| {{unk}}
| 1455
| rowspan='2'|HBM2
| rowspan='2'|4096
| rowspan='2'|16 or 32
| rowspan='2'|1750
| rowspan='2'|900
| {{no}}
| 14899
| 7450
| rowspan='2'| 7.0
| 300
| NVlink card
|-
|- style="vertical-align:top;"
! style="text-align:left;" | V100 GPU accelerator (PCIe card)<ref name='v100_1' /><ref name='v100_2' /><ref name="V100_3" />
| June 21, 2017
| 1× GV100
| {{n/a}}
| {{unk}}
| 1370
| {{no}}
| 14028
| 7014
| 250
| PCIe card
|-
! style="text-align:left;" | T4 GPU accelerator (PCIe card)<ref name='T4'>{{cite news|title=NVIDIA TESLA T4 TENSOR CORE GPU|url=https://www.nvidia.com/en-us/data-center/tesla-t4/|accessdate=17 October 2018|publisher=NVIDIA|archive-date=2021-02-04|archive-url=https://web.archive.org/web/20210204000708/https://www.nvidia.com/en-us/data-center/tesla-t4/|dead-url=no}}</ref><ref>{{cite web |url=https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-t4/t4-tensor-core-product-brief.pdf |format=PDF |title=NVIDIA Tesla T4 Tensor Core Product Brief |website=www.nvidia.com |accessdate=2019-07-10 |archive-date=2020-06-17 |archive-url=https://web.archive.org/web/20200617012315/https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-t4/t4-tensor-core-product-brief.pdf |dead-url=no }}</ref>
| [[图灵微架构|图灵微架构]]
| September 12, 2018
| 1× TU104-895-A1
| {{n/a}}
| 2560
| 585
| 1590
| GDDR6
| 256
| 16
| {{unk}}
| 320
| {{no}}
| 8100
| {{unk}}
| 7.5
| 70
| PCIe card
|-
! style="text-align:left;" | RTX A40<ref>{{cite news |title=NVIDIA发布RTX A6000/A40：满血10752个CUDA核心、48GB显存 |url=https://m.mydrivers.com/newsview/716873.html?ref=android-app%3A//com.google.android.googlequicksearchbox/}}</ref>
| [[安培微架构|安培微架构]]
| 2020年10月5日
| 
| 
| 
|
| 
| 
| 
| 
| 
| 
| 
| 
| 
| 
| 
| 
|-
! rowspan=2 | Model
! rowspan=2 | [[微架構|微架構]]
! rowspan=2 | Launch
! rowspan=2 | Chips
! rowspan=2 | Core clock<br/>([[Hertz|MHz]])
! colspan=3 | Shaders
! colspan=5 | Memory
! colspan=3 | Processing power ([[每秒浮點運算次數|每秒浮點運算次數]]){{efn|name="Calculate"|group="NvidiaTesla}}
! rowspan=2 | CUDA<br/>compute<br/>ability
! rowspan=2 | [[热设计功耗|热设计功耗]]<br/>(watts)
! rowspan=2 | Notes, form factor
|-
! Cuda cores<br/>(total)
! Base clock ([[赫兹|赫兹]])
! Max boost<br/>clock ([[赫兹|赫兹]]){{efn|name="GPUBoost"|group="NvidiaTesla"}}
! Bus type
! Bus width<br/>([[位元|位元]])
! Size<br/>([[吉字节|吉字节]])
! Clock<br/>({{link-en|Transfer (computing)}})
! Bandwidth<br/>(total)<br/>([[吉字节|吉字节]]/s)
! [[單精度浮點數|單精度浮點數]]<br/>(MAD+MUL)
! [[單精度浮點數|單精度浮點數]]<br/>(MAD or [[乘積累加運算|乘積累加運算]])
! [[雙精度浮點數|雙精度浮點數]]<br/>([[乘積累加運算|乘積累加運算]])
|}
Notes
{{notelist|group=NvidiaTesla}}<noinclude>
{{Template reference list}}
[[Category:輝達圖形處理器|Category:輝達圖形處理器]]
[[Category:Templates_that_generate_named_references|Category:Templates that generate named references]]
</noinclude>

== 另見 ==
* [[GeForce|NVIDIA GeForce]]
* [[NVIDIA_GeForce_100|GeForce 100]] 
* [[NVIDIA_GeForce_200|GeForce 200]] 
* [[NVIDIA_GeForce_300|GeForce 300]] 
* [[NVIDIA_GeForce_400|GeForce 400]] 
* [[NVIDIA_GeForce_500|GeForce 500]] 
* [[NVIDIA_GeForce_600|GeForce 600]] 
* [[NVIDIA_GeForce_700|GeForce 700]] 
* [[NVIDIA_GeForce_800|GeForce 800]] 
* [[NVIDIA_GeForce_900|GeForce 900]] 

* [[NVIDIA_GeForce_10系列|GeForce 10系列]] 
* [[NVIDIA_GeForce_16系列|GeForce 16系列]]
* [[NVIDIA_GeForce_20系列|GeForce 20系列]] 
* [[NVIDIA_GeForce_30系列|GeForce 30系列]] 
* [[NVIDIA_Quadro|NVIDIA Quadro]]

== 參考資料 ==
{{Reflist}}

== 外部連結 ==
*[https://web.archive.org/web/20080728200305/http://www.nvidia.com/object/tesla_computing_solutions.html NVIDIA的Tesla主頁]

{{Commonscat|Nvidia Tesla series}}
{{NVIDIA}}

[[Category:英伟达|Category:英伟达]]