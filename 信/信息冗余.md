{{NoteTA
|G1 = Communication
|G2 = IT
}}
在[[信息论|信息论]]中，'''信息冗余'''是传输消息所用数据位的数目与消息中所包含的实际信息的数据位的数目的差值。[[数据压缩|数据压缩]]是一种用来消除不需要的冗余的方法，[[校验和|校验和]]是在经过有限[[信道容量|信道容量]]的噪声信道中通信，为了进行[[错误校正|错误校正]]而增加冗余的方法。

==定量定义==
在描述原始数据的冗余时，信源[[熵率|信息率]]为平均每个符号的[[熵_(信息论)|熵]]。对于无记忆信源，这仅是每个符号的熵；而对于一个[[随机过程|随机过程]]的最普遍形式为前 ''n'' 个符号的[[联合熵|联合熵]]除以 ''n'' 之后，随着 ''n'' 趋于无穷时的极限

:<math>r = \lim_{n \to \infty} \frac{1}{n} \Eta(M_1, M_2, \dots M_n),</math>

在信息论中经常提及一种语言的“熵率”或者“[[信息熵|信息熵]]”。当信源是英文散文时这是正确的。由于无记忆信源的消息之间没有相互依赖性，所以无记忆信源的信息率为<math>\Eta(M)</math>。

信源的'''绝对信息率'''为

:<math>R = \log |\mathbb M| ,\,</math>

即是消息空间[[基数|基数]]的[[对数|对数]]值。这个公式也称作[[Hartley函数|Hartley函数]]。这是传送用这个字母表表示的信息的最大信息率。其中对数要根据所用的测量单位选择合适的[[底数|底数]]。[[当且仅当|当且仅当]]信源是无记忆的且均匀分布的时候，绝对信息率等于信息率。

'''绝对信息冗余'''定义为

:<math> D = R - r</math>，

即信息率与绝对信息率之间的差。

<math>\frac D R</math>称为'''相对信息冗余'''，它表示了最大的[[数据压缩率|数据压缩率]]，这个压缩率用文件大小减小比例所表示。当用原始文件与压缩后的文件表示的时候，<math>R : r</math>表示能够得到的最大压缩率。与相对信息冗余互补的是'''效率'''<math>\frac r R </math>，于是<math>\frac r R + \frac D R = 1</math>。均匀分布的无记忆信源的冗余为0，效率为100%，因此无法压缩。

==其它的冗余概念==
两个变量之间''冗余''的度量是[[互信息|互信息]]或者正规化变量。多个变量之间冗余的度量是[[全相关|全相关]]（total correlation）。

压缩数据的冗余是指 <math>n</math> 个消息的[[期望值|期望]]压缩数据长度为<math>L(M^n) \,\!</math>（或期望数据熵率 <math>L(M^n)/n \,\!</math>）与熵值 <math>nr \,\!</math>（或熵率 <math>r \,\!</math>）的差。（这里我们假设数据是[[遍历性|遍历的]]也是[[平稳过程|平稳的]]，例如无记忆信源。）虽然熵率之差 <math>L(M^n)/n-r \,\!</math> 会随着 <math>n \,\!</math> 增加而任意小，实际的差 <math>L(M^n)-nr \,\!</math> 已不能（尽管理论上可以）在有限熵的无记忆信源情况下上界为 1。

==参见==

* [[信源编码|信源编码]]
* [[信源编码定理|信源编码定理]]
* [[数据压缩|数据压缩]]
* [[负熵|负熵]]

==参考文献==

* {{cite book | first = Fazlollah M. | last = Reza | title = An Introduction to Information Theory | origyear = 1961| location = New York | publisher = Dover | year = 1994 | isbn = 0-486-68210-2 }}
* {{cite book | first = Bruce | last = Schneier | authorlink = Bruce Schneier | title = Applied Cryptography: Protocols, Algorithms, and Source Code in C | location =New York | publisher = John Wiley & Sons, Inc. | year = 1996 | isbn = 0-471-12845-7 }}
* {{cite book | last1 = Auffarth | first1 = B | last2 = Lopez-Sanchez | first2 = M. | last3 = Cerquides | first3 = J. | chapter = Comparison of Redundancy and Relevance Measures for Feature Selection in Tissue Classification of CT images | id = {{citeseerx|10.1.1.170.1528}} | title = Advances in Data Mining. Applications and Theoretical Aspects | pages = 248–262 | publisher = Springer | year = 2010 }}

{{压缩方法}}

[[Category:信息论|Category:信息论]]