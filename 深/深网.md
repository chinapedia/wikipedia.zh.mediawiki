{{Expand|time=2013-12-30T22:49:39+00:00}}
{{TA
|G1=IT
|1=zh-hans:通过; zh-hant:透過;
|2=zh-hans:视频点播;zh-hk:自選影像;zh-tw:隨選視訊;
}}
{{About|传统的网络搜索引擎无法访问到的網站內容|無法用正常方式訪問的網站|暗網}}
'''深网'''，即'''深層網路'''（{{lang-en|Deep web}}），又称：不可见网、隐藏网，是指不能被标准[[網路搜尋引擎|搜索引擎]]索引的[[全球資訊網|全球資訊網]]内容。與深網相反的術語是[[表網|表網]]，任何人都可以使用網際網路存取。

深網的內容隱藏在[[HTTP|HTTP]]表單後面，包括許多非常常見的用途，如[[網路郵件|網路郵件]]、[[網路銀行|網路銀行]]和使用者必須付費的服務，這些內容受到付費牆的保護，如[[隨選視訊|隨選視訊]]、一些網路雜誌和報紙等。 

==命名==
伯格曼在''The Journal of Electronic Publishing''上發表一篇關於深网的重大論文中提到，[[吉尔.艾尔斯沃夫|吉尔.艾尔斯沃夫]]曾经使用“隱形網”这一术语表示那些没有被任何搜索引擎索引注册的网站<ref name=bergman2001 />。伯格曼還引用[[法兰克·加西亚|法兰克·加西亚]]在1996年1月的一篇文章<ref>Garcia, Frank (January 1996). "Business and Marketing on the Internet". ''Masthead'' 9 (1). (Citation from Flynn-Burhoe, Maureen (19 December 2006). "[http://papergirls.wordpress.com/2006/12/19/the-ultimate-guide-to-the-invisible-web/ The Ultimate Guide to the Invisible Web]". ''oceanflynn @ Digg''.) ([https://web.archive.org/web/19961205083117/http://tcp.ca/Jan96/BusandMark.html Electronic copy] archived by the [[Internet_Archive|Internet Archive]].)</ref>：

<blockquote>这些网站可能已经被合理地设计出来了，但是他们却没有被任何搜索引擎编列索引，以至于事实上没有人能找到他们。我可以这样对这些不可见的网站说，你们是隐藏了的。我稱之為隱形網。</blockquote>

早期另一個使用“隱形網”这一术语的是一家叫做“个人图书馆软件”公司的[[布鲁斯·芒特|布鲁斯·芒特]]和[[马修·B·科尔|马修·B·科尔]]，当他们公司在1996年12月推出和发行的一款软件时，他们对深网工具的有过这样的一番描述。<ref>Personal Library Software (Dec 1996). "PLS introduces AT1, the first 'second generation' Internet search service". ([https://web.archive.org/web/19971021232057/http://www.pls.com/news/pr961212_at1.html Archived by the Internet Archive].)</ref>

現在普遍接受的深网這一特定術語首次使用在2001年伯格曼的研究中<ref name=bergman2001 />。2001年，[[電腦科學|電腦科學家]][[迈克尔·伯格曼|迈克尔·伯格曼]]将当今全球資訊網上的搜索服务比喻为像在地球的海洋表面的拉起一个大网的搜索，巨量的表面信息固然可以通过这种方式被查找得到，可是还有相当大量的信息由于隐藏在深处而被搜索引擎错失掉。绝大部分这些隐藏的信息是须通过动态请求产生的网页信息，而标准的搜索引擎却无法对其进行查找。传统的搜索引擎“看”不到，也获取不了这些存在于深网的内容，除非通过特定的搜查这些页面才会动态产生。于是相对的，深网就隐藏了起来。据估计，深网要比[[表網|表網]]大几个[[数量级|数量级]]<ref name=bergman2001>{{cite journal |first=Michael K. |last=Bergman | title = The Deep Web: Surfacing Hidden Value | journal = The Journal of Electronic Publishing | volume = 7 | issue = 1 | url = http://www.press.umich.edu/jep/07-01/bergman.html|date=August 2001}}.  According to that paper, the study was originally published on July 26, 2000, with data then updated to 2001.</ref>。

==深網資源==
防止網頁被傳統搜索引擎索引的方法可以被分類為以下一個或多個：
# '''被限制存取的內容'''：以技術方式限制訪問其網頁的網站，例如[[Robots.txt|Robots.txt]]、[[验证码|CAPTCHAs]]或是禁止搜尋引擎建立快取<ref>{{cite web|title=Hypertext Transfer Protocol (HTTP/1.1): Caching|publisher=[[Internet_Engineering_Task_Force|Internet Engineering Task Force]]|year=2014|url=http://tools.ietf.org/html/rfc7234#section-5.2.2.3|accessdate=2014-07-30}}</ref>。
# '''非HTML或文本的內容'''：圖像或影片等多媒體或是特定檔案格式無法被搜尋引擎處理。
# '''私人網站'''：需要註冊或是登入的網站。
# '''軟體'''：某些內容刻意隱藏在一般的網路上，只能使用特殊軟體如[[Tor|Tor]]、[[I2P|I2P]]或其他程式存取。例如Tor讓使用者匿名訪問[[.onion|.onion]]網址的網站，以隱藏他們的IP位址。
# '''未被連結的內容'''：未被其他網站連結或很少連結的網頁，這可能防止被[[網路爬蟲|網路爬蟲]]存取。
# '''網站檔案管理庫'''：[[網站時光機|網站時光機]]這類網站內容的網頁無法被搜尋引擎編入索引<ref>{{cite web|last1=Wiener-Bronner|first1=Danielle|title=NASA is indexing the 'Deep Web' to show mankind what Google won't|url=http://fusion.net/story/145885/nasa-is-indexing-the-deep-web-to-show-mankind-what-google-wont/|publisher=Fusion |date=June 10, 2015 |accessdate=June 27, 2015|quote=There are other simpler versions of Memex already available. "If you've ever used the Internet Archive's Wayback Machine", which gives you past versions of a website not accessible through Google, then you've technically searched the Deep Web, said Chris Mattmann.}}</ref>。

==抓取深網內容==
研究人员探寻了如何自动抓取深网内容。

2001年，斯利拉姆·拉格哈瓦（Sriram Raghavan）和赫克托·加西亞·莫利納（Hector Garcia-Molina）<ref name=raghavan2000>{{cite paper
  | author = Sriram Raghavan
  | authorlink = 
  | coauthors = Hector Garcia-Molina
  | title = Crawling the Hidden Web
  | publisher = Stanford Digital Libraries Technical Report
  | date = 2000
  | url = http://ilpubs.stanford.edu:8090/456/1/2000-36.pdf
  | format = [[Portable_Document_Format|PDF]]
  | accessdate = 2008-12-27}}</ref><ref>{{cite conference |first=Sriram |last=Raghavan |coauthors=Garcia-Molina, Hector | year = 2001 | title = Crawling the Hidden Web | booktitle = Proceedings of the 27th International Conference on Very Large Data Bases (VLDB) | pages = 129-138 | url = http://www.dia.uniroma3.it/~vldbproc/017_129.pdf|format=PDF}}</ref>发明了一个从用户请求界面表格收集关键词的深网抓取模型并且抓取深网资源。[[加利福尼亚大学洛杉矶分校|加利福尼亚大学洛杉矶分校]]的Alexandros Ntoulas、Petros Zerfos和Junghoo Cho创建了一个自动生成有意义的查询词的程序。<ref>{{cite paper
  | first = Ntoulas
  | last =  Alexandros
  | author =
  | authorlink =
  | coauthors = Petros Zerfos, and Junghoo Cho
  | title = Downloading Hidden Web Content
  | version =
  | publisher = [[UCLA|UCLA]] Computer Science
  | date = 2005
  | url = http://oak.cs.ucla.edu/~cho/papers/ntoulas-hidden.pdf
  | format =
  | accessdate = 2009-02-24}}</ref><!-- Their crawler generated promising results, but the problem is far from being solved, as the authors recognized. Another effort is [[DeepPeep|DeepPeep]], a project of the [[University_of_Utah|University of Utah]] sponsored by the [[National_Science_Foundation|National Science Foundation]], which gathered hidden-Web sources (Web forms) in different domains based on novel focused crawler techniques.<ref>{{ cite paper
  | first = Luciano
  | last =  Barbosa
  | author =
  | authorlink =
  | coauthors = Juliana Freire
  | title =  An Adaptive Crawler for Locating Hidden-Web Entry Points
  | version =
  | publisher = WWW Conference 2007
  | date = 2007
  | url = http://www.cs.utah.edu/~lbarbosa/publications/ache-www2007.pdf
  | format =
  | accessdate = 2009-03-20}}</ref><ref>{{cite paper
  | first = Luciano
  | last =  Barbosa
  | author =
  | authorlink =
  | coauthors = Juliana Freire
  | title =   Searching for Hidden-Web Databases.
  | version =
  | publisher = WebDB 2005
  | date = 2005
  | url = http://www.cs.utah.edu/~lbarbosa/publications/webdb2005.pdf
  | format =
  | accessdate = 2009-03-20}}</ref>-->

商业搜索引擎已经开始使用以上两种方法之一抓取深网。Sitemap協議（由Google於2005年首次開發並由Google引入）和mod oai是允许搜索引擎和其他网络服务探索深网解决方法。以上两种解决方法允许网络服务主动公布网址，这对于他们来说是容易的，因而允许自动探寻资源而不直接通过网络表面的链接。Google的深网探寻系统预先计算每个HTML表单并且添加结果HTML页面到Google搜索引擎索引。<!--The surfaced results account for a thousand queries per second to deep Web content.<ref>{{cite paper
  | first = Jayant
  | last =  Madhavan
  | author =
  | authorlink =
  | coauthors = David Ko, Łucja Kot, Vignesh Ganapathy, Alex Rasmussen, Alon Halevy
  | title = Google’s Deep-Web Crawl
  | version =
  | publisher = VLDB Endowment, ACM
  | date = 2008
  | url = http://www.cs.cornell.edu/~lucja/Publications/I03.pdf
  | format =
  | accessdate = 2009-04-17}}</ref>.-->在这个系统里，使用三种方法计算提交词：
# 为输入搜索选择关键词允许的输入值，
# 确定是否只接受特定的值（例如时间），以及
# 选择少量的组合生成适合纳入网站的搜索索引网址。
2008年，為了方便[[洋葱路由器#隱藏服務|Tor隱藏服務]]的使用者存取和搜尋隱藏的[[.onion|.onion]]網域，[[亞倫·斯沃茨|亞倫·斯沃茨]]設計了Tor2web—一個能夠利用普通瀏覽器存取的代理應用程序<ref name=RELEASE>{{cite web|last=Aaron|first=Swartz|title=In Defense of Anonymity|url=http://www.aaronsw.com/weblog/tor2web|accessdate=February 4, 2014}}</ref>。

==参見==
*[[暗网|暗网]]

==参考资源==
{{reflist}}

{{Authority control}}

[[Category:網路搜尋引擎|Category:網路搜尋引擎]]
[[Category:網路術語|Category:網路術語]]
[[Category:全球資訊網|Category:全球資訊網]]
[[Category:2000年代創造的新詞語|Category:2000年代創造的新詞語]]