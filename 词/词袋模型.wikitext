'''词袋模型'''（{{lang-en|'''Bag-of-words model'''}}）是個在自然語言處理和信息檢索(IR)下被簡化的表達模型。此模型下，一段文本（比如一个句子或是一个文档）可以用一個装着这些词的袋子来表示，這種表示方式不考慮文法以及詞的順序。最近词袋模型也被應用在電腦視覺領域。<ref name=sivic>{{cite conference
  | first = Josef
  | last = Sivic
  | title = Efﬁcient visual search of videos cast as text retrieval
  | booktitle = IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, VOL. 31, NO. 4
  | pages = 591–605
  | publisher = IEEE
  | date = April 2009
  | url = http://www.di.ens.fr/~josef/publications/sivic09a.pdf
  | access-date = 2016-03-06
  | archive-date = 2016-02-22
  | archive-url = https://web.archive.org/web/20160222011545/http://www.di.ens.fr/~josef/publications/sivic09a.pdf
  | dead-url = no
  }}</ref>

词袋模型被廣泛應用在文件分類，詞出現的頻率可以用來當作訓練分類器的特徵。

關於"词袋"這個用字的由來可追溯到澤里格·哈里斯於1954年在''Distributional Structure''的文章''。''<ref>{{cite journal
  |last= Harris
  |first= Zellig
  |authorlink= Zellig Harris
  |year= 1954
  |title= Distributional Structure
  |journal= Word
  |volume= 10
  |issue= 2/3
  |pages= 146–62
  |quote= And this stock of combinations of elements becomes a factor in the way later choices are made ... for language is not merely a bag of words but a tool with particular properties which have been fashioned in the course of its use}}</ref>

== 範例 ==
下列文件可用词袋表示:

以下是兩個簡單的文件:
<syntaxhighlight lang="text">
(1) John likes to watch movies. Mary likes movies too.
</syntaxhighlight>

<syntaxhighlight lang="text">
(2) John also likes to watch football games.
</syntaxhighlight>

基於以上兩個文件，可以建構出下列清單:
<syntaxhighlight lang="javascript">
[
    "John",
    "likes",
    "to",
    "watch",
    "movies",
    "also",
    "football",
    "games",
    "Mary",
    "too"
]
</syntaxhighlight>
此處有10個不同的詞，使用清單的索引表示長度為10的向量:
 (1) [1, 2, 1, 1, 2, 0, 0, 0, 1, 1] (2) [1, 1, 1, 1, 0, 1, 1, 1, 0, 0] 
每個向量的索引內容對應到清單中詞出現的次數。

舉例來說，第一個向量(文件一)前兩個內容索引是1和2，第一個索引內容是"John"對應到清單第一個詞並且該值設定為1，因為"John"出現一次。

此向量表示法不會保存原始句子中詞的順序。該表示法有許多成功的應用，像是郵件過濾。

== Term weighting ==
在上述的範例，文件向量包含term頻率   。在IR和文字分類常用不同方法量term權重。常見方法為tf-idf。

== 範例:垃圾郵件過濾 ==
分類一個郵件訊息，一個貝氏垃圾郵件分類假設訊息是一堆字並且隨機倒在兩堆袋子其中一個袋子裡，之後使用貝氏機率去決定哪個袋子是較有可能的。

== 参考文献 ==
{{Reflist}}

== 參見 ==
{{Portal box|计算机科学}}
* {{tsl|en|w-shingling||w-shingling}}
* [[n元语法|n元语法]]
* [[向量空間模型|向量空間模型]]
* [[自然语言处理|自然語言處理]]
* {{tsl|en|Additive smoothing||Additive smoothing}}
* [[文件分類|文件分類]]
* [[机器学习|機器學習]]
* {{tsl|en|Document-term matrix||Document-term matrix}}
* {{tsl|en|Hashing trick||Hashing trick}}
* [[最小哈希|最小哈希]]
* [[特徵擷取|特徵擷取]]

{{-}}
{{自然語言處理}}

{{DEFAULTSORT:词袋模型}}
[[Category:自然語言處理|Category:自然語言處理]]
[[Category:机器学习|Category:机器学习]]