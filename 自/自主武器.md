{{primarysources|time=2018-10-08T15:58:43+00:00}}
{{refimprove|time=2018-10-08T15:58:43+00:00}}
'''自主武器'''是指能够在无人干预情况下独立搜索、识别并攻击目标的一种新式[[武器|武器]]，包括目前某些[[防御|防御]]武器所具有的能够拦截来袭的[[导弹|导弹]]、[[火箭弹|火箭弹]]和[[炮弹|炮弹]]或附近的飞机的自主模式均属于自主武器的雏形。作为一种新式武器，有专家认为其出现可能改变战争模式，而其在随后发展中是否能够区分[[平民|平民]]和军事目标也受到国际人道组织的关注。

== 定义 ==
自主武器在国际上并没有一个明确而广泛接受的定义。[[红十字国际委员会|红十字国际委员会]]将其定义为“可以根据自身所部署的环境中不断变化的情况，随时学习或调整运转的武器。 真正的自主武器能够在无人干预或操控的情况下搜索、识别并使用致命武力攻击包括人类在内的目标（敌军战斗员）。”也有人将自主武器称作“杀手机器人”，其“是具有某种形式[[人工智能|人工智能]]的移动系统，能够在无人控制的情况下在动态环境中运行。”<ref>[https://www.icrc.org/chi/resources/documents/statement/2013/09-03-autonomous-weapons.htm 完全自主武器系统]</ref>
=== 与自动武器的区别 ===
自动武器不同与自主武器，其虽以自足完备和独立的方式运行，但最初目标由操作人员设定并控制，并在可控环境下严格执行预编程行动或序列。此类系统的实例包括自动岗哨炮和末敏弹（包括某些反车辆[[地雷|地雷]]）。在红十字国际委员会有关2011年挑战的报告中，该组织表示“最近科技的发展逐渐加强了此类系统区分某类军事目标与民用物体的能力。尽管如此，目前仍无法 预测这类系统将来在多大程度上能够进行区分，此类系统的主要挑战仍将是如何确保在使用这些武器时能按[[国际人道法|国际人道法]]规定区分军事目标与民用物体。”<ref>[https://www.icrc.org/chi/resources/documents/statement/2013/09-03-autonomous-weapons.htm 完全自主武器系统]</ref>

值得注意的是，[[无人机|无人机]]属于遥控武器之列，其必须由操作人员选定目标并激活、瞄准和发射相关武器。因此，无人机不属于自主武器。

== 现状 ==
全自主武器目前尙不存在，世界各强权国家，包括美国在内，也都尙未决定是否部署这类武器。但某些武器装置已具有部分自主系统，特别是在识别和攻击目标方面。但值得注意的是目前该类武器均固定在某特定位置，短期内在少平民和民用设施的限定环境下自主运转，攻击目标主要针对弹药或军用车辆<ref>[https://www.icrc.org/zh/content/zi-zhu-wu-qi-xi-tong-wen-da 自主武器系统——问答]</ref>

不过，有些高科技军事单位正着手发展，或已经部署某些自主性更强，能够自动调整的试验型的装备。[[美国|美国]]是这个科技发展领域的先驱者。其他几个国家，包括[[中国|中国]]、[[德国|德国]]、[[以色列|以色列]]、南韩、[[俄罗斯|俄罗斯]]和[[英国|英国]]，都已跟着投入。许多专家预测，全自主武器可在二十到三十年内被研制成功，部分专家甚至认为更快。<ref>[http://www.hrw.org/zh-hans/news/2012/11/19 趁早禁止“杀手机器人”]</ref>2013年5月17日俄罗斯负责国防工业的副总理罗戈津透露，俄罗斯科研人员正在研发一种机器人，该机器人被称之为“杀手机器人”，可不借助人类干预就能自行选择并攻击目标，还可以在恐怖分子袭击的环境中帮助疏散撤离受伤士兵和平民。<ref>[http://news.ifeng.com/mil/4/detail_2013_06/06/26142884_0.shtml 专家：全自主武器系统将在未来10到20年投入实战]</ref>

== 争议 ==
美国[[陆军|陆军]]训练及战略思想司令部长肯尼斯·罗斯列举了自主武器的优势<ref>[http://news.bbc.co.uk/cbbcnews/hi/teachers/citizenship_11_14/subject_areas/scientific_development/newsid_1923000/1923299.stm Robot soldiers]</ref>：“机器不会劳累，他们不会闭眼，他们不需要在下雨时躲在树下或和朋友交谈…人类在30分钟后注意力就会急剧下降，但机器从来不会感到害怕。” 从技术角度来说，有朝一日有可能设计出一种自主武器系统，完全能够遵守攻击中的区分、比例和预防原则。由于机器人不会受到情绪或个人利益的影响，自主武器在战场上也许能够比人类更道德和更审慎地行事。

但自主武器的研发带给人们更多的担忧。主要在攻击目标方面，人们担心自主武器无法区分军事目标和平民，从而造成对人道法的违反。此外，由于自主武器的操作者不明，谁应为武器的过错承担责任变得扑朔迷离。

[[人权观察组织|人权观察组织]]认为，“各国政府应当预先禁止全自主武器（fully autonomous weapons），以免当它被部署于武装冲突时危及平民”。人权观察表示，由于全自主武器不会对被害者感到同情，因此，[[独裁者|独裁者]]可能利用它们来对付自己的人民。虽然用机器来取代士兵可以减少军人的伤亡，但也可能因此导致战争更易发生，其生命代价却由军人转移到平民来负担<ref>[http://www.hrw.org/zh-hans/news/2012/11/19 趁早禁止“杀手机器人”]</ref>。在《当心间隙：杀手机器人缺乏问责机制》报告<ref>[http://www.hrw.org/node/133918  Mind the Gap]</ref>中，人权观察明确阐述全自动武器的难以追责性。此外，2013年4月，人权观察还联合50多个[[非政府组织|非政府组织]]组成“阻止杀手机器人组织”，呼吁预先禁止全自主武器的发展、生产和使用。
=== 对人道法的挑战 ===
红十字国际委员会尚未参与对于禁止全自主武器的呼吁，但该组织呼吁各国遵守[[日内瓦公约|日内瓦公约]]第一附加议定书第36条，在使用或发展该类武器时预先对其后果和对国际人道法的影响作出判断。此外，该组织还评估了全自主武器可能对国际人道法形成的挑战：

* 首先，国际人道法要求战斗中需要明确区分战斗员和平民，保证平民免受攻击和伤害。但自主武器是否具有区分能力受到怀疑。
* 其次，国际人道法的比例性原则“规定平民生命与财产的损失或对平民造成的伤害与预期的具体和直接军事利益相比不得是过分的”<ref>[https://www.icrc.org/chi/resources/documents/legal-fact-sheet/humanitarian-law-factsheet.htm 什么是国际人道法？]</ref>。此类评估需要人类独特的判断力，而目前的编程技术可能无法使人工智能达到该种能力。
* 第三，预防原则要求尽量减少平民伤亡。而在战争瞬息万变环境中自主武器似乎很难根据情况进行判断。

== 参考资料 ==
{{reflist|colwidth=30em}}

[[Category:人工智能应用|Category:人工智能应用]]
[[Category:武器|Category:武器]]