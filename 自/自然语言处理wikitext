{{noteTA
|G1=IT
|G2=Communication
|T=zh:自然語言處理; zh-tw:自然語言處理; zh-hk:自然語言處理; zh-cn:自然语言处理; 
|1=zh:自然語言處理; zh-tw:自然語言處理; zh-hk:自然語言處理; zh-cn:自然语言处理;
|2=zh:臉部; zh-tw:臉部; zh-hk:臉部; zh-cn:人脸;
|3=zh:指紋; zh-tw:指紋; zh-hk:指紋; zh-cn:指纹;
|4=zh:圖形; zh-tw:圖形; zh-hk:圖形; zh-cn:模式; 
|5=zh:辨識; zh-tw:辨識; zh-hk:辨識; zh-cn:识别; 
}}
{{人工智能}}
'''自然語言處理'''（{{lang-en|Natural Language Processing}}，[[缩写|缩写]]作 '''{{lang|en|NLP}}'''）是[[人工智慧|人工智慧]]和[[語言學|語言學]]領域的分支學科。此領域探討如何處理及運用[[自然語言|自然語言]]；自然語言處理包括多方面和步骤，基本有认知、理解、生成等部分。

自然語言認知和理解是讓電腦把输入的[[語言|語言]]变成有意思的符号和关系，然后根据目的再處理。自然語言生成系統则是把計算機數據轉化為自然語言。

== 歷史 ==
自然語言處理大體是從1950年代開始，雖然更早期也有作為。1950年，[[图灵|图灵]]發表論文「{{link-en|計算機器與智能|Computing Machinery and Intelligence}}」，提出現在所謂的「[[圖靈測試|圖靈測試]]」作為判斷智能的條件。

1954年的[[乔治城-IBM实验|乔治城-IBM实验]]涉及全部{{link-en|自動翻譯| automatic translation }}超過60句俄文成為英文。研究人員聲稱三到五年之內即可解決機器翻譯的問題。<ref>{{cite web|author=Hutchins, J.|year=2005|url=http://ahs.annaisd.org/common/pages/GalleryPhoto.aspx?photoId=11772950&width=180&height=180|title=The history of machine translation in a nutshell}}{{self-published source|date=December 2013}}</ref>不過實際進展遠低於預期，1966年的{{link-en| ALPAC報告| ALPAC report }}發現十年研究未達預期目標，機器翻譯的研究經費遭到大幅削減。一直到1980年代末期，[[統計機器翻譯|統計機器翻譯]]系統發展出來，機器翻譯的研究才得以更上一層樓。

1960年代發展特別成功的NLP系統包括[[SHRDLU|SHRDLU]]——一個詞彙設限、運作於受限如「[[積木世界|積木世界]]」的一種自然語言系統，以及1964-1966年[[约瑟夫·维森鲍姆|约瑟夫·维森鲍姆]]模擬「[[個人中心治療|個人中心治療]]」而設計的{{link-en| ELIZA |ELIZA}}——幾乎未運用人類思想和感情的訊息，有時候卻能呈現令人訝異地類似人之間的互動。「病人」提出的問題超出ELIZA 極小的知識範圍之時，可能會得到空泛的回答。例如問題是「我的頭痛」，回答是「為什麼說你頭痛？」

1970年代，程式設計師開始設計「概念本體論」（conceptual ontologies）的程式，將現實世界的資訊，架構成電腦能夠理解的資料。實例有MARGIE、SAM、PAM、TaleSpin、QUALM、Politics以及Plot Unit。許多[[聊天機器人|聊天機器人]]在這一時期寫成，包括{{link-en| PARRY | PARRY }} 、{{link-en| Racter| Racter}} 以及{{link-en| Jabberwacky | Jabberwacky }} 。

一直到1980年代，多數自然語言處理系統是以一套複雜、人工訂定的規則為基礎。不過從1980年代末期開始，語言處理引進了[[機器學習|機器學習]]的演算法，NLP產生革新。成因有兩個：運算能力穩定增加（參見[[摩爾定律|摩爾定律]]）；以及[[喬姆斯基|喬姆斯基]] 語言學理論漸漸喪失主導（例如[[轉換-生成文法|轉換-生成文法]]）。該理論的架構不傾向於[[語料庫|語料庫]]——機器學習處理語言所用方法的基礎。有些最早期使用的機器學習演算法，例如[[決策樹|決策樹]]，是硬性的、「如果-則」規則組成的系統，類似當時既有的人工訂定的規則。不過{{link-en|詞性標記|part-of-speech tagging }}將[[隱馬爾可夫模型|隱馬爾可夫模型]]引入NLP，並且研究日益聚焦於軟性的、以[[機率|機率]]做決定的[[統計模型|統計模型]]，基礎是將輸入資料裡每一個特性賦予代表其份量的數值。許多[[語音識別|語音識別]]現今依賴的{{link-en|快取語言模型| cache language model }}即是一種統計模型的例子。這種模型通常足以處理非預期的輸入數據，尤其是輸入有錯誤（真實世界的數據總免不了），並且在整合到包含多個子任務的較大系統時，結果比較可靠。

許多早期的成功屬於[[機器翻譯|機器翻譯]]領域，尤其歸功IBM的研究，漸次發展出更複雜的統計模型。這些系統得以利用加拿大和歐盟現有的[[語料庫|語料庫]]，因為其法律規定政府的會議必須翻譯成所有的官方語言。不過，其他大部分系統必須特別打造自己的語料庫，一直到現在這都是限制其成功的一個主要因素，於是大量的研究致力於從有限的數據更有效地學習。

近來的研究更加聚焦於[[非監督式學習|非監督式學習]]和{{link-en|半監督學習|semi-supervised learning}}的演算法。這種演算法，能夠從沒有人工註解理想答案的資料裡學習。大體而言，這種學習比[[監督學習|監督學習]]困難，並且在同量的數據下，通常產生的結果較不準確。不過沒有註解的數據量極巨（包含了[[全球資訊網|全球資訊網]]），彌補了較不準確的缺點。

近年來，[[深度學習|深度學習]]技巧紛紛出爐<ref name=goldberg:nnlp17>Goldberg, Yoav (2016). https://www.jair.org/media/4992/live-4992-9623-jair.pdf {{Wayback|url=https://www.jair.org/media/4992/live-4992-9623-jair.pdf |date=20180421110114 }} A Primer on Neural Network Models for Natural Language Processing. Journal of Artificial Intelligence Research 57 (2016) 345–420</ref><ref name=goodfellow:book16>Ian Goodfellow, Yoshua Bengio and Aaron Courville. http://www.deeplearningbook.org/ Deep Learning].  MIT Press.</ref> 在自然語言處理方面獲得最尖端的成果，例如語言模型<ref name=jozefowicz:lm16>Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu (2016). https://arxiv.org/abs/1602.02410 Exploring the Limits of Language Modeling</ref>、語法分析<ref name=choe:emnlp16>Do Kook Choe and Eugene Charniak (EMNLP 2016). http://www.aclweb.org/website/old_anthology/D/D16/D16-1257.pdf Parsing as Language Modeling</ref><ref name="vinyals:nips15">Vinyals, Oriol, et al.  (NIPS2015). https://papers.nips.cc/paper/5635-grammar-as-a-foreign-language.pdf</ref>等等。

==用途==
在許多情況下，學者們需要通過許多不同的數據庫來確定新的研究方向，以識別研究差距並確定迄今為止尚未研究的領域。檢查所有電子數據庫很麻煩，而且經常會遺漏重要的部分。通過使用網絡抓取和自然語言處理來縮短識別研究差距所需的時間。在Google學術搜索上索引的出版物的標題, 自然语言处理標記化(Tokenization)從最高頻率到最低頻率對搭配進行排序。因此，自然语言处理標記化(Tokenization)確定了標題中未提及的關鍵字集，並將最初的想法確定為研究空白 <ref>Li(2021)Building Updated Research Agenda by Investigating Papers Indexed on Google Scholar: A Natural Language Processing Approach, Advances in Intelligent Systems and Computing book series, volume 1213, pp 298-305 </ref>。

== 任務和限制 ==
理論上，NLP是一種很吸引人的人機交互方式。早期的语言处理系统如[[SHRDLU|SHRDLU]]，当它们处于一个有限的“积木世界”，运用有限的词汇表会话时，工作得相当好。这使得研究员们对此系统相当乐观，然而，当把这个系统拓展到充满了现实世界的含糊与不确定性的环境中时，他们很快丧失了信心。

由於理解（understanding）自然語言，需要關於外在世界的廣泛知識以及運用操作這些知識的能力，自然語言認知，同時也被視為一個人工智慧完備（AI-complete）的問題。同時，在自然語言處理中，"理解"的定義也變成一個主要的問題。

== 實際問題 ==
一些NLP面臨的問題實例：
* 句子“我們把香蕉給猴子，因為（-{牠}-們）餓了”和“我們把香蕉給猴子，因為（-{它}-們）熟透了”有同樣的結構。但是代詞“它們”在第一句中指的是“猴子”，在第二句中指的是“香蕉”。如果不了解猴子和香蕉的屬性，無法區分。（简体中文和英文的-{它/it}-沒有區分，但在正體中文裡-{「牠」和「它」}-是有區別的，只是代詞在中文裡常常被省略，因此需區別屬性並且標示出來）

不少的中文相關笑話即是利用類似結構的中文造句而成，此類笑話通常帶有“中文博大精深”之類的詞彙，敘述多以老外參加考試為背景。例子如下：

{{Cquote|某老外苦學漢語10年，到東方參加漢語考試。試題為「請解釋下列句子」： 阿呆給長官送紅包時，兩個人的對話頗有意思。 長官：「你這是什麼意思？」 阿呆：「沒什麼意思，意思意思。」 長官：「你這就不夠意思了。」 阿呆：「小意思，小意思。」 長官：「你這人真有意思。」 阿呆：「其實也沒有別的意思。」 長官：「那我就不好意思了。」 阿呆：「是我不好意思。」

老外淚流滿面，交白卷回國了。}}

==自然語言處理研究的難點==
===單詞的邊界界定===
:在口語中，詞與詞之間通常是連貫的，而界定字詞邊界通常使用的辦法是取用能讓給定的上下文最為通順且在文法上無誤的一種最佳組合。在書寫上，[[漢語|漢語]]也沒有詞與詞之間的邊界。

===詞義的消歧===
:許多字詞不單只有一個意思，因而我們必須選出使句意最為通順的解釋。

===句法的模糊性===
: [[自然語言|自然語言]]的[[文法|文法]]通常是[[模稜兩可|模稜兩可]]的，針對一個句子通常可能會[[語法分析器|剖析]]（Parse）出多棵[[剖析樹|剖析樹]]（Parse Tree），而我們必須要仰賴[[語意|語意]]及前後文的資訊才能在其中選擇一棵最為適合的剖析樹。

===有瑕疵的或不規範的輸入===
:例如語音處理時遇到外國口音或地方口音，或者在文本的處理中處理拼寫，語法或者[[光學字元識別|光學字元識別]]（OCR）的錯誤。

===语言行为与计划===
:句子常常并不只是字面上的意思；例如，“你能把盐递过来吗”，一个好的回答应当是動手把盐递过去；在大多数上下文环境中，“能”将是糟糕的回答，虽说回答“不”或者“太远了我拿不到”也是可以接受的。再者，如果一门课程去年没开设，对于提问“这门课程去年有多少学生没通过？”回答“去年没开这门课”要比回答“没人没通过”好。

==当前自然语言处理研究的发展趋势==
第一，传统的基于句法-语义规则的理性主义方法过于复杂，随着语料库建设和语料库语言学的崛起，大规模真实文本的机器学习处理成为自然语言处理的主要选择。

第二，统计数学方法越来越受到重视，自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。

第三，浅层处理与深层处理并重，统计与规则方法并重，形成混合式的系统。

第四，自然语言处理中越来越重视词汇的作用，出现了强烈的“词汇主义”的倾向。词汇知识库的建造成为了普遍关注的问题。<ref>http://www.lingviko.net/feng/4feature.pdf</ref>

== 統計自然語言處理==
統計自然語言處理運用了[[推測學|推測學]]、[[機率|機率]]、[[統計|統計]]的方法來解決上述，尤其是針對容易高度模糊的長串句子，當套用實際文法進行分析產生出成千上萬筆可能性時所引發之難題。處理這些高度模糊句子所採用消歧的方法通常運用到[[語料庫|語料庫]](Corpus)以及[[馬可夫模型|馬可夫模型]]（Markov models）。統計自然語言處理的技術主要由同樣自[[人工智慧|人工智慧]]下與學習行為相關的子領域：[[機器學習|機器學習]]及[[資料採掘|資料採掘]]所演進而成。

==主要範疇==
*[[文本朗讀|文本朗讀]]（Text to speech）
*[[語音合成|語音合成]]（Speech synthesis）
*[[語音識別|語音識別]]（Speech recognition）
*[[斷詞|斷詞]]/分詞（Text segmentation/Word tokenization）
*[[中文自动分词|中文自动分词]]（Chinese word segmentation）
*[[語法分析|語法分析]]/[[剖析|剖析]]（Syntactic analysis/Parsing）
*[[漢語自動句法分析|漢語自動句法分析]]
*[[詞彙標示框架|詞彙標示框架]](Lexical Markup Framework)
*[[n元语法|n元语法]] (n-gram）
*[[詞嵌入|詞嵌入]] (Word2vec) 
*[[词性标注|词性标注]]（Part-of-speech tagging）
*[[文檔分類|文檔分類]] (Document classification)
*[[自然語言生成|自然語言生成]]（Natural language generation）
*[[文本分类|文本分类]]（Text categorization）
*[[信息检索|信息检索]]（Information retrieval）
*[[信息抽取|信息抽取]]（Information extraction）
*[[校對|文字校對]]（Text-proofing）
*[[問答系統|問答系統]]（Question answering）
:給一句人類語言的问句，決定其答案。 典型問題有特定答案 (像是加拿大的首都叫什麼?)，但也考慮些開放式問句(像是人生的意義是是甚麼?)
*[[聊天機器人|聊天機器人]] (ChatBot)
*[[对话系统|对话系统]] (Dialogue system)
*[[機器翻譯|機器翻譯]]（Machine translation）
:將某種人類語言自動翻譯至另一種語言
*[[自動摘要|自動摘要]]（Automatic summarization）
:產生一段文字的大意，通常用於提供已知領域的文章摘要，例如產生報紙上某篇文章之摘要
*[[文字蘊涵|文字蘊涵]]（Textual entailment）
*[[命名实体识别|命名实体识别]]（Named entity recognition, NER）
*[[主题模型|主题模型]]（Topic Model）
*[[文本情感分析|文本情感分析]]（Sentiment analysis）
*[[語意分析|語意分析]]（Semantic analysis）
*[[潛在語義學|潛在語義學]]（Latent Semantic Analysis）
*[[詞袋模型|詞袋模型]]（Bag-of-words model）
*[[標籤雲|標籤雲]] (Tag Cloud)
*[[自然语言理解|自然语言理解]] (Natural Language Understanding)
==参见==
{{div col |cols = 3 }}
* {{le|萬能翻譯機|universal translator}}
* [[電腦語言學|電腦語言學]]
* [[受限自然語言|受限自然語言]]
* [[信息抽取|信息抽取]]
* [[資訊檢索|資訊檢索]]
* [[自然語言理解|自然語言理解]]
* [[潛在語義索引|潛在語義索引]]
* [[潜在语义学|潜在语义学]]
* {{le|隨機文法|Stochastic grammar}}
* [[機器記者|機器記者]]
* {{le|寫作自動評分|Automated essay scoring}}
* {{le|生物醫學文件探勘系統|Biomedical text mining}}
* {{le|複合詞處理|Compound term processing}}
* [[计算语言学|计算语言学]]
* {{le|電腦輔助審查|Computer-assisted reviewing}}
* [[深度学习|深度学习]]
* {{le|深度語言處理|Deep linguistic processing}}
* {{le|輔助外文閱讀|Foreign language reading aid}}
* {{le|輔助外文寫作|Foreign language writing aid}}
* {{le|語言科技|Language technology}}
* [[隐含狄利克雷分布|隐含狄利克雷分布]]（LDA）
<!--* [[List_of_natural_language_processing_toolkits|List of natural language processing toolkits]]-->
* {{le|母语识别|Native-language identification}}
* {{le|自然語言編程|Natural language programming}}
* {{le|自然語言使用者界面|Natural language user interface}}
* [[擴展查詢|擴展查詢]]
* {{le|具體化 (語言學)|Reification (linguistics)}}
* {{le|語義折疊|Semantic folding}}
* [[语音处理|语音处理]]
* {{le|口語對話系統|Spoken dialogue system}}
* [[校對|校對]]
* {{le|文字简化|Text simplification}}
* {{le|Thought vector|Thought vector}}
* {{le|Truecasing|Truecasing}}
* [[問答系統|問答系統]]
* [[Word2vec|Word2vec]]
* [[BERT|BERT]]
{{div col end}}

==参考文献==
{{reflist}}
== 延伸閱讀 ==
<!-- In alphabetical order of by last name -->
{{refbegin|2}}
* {{cite journal | last1 = Bates | first1 = M | year = 1995 | title = Models of natural language understanding | url = | journal = Proceedings of the National Academy of Sciences of the United States of America | volume = 92 | issue = 22| pages = 9977–9982 | doi=10.1073/pnas.92.22.9977}}
* Steven Bird, Ewan Klein, and Edward Loper (2009). ''Natural Language Processing with Python''. O'Reilly Media. ISBN 978-0-596-51649-9.
* Daniel Jurafsky and James H. Martin (2008). ''Speech and Language Processing'', 2nd edition. Pearson Prentice Hall. ISBN 978-0-13-187321-6.
* Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze (2008). ''Introduction to Information Retrieval''. Cambridge University Press. ISBN 978-0-521-86571-5. [http://nlp.stanford.edu/IR-book/ Official html and pdf versions available without charge.]
* Christopher D. Manning and Hinrich Schütze (1999). ''Foundations of Statistical Natural Language Processing''. The MIT Press. ISBN 978-0-262-13360-9.
* David M. W. Powers and Christopher C. R. Turk (1989). ''Machine Learning of Natural Language''. Springer-Verlag. ISBN 978-0-387-19557-5.
{{refend}}

== 外部連結 ==
{{Commons}}
* [https://web.archive.org/web/20100616131036/http://www.cslu.ogi.edu/HLTsurvey/ 人類語言技術當前發展情況概覽]
* [http://www.cs.columbia.edu/nlp/ 哥倫比亞大學自然語言處理研究組]
* [http://www.lti.cs.cmu.edu/ 卡内基梅隆大学語言技術研究院]
* [http://nlp.stanford.edu/ 斯坦福大學自然語言處理研究小組]
* [http://www.nlp.org.cn/ 中文自然語言處理開放平臺]
* [https://web.archive.org/web/20040916080945/http://acl.ldc.upenn.edu/ ACL（美國電腦語言學協會）提供的相關雜誌以及研討會的論文]
* [http://gate.ac.uk/ GATE: a Java Library for Text Engineering]
* [https://web.archive.org/web/20101222002124/http://ir.hit.edu.cn/demo/ltp/ LTP:语言技术平台（简体中文）]
* [http://www.nltk.org/book Python編程語言的自然語言處理工具包教程]
* [https://github.com/fastnlp/fastNLP fastNLP]
{{-}}

{{自然语言处理}}
{{Computer Science}}
{{Authority control}}

[[Category:人工智能应用|Category:人工智能应用]]
[[Category:自然語言處理|]]
[[Category:人机交互|Category:人机交互]]
[[Category:中文信息处理|Category:中文信息处理]]