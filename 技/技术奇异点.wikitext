{{refimprove|time=2012-06-12T04:09:44+00:00}}
{{NoteTA
|G1 = IT
|G2 = Physics
|1 = zh-hans:瑞·库茨维尔; zh-hant:雷蒙德·庫茲威爾;
|2 = zh-hans:技术奇点;zh-tw:科技奇點;zh-hk:科技奇異點;
|3 = zh-hans:技术;zh-tw:科技;zh-hk:科技;
}}

'''技术奇点'''（{{lang-en|Technological Singularity}}），出自[[引力奇点|奇點]]理論；根据[[技术发展史|技术发展史]]总结出的观点，认为人类正在接近一个使得现有技术被完全抛弃或者人类文明被完全颠覆的事件点，在这个事件点以后的事件就像黑洞的[[事件视界|事件视界]]一样完全无法预测。例如，[[意识上传|意识上传]]技术可能使人类的意识摆脱有机体的约束，在这个奇点之后的人类文明將發展到當今完全无法理解的水準。

一般设想技术奇异点將由超越现今人类并且可以自我进化的[[机器智能|机器智能]]、或者其它形式的超级智能的出现所引发。由于其智能远超今天的人类，因此技术的发展会完全超乎全[[人类|人类]]的理解能力，甚至无法预测其发生。

之所以被称为奇异点，因為它是一个[[临界点_(数学)|临界点]]。当我们越来越接近这个临界点，它会对人类的事物产生越来越大的影响，直到它成为人类的共识。但当它最终来临的时候，也许仍会出人意料并且难以想象。就好比[[物理学|物理学]]上引力无穷大时产生的[[黑洞|黑洞]]的物理属性一样，已经不在一般正常模型所能预测的范围之内。

一些研究指出，當今全球範圍內創新的速率正在趨緩，而非加速。許布納（Jonathan Huebner）在2005年指出，根據美國專利數和世界科技突破的狀況來看，人類科技創新的速率在1873年達到頂峰，之後便開始趨緩。<ref name=Huebner>{{Cite journal | last1 = Huebner | first1 = J. | title = A possible declining trend for worldwide innovation | doi = 10.1016/j.techfore.2005.01.003 | journal = [[Technological_Forecasting_and_Social_Change|Technological Forecasting and Social Change]] | volume = 72 | issue = 8 | pages = 980–986 | year = 2005 | pmid =  | pmc =  | url = https://zenodo.org/record/1259385 | access-date = 2019-11-13 | archive-date = 2020-10-27 | archive-url = https://web.archive.org/web/20201027010009/https://zenodo.org/record/1259385 | dead-url = no }}</ref><ref>{{cite news|url=https://www.usnews.com/usnews/culture/articles/050707/7inventor.htm|title=Science: Wanna be an inventor? Don't bother|last=Hayden|first=Thomas|date=7 July 2005|work=U.S. News & World Report|accessdate=10 June 2013|archive-url=https://web.archive.org/web/20131101195406/http://www.usnews.com/usnews/culture/articles/050707/7inventor.htm|archive-date=2013-11-01|dead-url=yes}}</ref>在他的文章當中，他曾問道：「科技（創新的）程度將會達到頂峰然後跌落到黑暗時代（的水準）？」<ref name=Huebner/>在之後於《新科學人》的評論中，許布納提到說盡管他相信在2024年，科技創新的頻率會跌落到黑暗時代的水準，但這不表示他認為黑暗時代將會再次到來。<ref>{{cite news|last=Adler|first=Robert|title=Entering a dark age of innovation|url=https://www.newscientist.com/article/dn7616-entering-a-dark-age-of-innovation.html|accessdate=30 May 2013|newspaper=New Scientist|date=2 July 2005|archive-date=2015-04-27|archive-url=https://web.archive.org/web/20150427171637/http://www.newscientist.com/article/dn7616-entering-a-dark-age-of-innovation.html|dead-url=no}}</ref>盡管一些人質疑許布納創新速率正在下降的觀點，並認為科技創新的速率實際上是在加快的，但許布納的觀點獲得一些其他資料的支持。美國專利局在2010年的資料支持許布納的觀點；<ref>{{Cite journal | last1 = Strumsky | first1 = D. | last2 = Lobo | first2 = J. | last3 = Tainter | first3 = J. A. | doi = 10.1002/sres.1057 | title = Complexity and the productivity of innovation | journal = Systems Research and Behavioral Science | volume = 27 | issue = 5 | page = 496 | year = 2010 | pmid =  | pmc = }}</ref>一篇2012年的研究也支持許布納的觀點。<ref>{{cite journal |last1=Gordon |first1=Robert J. |title=Is U.S. Economic Growth Over? Faltering Innovation Confronts the Six Headwinds |journal=NBER Working Paper No. 18315 |date=2012 |doi=10.3386/w18315 }}</ref>這表示現代社會沒有接近科技奇異點的跡象。

== 智能与创造力的大爆炸 ==
{{cquote|我们的未来不是再经历进化，而是要经历爆炸。
:::::::::<small>——[[瑞·库茨维尔|瑞·库茨维尔]]</small>}}

最早意识到人类技术发展速度加快的是[[波兰|波兰]]数学家[[斯塔尼斯拉夫·乌拉姆|斯塔尼斯拉夫·乌拉姆]]，于1958年和计算机科学家[[冯·诺伊曼|冯·诺伊曼]]的一次对话中。而统计学家{{tsl|en|I. J. Good|I.J. Good}}于1965年提出技术奇异点的必要条件──“智能爆炸”概念：
{{cquote|让我们将超级智能机器定义为一种能够远远超过任何人的所有智力活动的机器。如果说设计机器是这些智力活动的一种，那么超级智能机器肯定能够设计出更加优良的机器；

毫无疑问，随后必将出现一场“智能爆炸”，人类的智能会被远远抛在后面。因此，第一台超级智能机器是人类需要完成的最后一项发明，前提是这台机器足够听话，会告诉我们如何控制它。……
在二十世纪之内，超级智能机器将很有可能被制造出来，而它会是人类需要进行的最后一项发明。}}
1982年，[[弗诺·文奇|弗诺·文奇]]在[[卡内基梅隆大学|卡内基梅隆大学]]召开的[[美国人工智能协会|美国人工智能协会]]年会上首次提出“技术奇异点”这一概念。1993年，[[弗诺·文奇|弗诺·文奇]]在[[美国国家航空航天局|美国国家航空航天局]]路易斯研究中心举行的一次讨论会上发表了论文《技术奇异点即将来临：后人类时代生存指南》（《The Coming Technological Singularity》）再次简述了这个观点，论文同年刊载于《[[全地球评论|全地球评论]]》（《Whole Earth Review》）杂志上。在这篇论文中，[[弗诺·文奇|弗诺·文奇]]系统地阐述了自己的“技术奇异点”的理论，并声称超越人类智能的计算器将在50年之內问世，并把这次变化好比200万年以前人类的出现一样重大。

1999年，美国[[哲學家|哲學家]]，[[麻省理工学院|麻省理工学院]]博士[[瑞·库茨维尔|瑞·库茨维尔]]发表的《[[心靈機器時代_—當電腦超越人腦|心靈機器時代 —當電腦超越人腦]]》（''{{lang|en|The Age of Spiritual machines}}''）一书，阐明了未来[[互联网|互联网]]将把全人类乃至其他生命和非生命体汇集成一个完整意识体的概念，在美国学术界激起一片浪潮。2001年，他提出[[摩尔定律|摩尔定律]]的扩展定理，即[[库茨维尔定理|库茨维尔定理]]（Kurzweil's Law of Accelerated Return）。该定理指出，人类出现以来所有技术發展都是以[[指数|指数]]增长。也就是说，一开始技术發展是小的，但是一旦信息和经验积累到一定的基础，發展开始快速增长，以指数的形式，然后是以指数的指数形式增长。[[瑞·库茨维尔|瑞·库茨维尔]]将同样的概念引入到生物进化和宇宙诞生以来的变化裡，并导出了同样的指数增长的[[公式|公式]]。根据[[数学模型|数学模型]]，在未来的某个时间内，技术發展将接近于无限大。2005年，[[瑞·库茨维尔|瑞·库茨维尔]]发表了500多页的巨著《[[奇點迫近|奇點迫近]]》，再次系统的介绍了这个概念的数学模型、基因工程的发展、[[纳米|纳米]]技术的展望和超越光速的可能性，该书成为美国网络书店[[亞馬遜公司|亚马逊]]上2005年科普十大畅销书之一，同时成为网上博客热谈的一个话题之一。

== 加速度发展 ==
[[File:PPTMooresLawai.jpg|thumb]]认为，随着[[範式轉移|範式轉移]]的加快，计算机以几何级数的形势发展，从打卡式机械计算机，到电磁继电式计算机，到真空管计算机，到晶体管计算机，到早期集成电路计算机，到现代超大规模集成电路计算机，计算机设计与技术的[[範式轉移|範式轉移]]所需的时间越来越短，此即[[摩尔定律|摩尔定律]]。]]

一些技术奇异点的拥护者依据对历史数据的总结与归纳得出技术奇异点必将不可避免的到来的结论。波兰数学家[[斯塔尼斯拉夫·烏拉姆|斯塔尼斯拉夫·烏拉姆]]于1945年和计算机科学家[[冯·诺伊曼|冯·诺伊曼]]的一次关于科技加速度发展的对话<ref>Ulam, Stanislaw (May 1958), "Tribute to John von Neumann", Bulletin of the American Mathematical Society 64（nr 3, part 2）: 1-49</ref>中第一次把「奇异点」这个词置于科技发展的上下文裡：

{{cquote|我们的对话集中讨论了不断加速的科技进步，以及其对人类生活模式带来的改变，这些发展及改变，似乎把人类带到了一个可以被称之为人类历史的奇异点的阶段，在这个阶段过后，我们目前所熟知的人类的社会、艺术和生活模式，将不复存在。}}

与此同时，[[中国|中国]][[科学家|科学家]][[李四光|李四光]]在他的短文《人类的出现》<ref>李四光，《人类的出现》，节选自《天文、地质、古生物资料摘要》，高级中学课本──语文，第二册，第216－217页，人民教育出版社，1995年6月第2版，1996年10月第1次印刷，ISBN7-107-01134-0/G·2401（课）</ref>裡写到：

{{cquote|人类文化的发展，经过新人阶段的旧石器时代晚期以后，先后进入新石器时代及金属时代。愈到后来发展愈为迅猛。从新石器时代的开始到现在至多不过一万年左右，金属时代的开始到现在不过数千年，人们开始利用电能到现在不过一百多年，原子能的利用则仅是最近几十年的事；而新石器时代以前的发展阶段，则动辄以数十万年到千百万年计。由此可见，人类的发展不是等速度运动，而是类似一种加速度运动，即愈到后来前进的速度愈是成倍地增加。}}

大部分人用電腦只是十多年，而使用互聯網的時間更加短，而使用智能手機的時間更只是數年。

[[霍金|霍金]]认为使世界产生不可逆转的[[範式轉移|範式轉移]]发生的频率越来越高，速度越来越快<ref>Hawkins, Gerald S.（1983）, Mindsteps to the Cosmos, HarperCollins </ref>。作为例子，霍金指出从现代数学的发现到计算机的发明所用的时间远小于从文字被发明到现代数学被发现所用的时间。

[[瑞·库茨维尔|瑞·库茨维尔]]对于科技历史所做出的分析让他得出了关于科技的增长以[[几何级数|几何级数]]进行的结论，他把这个结论称作「加速度回报定律」。这个定律把[[摩尔定律|摩尔定律]]扩展到了许多積體電路科技以外的科技领域中去。

== 发生时间与可能性 ==
大部分相信这个理论的科学家认为这件事情将会在2005年到2100年之间发生。发展会非常迅速，以至大部分人還没有意识到事件就已经发生了。
[[File:The-singularity-Masayoshi_Son.jpg|thumb]]預測奇點將發生於2018年]]

=== 发生的可能途径 ===
#某种先进的电脑也许会“甦醒”，并拥有超人智能。
#大型电脑网络（以及和网络相连的用户）也可能“甦醒”过来，成为超人智能的实体。
#人类与计算机结合使操纵计算机的用户可能被视为超人智能实体，也就是“智能扩大”。
#生物科学将有可能大大提升人类的智能。

=== 来临的条件 ===
技术奇异点来临的条件是超级智能的产生。超级智能产生方式可能是人工智能（AI）和智能扩大（IA）。

=== 智能扩大的发展方向 ===
#人机小组自动化控制。
#用于艺术创作的人机共同体。
#允许人机联合团队参加棋类比赛。
#发展不需要人类待在某个固定的地方才能使用的人机界面和网络接口。
#发展更对称的决策系统。
#利用本地网络让人类小组更高效地工作。
#开发世界性的互联网，使其成为人机结合的工具。

=== 技术奇异点的前景——强人工智能 ===
弱人工智能的特点：依靠快速思维取胜的超级智能。

强人工智能的特点：通过不同带宽交流的能力，包括高于语言和文字信息的交流方式。

=== 可能阻止技术奇异点来临的因素 ===
#大规模的灾难，最可能发生的是国家之间相互毁灭的核战。
#无论计算机硬件发展到多么先进的程度，我们都无法让其“甦醒”。
#我们大大低估了人类大脑的计算能力，这将使得计算机超越人脑的时间大大延迟。
#艺术对于人类的阻碍，以及人类的艺术不能让机器人明白。反对者认为技术发展到一定的时候会停止下来。但是，[[瑞·库茨维尔|瑞·库茨维尔]]强调：[[範式轉移|範式轉移]]会用更大、更优良的方法解决以往技术无法跨越的门槛。他更强调思維轉換发生的时间间隔越来越短，同时会越来越频繁。


== 数学模型的现实解释 ==
在数学模型到达奇异点的意义可以通过进化模式阶梯（Evolutionary Paradigm Hierarchy）来解释。这个阶梯强调[[数学|数学]]是最宏观的[[集合_(数学)|集合]]，而[[物理|物理]]是数学的一个[[子集|子集]]，而[[化学|化学]]则是物理的一个[[子集|子集]]，[[生物|生物]]则是化学的[[子集|子集]]，[[生物圈|生物圈]]则是[[生物|生物]]的子集。接下来，人类不同地区的文化是生物圈定义出的子集，而政治又是以文化为基础指法规，最后人类的经济活动是由政府的法规所规定。

这个阶梯强调从宇宙诞生以来，筛选就不断的进行，能量首先以三维空间的形式出现，定义了宇宙的数学基础，而[[万有引力|万有引力]]、[[强相互作用|强相互作用]]、[[弱相互作用|弱相互作用]]、[[电磁力|电磁力]]，还有其他未知的物理常数在三维空间的基础上定义了能量在宇宙中的物理属性，而通过这些物理属性，产生了一百多种[[元素|元素]]，而在这些元素中，只有少数几种像[[碳|碳]]原子这样的[[原子|原子]]构造了生物学，在几亿年的生物进化中才造就出人类。又由于每个人类文明所处在的生物圈不同，从而产生了不同的文化和技术进步的速度。而人类的技术进步速度增快的意义则是人对这个阶梯上越来越宏观集合上的掌握。第一步是发现更为宏观项上基本定理，即[[牛顿|牛顿]]的[[万有引力|万有引力]]、[[查爾斯·羅伯特·達爾文|達爾文]]的[[进化论|进化论]]，第二步是开始有足够的实力去改变自然界原有的定理。所以，可以把人类历史的发展看成是发现的时代和创造跟改变的时代两阶段。自工业革命以来，我们其实已经进入第二个阶段。

该理论的有趣论证是，在一定的时间内有些事情一定会发生。也就是说，人类或早或晚都会发现基本的定理，不管是否由历史上已经出现的伟人们完成。进入第二个阶段以后，发现仍然继续，但是发明创造成为更为重要的活动。而发明的总的步伐会是倒着往回爬阶梯。在[[后工业时代|后工业时代]]，人类已经基本上征服和控制[[生物圈|生物圈]]，甚至已经在破坏，[[全球暖化|全球暖化]]就是非常好的例子。接下来，人类或人类发明的机器逐渐掌控[[生物|生物]]本身，[[基因|基因]]科学的发展成为一个很好的例子，然后是化学、物理和数学。最后，人类的技术有可能突破到三维空间以外的地方以其他的方式表达能量的存在。甚至，能量本身是否作为最基本的表现形式也值得怀疑，可能能量本身也是某些东西的一种表现形式而已。但是阶梯的概念描述了未来人类的发展方向、技术在人类生活中扮演的越来越重要的角色，以及每一次控制能力升级以后所带来的极大的对更小子集掌控与优化。

== 事件的意义与影响 ==
如果必定发生，技术奇点的意义将非常深远。人类与宇宙的关系似乎要重新定义。如果技术奇点发生，那么一些科学幻想中的技术像[[人脑意识的数字化|人脑意识的数字化]]，无限的生命，甚至超越[[光速|光速]]都将成为现实。人类智能将以光速速度在宇宙中殖民和扩散开来，直到充满整个宇宙。[[瑞·库茨维尔|瑞·库茨维尔]]强调人类将和机器融合，而机器部分将在2150年左右达到现代人类智能的几十亿倍以上。

== 对外星人的推测 ==
如果[[宇宙|宇宙]]中大部分适合生命居住的[[星球|星球]]产生了类似人类智能的環境，大都应该在很短的时间内达到技术奇点。那么，人类先寻找[[外星人|外星人]]似乎是徒劳无功的。因为到达技术奇点以后，人类所创造的智能已经能够了解到宇宙的全部可能性，寻找[[外星人|外星人]]似乎变得没有意义。

== 关于时间 ==
如果把技术描述成一种不断突破各种世界中存在的限制的机制的话，而接近最顶端的数学限制又是建立在逻辑基础之上，那么逻辑本身也就是一种限制。也就是说时间本身也是一种限制。如果，能够突破时间的逻辑限制，那么我们应该生活在未来人类创造的世界里。话说回来，我们是未来人类的始祖，但是未来人类又是我们的创造者。或者说，最初制造宇宙大爆炸的前因和突破时间限制而可以看到过去、现在和将来所有可能的未来无限技术进步的智能是同一个人，或者说我们无法区分开来他们。有趣的是，如果时间机器确实在未来被制造出来，我们为什么无法在现在遇见他们？这是[[霍金|霍金]]已经提出过的问题。但是，事实上，如果技术奇异点发生，那么未来人类早在宇宙诞生时就在观察宇宙的进化。他们无须也没有兴趣去看望某一个时段人类。因为一切像剧本一样被事先排列好了。而我们现在的存在则证明了技术奇异点在未来发生。甚至可以说，未来的人类为了屏蔽与古代智能的交流而制造了时间，而时间在任何的[[参照系|参照系]]中都不能看到未来，从而躲避古代人类的追问。所以，我们甚至可以说，我们自己就是未来智能所创造的活化石。

技术奇点的出现似乎预测[[时间|时间]]将会终止。在技术奇点到来前的几秒钟时间内，所有可发现的东西都将被发现和利用。无限接近技术奇点的时候，似乎所有能够用来调动的[[能量|能量]]将被调用完。以计算机[[自动机|自动机理论]]的论点来说，这个智能可能会控制所有能量的变换，停止计算。但可能仍然在[[高维空间|高维空间]]计算能量变化。甚至在[[无理数维度|无理数维度]]上计算能量，所以时间仍然在某些空间中运行。通过这个观点，可以把宇宙想象成一个能量逐渐被整理成[[绝对优化|绝对优化]]的一个过程。

== 社团组织 ==
目前全世界最权威的两家技术奇异点研究中心{{link-en|Singularity Institute for Artificial Intelligence|Singularity Institute for Artificial Intelligence}}和{{link-en|Acceleration Studies Foundation|Acceleration Studies Foundation}}都设在美国。Singularity Institute for Artificial Intelligence于2000年宣告成立，吸收了[[瑞·库茨维尔|瑞·库茨维尔]]为荣誉会长，目标是研制出第一个[[种子人工智能|种子人工智能]]（遞歸自我完善/{{link-en|Seed AI|Seed AI}}）。而全世界第一次技术奇异点会议于2006年5月于[[斯坦福大学|斯坦福大学]]举行。

==批評==
技术奇异点的论证并非严密。仅仅从电脑技术正在加速度发展，就得出技术奇异点的发生，推理上不严密。

事实上，不少技术领域已经长期处于技术瓶颈难以突破，并不能持续[[指数增长|指数增长]]，例如民用[[核聚变|核聚变]]发电站、常温[[超导体|超导体]]、高能量密度且安全的[[电池|电池]]技术……。在理论方面，超越[[标准模型|标准模型]]的物理理论与实验不符，已令相关研究陷入困难。此外，一些新技术虽然是很厉害的创新，但因为不符合经济适用原则反而被淘汰，如[[超音速客机|超音速客机]]、[[航天飞机|航天飞机]]等。

《经济学人》曾嘲笑技术奇异点这个概念：按照这个说法，因为剃须刀的刀头在历史上数量不断增多，那么最终，剃须刀的刀头数量会增加到无穷多个。<ref name="moreblades">{{Citation |title=More blades good |author=Anonymous |newspaper=The Economist |date=18 March 2006 |url=http://www.economist.com/science/displaystory.cfm?story_id=5624861 |location=London |page=85 |volume=378 |issue=8469 |accessdate=2015-08-28 |archive-date=2006-07-10 |archive-url=https://web.archive.org/web/20060710033628/http://www.economist.com/science/displaystory.cfm?story_id=5624861 |dead-url=no }}</ref>

== 註腳 ==
{{Reflist}}

== 參考文獻 ==
{{refbegin|2}}
*《The Coming Technological Singularity》，弗诺·文奇，1993，出自《Whole Earth Review》。
*《弗诺·文奇的幻想世界》，Mick，出自《科幻世界译文版》，2008.11下半月版，104-108页。
*《弗诺·文奇访谈》，Mick，出自《科幻世界译文版》，2008.11下半月版，118-120页。
*《技术奇异点即将来临：后人类时代生存指南》，弗诺·文奇，出自《科幻世界译文版》，2008.11下半月版，124-130页。
* [[科技想要什麼|科技想要什麼]]
* {{Citation| last = Acceleration Studies Foundation| year = 2007| url = http://www.accelerating.org/about.html| title = ASF: About the Foundation| accessdate = 2007-11-13| archive-url = https://web.archive.org/web/20081226135037/http://www.accelerating.org/about.html| archive-date = 2008-12-26| dead-url = yes}}
* {{Citation | last = Anonymous | title = More blades good | newspaper = The Economist | date = 18 March 2006 <!-- web location incorrectly lists issue date as 16 March 2006 --> | url = http://www.economist.com/science/displaystory.cfm?story_id=5624861 | location = London | page = 85 | volume = 378 | issue = 8469 | accessdate = 2015-08-28 | archive-date = 2006-07-10 | archive-url = https://web.archive.org/web/20060710033628/http://www.economist.com/science/displaystory.cfm?story_id=5624861 | dead-url = no }}
* {{Citation| url = http://www.earthisland.org/journal/index.php/eij/article/technotopia_the_death_of_nature/| title = Technotopia and the Death of Nature: Clones, Supercomputers, and Robots| first = James John| last = Bell| authorlink = James John Bell| year = 2002| season = Summer| publisher = Earth Island Journal (first published in the November/December 2001 issue of the ''Earth First! Journal'')| accessdate = 2007-08-07| archive-date = 2018-07-27| archive-url = https://web.archive.org/web/20180727152232/http://www.earthisland.org/journal/index.php/eij/article/technotopia_the_death_of_nature/| dead-url = no}}
* {{Citation| url = http://www.mindfully.org/Technology/2003/Singularity-Bell1may03.htm| title = Exploring The "Singularity"| last = Bell| first = James John| date = 1 May 2003| work = The Futurist| publisher = [[World_Future_Society|World Future Society]] (mindfully.org)| accessdate = 2007-08-07| archive-date = 2007-08-10| archive-url = https://web.archive.org/web/20070810033456/http://www.mindfully.org/Technology/2003/Singularity-Bell1may03.htm| dead-url = no}}
* {{Citation| first=Anthony| last=Berglas| title=Artificial Intelligence will Kill our Grandchildren| year=2008| url=http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html| accessdate=2008-06-13| archive-date=2014-07-23| archive-url=https://web.archive.org/web/20140723053223/http://berglas.org/Articles/AIKillGrandchildren/AIKillGrandchildren.html| dead-url=no}}
* {{Citation| first = Damien| last = Broderick| authorlink = Damien Broderick| title = The Spike: How Our Lives Are Being Transformed by Rapidly Advancing Technologies| location= New York| publisher=Forge| year = 2001| isbn = 0-312-87781-1}}
* {{Citation| first=Nick| last=Bostrom| authorlink=Nick Bostrom| title=Existential Risks| journal=[[Journal_of_Evolution_and_Technology|Journal of Evolution and Technology]]| year=2002| volume=9| url=http://www.nickbostrom.com/existential/risks.html| accessdate=2007-08-07| archive-date=2011-04-27| archive-url=https://web.archive.org/web/20110427030852/http://www.nickbostrom.com/existential/risks.html| dead-url=no}}
* {{Citation| first = Nick| last = Bostrom| title = Ethical Issues in Advanced Artificial Intelligence| journal = Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence| year = 2003| volume = 2| pages = 12–17| url = http://www.nickbostrom.com/ethics/ai.html| accessdate = 2007-08-07| archive-date = 2018-10-08| archive-url = https://web.archive.org/web/20181008090224/http://www.nickbostrom.com/ethics/ai.html| dead-url = no}}
* {{Citation | last = Dreyfus | first = Hubert L. | author-link = Hubert Dreyfus | last2 = Dreyfus | first2 = Stuart E. | author2-link = Stuart Dreyfus | date = 1 March 2000 | title = Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer | edition = 1 | place = New York | publisher = Free Press | isbn = 0-7432-0551-0}}
* {{Citation | last = Ford | first = Martin | year = 2009 | title = The Lights in the Tunnel: Automation, Accelerating Technology and the Economy of the Future | publisher = CreateSpace | url = http://www.thelightsinthetunnel.com | isbn = 978-1-4486-5981-4 | postscript = . | accessdate = 2020-10-11 | archive-date = 2010-09-06 | archive-url = https://web.archive.org/web/20100906023409/http://www.thelightsinthetunnel.com/ | dead-url = no }}
* {{Citation
 |first=I. J. 
 |last=Good 
 |authorlink=I. J. Good 
 |title=Speculations Concerning the First Ultraintelligent Machine 
 |journal=Advances in Computers 
 |year=1965 
 |volume=6 
 |pages=31–88 
 |publisher=[[Academic_Press|Academic Press]] 
 |editors=Franz L. Alt and Morris Rubinoff 
 |url=http://www.aeiveos.com/~bradbury/Authors/Computing/Good-IJ/SCtFUM.html 
 |archiveurl=https://web.archive.org/web/20010527181244/http://www.aeiveos.com/~bradbury/Authors/Computing/Good-IJ/SCtFUM.html 
 |archivedate=2001-05-27 
 |accessdate=2007-08-07 
 |doi=10.1016/S0065-2458(08)60418-0 
 |series=Advances in Computers 
 |isbn=9780120121069 
 |deadurl=yes 
}}
* {{Citation|url=http://hanson.gmu.edu/vc.html |title=Some Skepticism |first=Robin |last=Hanson |author-link=Robin Hanson |year=1998 |publisher=Robin Hanson |accessdate=2009-06-19 |deadurl=no |archiveurl=https://web.archive.org/web/20090828023928/http://hanson.gmu.edu/vc.html |archivedate=2009-08-28 }}
* {{Citation| last= Hanson| first= Robin| title= Economics of the Singularity| periodical=IEEE Spectrum|date=June 2008}}
* {{Citation | last= Hawking | first= Stephen | author-link= Stephen Hawking | year= 1998 | title= Science in the Next Millennium: Remarks by Stephen Hawking | url= http://clinton2.nara.gov/Initiatives/Millennium/shawking.html | accessdate= 2007-11-13 | archive-url= https://web.archive.org/web/20090629195958/http://clinton2.nara.gov/Initiatives/Millennium/shawking.html | archive-date= 2009-06-29 | dead-url= yes }}
* {{Citation| first = Gerald S.| last = Hawkins| authorlink = Gerald Hawkins| title = Mindsteps to the Cosmos|date=August 1983| publisher = HarperCollins
| isbn = 0-06-015156-0}}
* {{Citation | last= Heylighen | first= Francis | author-link= Francis Heylighen | year= 2007 | contribution= Accelerating Socio-Technological Evolution: from ephemeralization and stigmergy to the global brain | contribution-url= http://pespmc1.vub.ac.be/Papers/AcceleratingEvolution.pdf | editor-last= Modelski | editor-first= G. | editor-link= George Modelski | editor2-last= Devezas | editor2-first= T. | editor3-last= Thompson | editor3-first= W. | title= Globalization as an Evolutionary Process: Modeling Global Change | place= London | publisher= Routledge | isbn= 978-0-415-77361-4 | accessdate= 2015-08-28 | archive-date= 2021-02-24 | archive-url= https://web.archive.org/web/20210224191910/http://pespmc1.vub.ac.be/Papers/AcceleratingEvolution.pdf | dead-url= no }}
* {{cite arXiv| last = Hibbard| first = Bill| authorlink = Bill Hibbard| title = Ethical Artificial Intelligence| date = 5 November 2014| eprint=1411.1373| class = cs.AI| ref=harv}}
* {{Citation
 |last=Johansen 
 |first=Anders 
 |last2=Sornette 
 |first2=Didier 
 |date=25 January 2001 
 |title=Finite-time singularity in the dynamics of the world population, economic and financial indices 
 |periodical=Physica A 
 |volume=294 
 |pages=465–502 
 |url=http://hjem.get2net.dk/kgs/growthphysA.pdf 
 |format=PDF 
 |accessdate=2007-10-30 
 |doi=10.1016/S0378-4371(01)00105-4 
 |issue=3–4 
 |arxiv=cond-mat/0002075 
 |bibcode=2001PhyA..294..465J 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20071129111006/http://hjem.get2net.dk/kgs/growthphysA.pdf 
 |archivedate=2007-11-29}}
* {{Citation| first=Bill| last=Joy| authorlink=Bill Joy| title=Why the future doesn't need us| journal=[[Wired_(magazine)|Wired Magazine]]| date=April 2000| issue=8.04| url=http://www.wired.com/wired/archive/8.04/joy.html| accessdate=2007-08-07| isbn=0-670-03249-2| publisher=Viking Adult| archive-date=2014-03-21| archive-url=https://web.archive.org/web/20140321124511/http://www.wired.com/wired/archive/8.04/joy.html| dead-url=no}}
* {{Citation| first=Raymond| last=Kurzweil| authorlink=Raymond Kurzweil| title=The Law of Accelerating Returns| year=2001| publisher=Lifeboat Foundation| url=http://lifeboat.com/ex/law.of.accelerating.returns| accessdate=2007-08-07| bibcode=2008NatPh...4..507B| volume=4| page=507| journal=Nature Physics| doi=10.1038/nphys1010| issue=7| archive-date=2018-08-27| archive-url=https://web.archive.org/web/20180827014027/https://lifeboat.com/ex/law.of.accelerating.returns| dead-url=yes}}
* {{Citation| first=Raymond| last=Kurzweil| title=[[The_Singularity_Is_Near|The Singularity Is Near]]| location=New York| publisher=Viking| year=2005| isbn=0-670-03384-7}}
* {{Citation| first=Hans| last=Moravec| authorlink=Hans Moravec| title=Pigs in Cyberspace| journal=On the Cosmology and Ecology of Cyberspace| url=http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1992/CyberPigs.html| date=January 1992| accessdate=2007-11-21| archive-date=2021-02-24| archive-url=https://web.archive.org/web/20210224213432/https://frc.ri.cmu.edu/~hpm/project.archive/general.articles/1992/CyberPigs.html| dead-url=no}}
* {{Citation| first=Ashik| last=Mahmud| authorlink=Ashik Mahmud| title=Post/Human Beings & Techno-salvation: Exploring Artificial Intelligence in Selected Science Fictions| journal=Socrates Journal| url=http://www.socratesjournal.com/index.php/socrates/article/view/150/html_145| date=June 2015| doi=10.7910/DVN/VAELLN| accessdate=2015-06-26| deadurl=yes| archiveurl=https://web.archive.org/web/20150626140131/http://www.socratesjournal.com/index.php/socrates/article/view/150/html_145| archivedate=2015-06-26}}
* {{cite arXiv| first = Jürgen| last = Schmidhuber| authorlink = Jürgen Schmidhuber| title = New Millennium AI and the Convergence of History| date = 29 June 2006
| eprint=cs/0606081| class = cs.AI| ref=harv}}
* {{Citation|last=Singularity Institute for Artificial Intelligence |authorlink=Singularity Institute for Artificial Intelligence |title=Why Artificial Intelligence? |year=2002 |url=http://www.singinst.org/intro/whyAI-print.html |deadurl=yes |archiveurl=https://web.archive.org/web/20061004201151/http://www.singinst.org/intro/whyAI-print.html |archivedate=2006-10-04 }}
* {{Citation|url=http://www.asimovlaws.com/ |title=3 Laws Unsafe |last=Singularity Institute for Artificial Intelligence |year=2004 |accessdate=2007-08-07 |deadurl=no |archiveurl=https://web.archive.org/web/20110323234811/http://www.asimovlaws.com/ |archivedate=2011-03-23 }}
* {{Citation|last=Singularity Institute for Artificial Intelligence |title=What is the Singularity? |year=2007 |url=http://www.singinst.org/overview/whatisthesingularity |accessdate=2008-01-04 |deadurl=yes |archiveurl=https://web.archive.org/web/20071230031316/http://www.singinst.org/overview/whatisthesingularity/ |archivedate=2007-12-30 }}
* {{Citation| url = http://accelerating.org/articles/huebnerinnovation.html| title = On Huebner Innovation| first = John| last = Smart| authorlink = John Smart (futurist)| date = September 2005| publisher = Acceleration Studies Foundation| accessdate = 2007-08-07| archive-url = https://web.archive.org/web/20060616144643/http://accelerating.org/articles/huebnerinnovation.html| archive-date = 2006-06-16| dead-url = yes}}
* {{Citation | first = Stanislaw | last = Ulam | authorlink = 斯塔尼斯拉夫·烏拉姆 | date = May 1958 | title = Tribute to John von Neumann | journal = Bulletin of the American Mathematical Society | volume = 64 | issue = nr 3, part 2 | pages = 1–49 | doi = 10.1090/S0002-9904-1958-10189-5 }}
* {{Citation| first=Vernor| last=Vinge| authorlink=Vernor Vinge| title=The Coming Technological Singularity| journal=Vision-21: Interdisciplinary Science & Engineering in the Era of CyberSpace, proceedings of a Symposium held at NASA Lewis Research Center| publisher=[[NASA|NASA]] Conference Publication CP-10129| url=http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html| date=30–31 March 1993| accessdate=2007-08-07| archive-date=2007-01-01| archive-url=https://web.archive.org/web/20070101133646/http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html| dead-url=yes}}. See also [http://mindstalk.net/vinge/vinge-sing.html this HTML version] {{Wayback|url=http://mindstalk.net/vinge/vinge-sing.html |date=20180410074243 }}, retrieved on 2009-03-29.
* {{Citation| first=Kevin| last=Warwick| authorlink=Kevin Warwick| year=2004| title=March of The Machines| publisher = University of Illinois Press| isbn=978-0-252-07223-9}}
{{refend}}

==延伸閱讀==
{{refbegin}}
*[[Gary_Marcus|Marcus, Gary]], "Am I Human?:  Researchers need new ways to distinguish [[artificial_intelligence|artificial intelligence]] from the natural kind", ''[[Scientific_American|Scientific American]]'', vol. 316, no. 3 (March 2017), pp. 58–63.  ''Multiple'' tests of [[artificial_intelligence|artificial-intelligence]] efficacy are needed because, "just as there is no single test of [[Athletics_(physical_culture)|athletic]] prowess, there cannot be one ultimate test of [[intelligence|intelligence]]."  One such test, a "Construction Challenge", would test perception and physical action—"two important elements of intelligent behavior that were entirely absent from the original [[Turing_test|Turing test]]."  Another proposal has been to give machines the same standardized tests of science and other disciplines that schoolchildren take.  A so far insuperable stumbling block to artificial intelligence is an incapacity for reliable [[disambiguation|disambiguation]].  "[V]irtually every sentence [that people generate] is [[ambiguity|ambiguous]], often in multiple ways."  A prominent example is known as the "pronoun disambiguation problem":  a machine has no way of determining to whom or what a [[pronoun|pronoun]] in a sentence—such as "he", "she" or "it"—refers.
*[[Piero_Scaruffi|Scaruffi, Piero]], "Intelligence is not Artificial" (2016) for a critique of the singularity movement and its similarities to religious cults.
*[[Wilson_da_Silva|da Silva, Wilson]], [https://www.wilsondasilva.com/post/tipping-point "Tipping Point?"] {{Wayback|url=https://www.wilsondasilva.com/post/tipping-point |date=20200822031219 }} (2009) for an essay on the singularity movement and its scientific validity.
{{refend}}

== 相關 ==
{{Portal|技术}}
* [[強人工智慧|強人工智慧]]（Strong AI）
* [[末世论|末世论]]
* [[摩爾定律|摩爾定律]]
* [[技術性失業|技術性失業]]
* [[無條件基本收入|無條件基本收入]]
* [[馬太效應|馬太效應]]

==外部連結==
{{Spoken Wikipedia|En-Technological_singularity-article.ogg|2018-11-03}}
* [https://intelligence.org/ie-faq/ Intelligence Explosion FAQ] {{Wayback|url=https://intelligence.org/ie-faq/ |date=20161107233352 }} by the [[Machine_Intelligence_Research_Institute|Machine Intelligence Research Institute]]
* [http://bootstrappingartificialintelligence.fr/WordPress3/ Blog on bootstrapping artificial intelligence] {{Wayback|url=http://bootstrappingartificialintelligence.fr/WordPress3/ |date=20210109065535 }} by Jacques Pitrat
* ''[https://web.archive.org/web/20121127035518/http://hplusmagazine.com/2011/03/07/why-an-intelligence-explosion-is-probable/ Why an Intelligence Explosion is Probable]'' (Mar 2011)
* ''[https://medium.com/@francois.chollet/the-impossibility-of-intelligence-explosion-5be4a9eda6ec Why an Intelligence Explosion is Impossible] {{Wayback|url=https://medium.com/@francois.chollet/the-impossibility-of-intelligence-explosion-5be4a9eda6ec |date=20210322214203 }}'' (Nov 2017)

{{Technology}}
{{Emerging technologies}}
{{年問題}}
{{世界末日}}
[[Category:未來學|Category:未來學]]
[[Category:技術預測|Category:技術預測]]
[[Category:机器人学|Category:机器人学]]