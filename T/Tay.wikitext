'''Tay'''是[[微软|微软]]在[[Twitter|Twitter]]平台上推出的[[人工智慧|人工智慧]][[聊天機器人|聊天機器人]]，在2016年3月23日推出<ref name="bizarre">{{cite news|url=http://www.independent.co.uk/life-style/gadgets-and-tech/news/tay-tweets-microsoft-creates-bizarre-twitter-robot-for-people-to-chat-to-a6947806.html|publisher=The Independent|title=Tay tweets: Microsoft creates bizarre Twitter robot for people to chat to|date=March 23, 2016|author=Andrew Griffin|accessdate=2016-03-25|archive-date=2016-03-26|archive-url=https://web.archive.org/web/20160326004423/http://www.independent.co.uk/life-style/gadgets-and-tech/news/tay-tweets-microsoft-creates-bizarre-twitter-robot-for-people-to-chat-to-a6947806.html|dead-url=no}}</ref>。此機器人是由微軟的技術及研究部門以及Bing部門推出<ref name="tr">{{cite news|url=http://www.techrepublic.com/article/why-microsofts-tay-ai-bot-went-wrong/|publisher=Tech Republic|title=Why Microsoft's 'Tay' AI bot went wrong|author=Hope Reese|date=March 24, 2016|accessdate=2016-03-25|archive-date=2017-06-15|archive-url=https://web.archive.org/web/20170615222836/http://www.techrepublic.com/article/why-microsofts-tay-ai-bot-went-wrong/|dead-url=no}}</ref><ref>{{cite news|title=Meet Tay, the creepy-realistic robot who talks just like a teen|author=Caitlin Dewey|date=March 23, 2016|publisher=Washington Post|url=https://www.washingtonpost.com/news/the-intersect/wp/2016/03/23/meet-tay-the-creepy-realistic-robot-who-talks-just-like-a-teen/|accessdate=2016-03-25|archive-date=2016-03-24|archive-url=https://web.archive.org/web/20160324201305/https://www.washingtonpost.com/news/the-intersect/wp/2016/03/23/meet-tay-the-creepy-realistic-robot-who-talks-just-like-a-teen/|dead-url=no}}</ref>。Tay設計成模仿一個十九歲美國女性的說話方式，再藉由和Twitter上用戶的互動繼續學習<ref name="bi">{{cite news|url=http://www.slate.com/blogs/business_insider/2016/03/24/microsoft_s_new_ai_chatbot_tay_removed_from_twitter_due_to_racist_tweets.html|publisher=Business Insider|title=Microsoft Took Its New A.I. Chatbot Offline After It Started Spewing Racist Tweets|date=March 24, 2016|author=Rob Price|accessdate=2016-03-25|archive-date=2016-03-25|archive-url=https://web.archive.org/web/20160325091607/http://www.slate.com/blogs/business_insider/2016/03/24/microsoft_s_new_ai_chatbot_tay_removed_from_twitter_due_to_racist_tweets.html|dead-url=no}}</ref>。在Tay推出一天之後，因為Tay開始有一些種族歧視之類的偏激言論，因此微軟暫時關閉了Tay的Twitter帳號，這些言論明顯的是和網路上一些有偏激言論的人互動後，被刻意教導而出現的<ref name="bi"/>。

人工智慧研究者{{le|罗曼·扬波尔斯基|Roman Yampolskiy}}認為他可以理解Tay不適當的言論，Tay其實是在模仿其他推特用戶的攻擊性言論，而微軟還沒有讓這個聊天機器人了解哪些言論是不適當的。他將此問題和IBM的人工智能程序[[沃森_(人工智能程序)|沃森]]比較，沃森在讀了[[城市词典|城市词典]]後就已經會用一些褻瀆性的言詞<ref name="tr"/>。

== 相關條目 ==
*[[微软小冰|微软小冰]]：另一個微软的聊天機器人

==參考資料==
{{reflist}}


[[Category:審查制度|Category:審查制度]]
[[Category:聊天機器人|Category:聊天機器人]]
[[Category:微软软件|Category:微软软件]]