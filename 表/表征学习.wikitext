{{Expand English}}

{{机器学习导航栏}}
在[[机器学习|机器学习]]中，'''特征学习'''或'''表征学习'''<ref name="pami">{{cite journal |author1=Y. Bengio |author2=A. Courville |author3=P. Vincent |title=Representation Learning: A Review and New Perspectives |journal=IEEE Trans. PAMI, special issue Learning Deep Architectures |year=2013|doi=10.1109/tpami.2013.50 |volume=35 |pages=1798–1828}}</ref>是学习一个特征的技术的集合：将原始数据转换成为能够被机器学习来有效开发的一种形式。它避免了手动提取特征的麻烦，允许计算机学习使用特征的同时，也学习如何提取特征：学习如何学习。

机器学习任务，例如[[分类问题|分类问题]]，通常都要求输入在数学上或者在计算上都非常便于处理，在这样的前提下，特征学习就应运而生了。然而，现实世界中的数据，例如圖片、影片，以及感測器的測量值都非常的複雜、冗長又多變，如何有效的提取出特征并且将其表达出來成為了一個重要挑戰。传统的手动提取特征需要大量的人力并且依赖于非常专业的知识。同时，还不便于推广。这就要求特征学习技术的整体设计非常有效，自动化，并且易于推广。

特征学习可以被分为两类：监督的和无监督的，类似于机器学习。
* 在监督特征学习中，被标记过的数据被当做特征用来学习。例如神经网络，多层感知器，(监督)字典学习。
* 在无监督特征学习中，未被标记过的数据被当做特征用来学习。例如(无监督)字典学习，[[独立成分分析|独立成分分析]]，[[自动编码|自动编码]]，[[矩阵分解|矩阵分解]]<ref>{{cite conference
|author1=Nathan Srebro |author2=Jason D. M. Rennie |author3=Tommi S. Jaakkola
|title=Maximum-Margin Matrix Factorization
|conference=[[Conference_on_Neural_Information_Processing_Systems|NIPS]]
|year=2004
}}</ref> ，各种[[聚类分析|聚类分析]]及其变形<ref name="coates2011"/><ref>{{cite conference
|last1 = Csurka
|first1 = Gabriella
|last2 = Dance
|first2 = Christopher C.
|last3 = Fan
|first3 = Lixin
|last4 = Willamowski
|first4 = Jutta
|last5 = Bray
|first5 = Cédric
|title = Visual categorization with bags of keypoints
|conference = ECCV Workshop on Statistical Learning in Computer Vision
|year = 2004
|url = http://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/csurka-eccv-04.pdf
|access-date = 2016-04-17
|archive-date = 2021-03-08
|archive-url = https://web.archive.org/web/20210308040610/https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/csurka-eccv-04.pdf
|dead-url = no
}}</ref><ref name="jurafsky">{{cite book |title=Speech and Language Processing |author1=Daniel Jurafsky |author2=James H. Martin |publisher=Pearson Education International |year=2009 |pages=145–146}}</ref>。

== 监督特征学习 ==
监督特征学习就是从被标记的数据中学习特征。大致有以下几种方法。

=== 监督字典学习 ===
总体来说，字典学习是为了从输入数据获得一组的表征元素，使每一个数据点可以（近似的）通过对表征元素加权求和来重构。字典中的元素和权值可以通过最小化表征误差来得到。通过L1正则化可以让权值变得稀疏（例，每一个数据点的表征只有几个非零的权值）。

监督字典学习利用输入数据的结构和给定的标签（输出）来优化字典。例如，2009年Mairal等人提出的一种监督字典学习方案被应用在了分类问题上。这个方案的优化目标包括最小化分类误差，表征误差，权值的1范数（L1正则化）和分类器参数的2范数。
有监督的字典学习可以被视为一个三层神经网络（一层隐含层），第一层（输入层）到第二层（隐含层）是表征学习，第二层到第三层（输出）是分类器的参数回归。

=== 神经网络 ===
[[神经网络|神经网络]]是通过多层由内部相连的节点组成的网络的一个学习算法。它的命名是受到神经系统的启发，它的每一个节点就像神经系统里的神经元，而每一条边就像一条突触。神经网络里面的每一条边都有对应的权值，而整个网络则定义运算法则将输入数据转换成为输出。神经网络的网络函数通过权值来刻画输入层跟输出层之间的关系。通过适当的调整网络函数，可以尽量最小化损耗的同时解决各种各样的机器学习任务。

== 无监督特征学习 ==
=== κ-平均算法 ===
=== 主要成分分析 ===
=== 独立成分分析 ===
=== 局部线性嵌入算法 ===
=== 无监督字典学习 ===

== 另見 ==
* [[特徵檢測|特徵檢測]]
* [[向量量化|向量量化]]
* [[深度學習|深度學習]]
== 参考文献 ==
{{Reflist}}

[[Category:机器学习|Category:机器学习]]